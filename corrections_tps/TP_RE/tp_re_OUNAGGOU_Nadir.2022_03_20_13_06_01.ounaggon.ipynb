{"cells":[{"cell_type":"markdown","metadata":{"id":"jjf5pW7H0Guf"},"source":["# TP Relation Extraction"]},{"cell_type":"markdown","metadata":{"id":"_kuQK4zd1kbL"},"source":["## Introduction"]},{"cell_type":"markdown","metadata":{"id":"efVai6Q31Cbh"},"source":["Dans ce TP nous allons:\n","\n","1. Découvrir la tache d’extraction de relation par réseaux neuronaux  (« neural relation extraction », NRE)\n","2.  Comprendre le fonctionnement d’un modèle d’extraction de relation avec un encodeur BERT\n","3. Découvrir la tache de reconnaissance d'entités nommées (« named-entity recognition », NER)\n","4. Coder une pipeline d’extraction de relation par réseaux neuronaux pour des jeux de données textuels\n","\n","Avec les outils suivants:\n","1. La libraire [OpenNRE](https://github.com/thunlp/OpenNRE), basée sur Pytorch et HuggingFace’s Transformers, pour la tache d’extraction de relation par réseaux neuronaux\n","2. [HuggingFace’s Transformers](https://huggingface.co/transformers/) : une bibliothèque basée sur Pytorch pour le traitement automatique des langues et notamment les modèles neuronaux de type Transformer (comme BERT)\n","3. Google Colab, qui héberge ce *Jupyter Notebook*. Avant de commencer le TP, vous pouvez consulter des pages d'introductions [à Colab](https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l01c01_introduction_to_colab_and_python.ipynb#scrollTo=YHI3vyhv5p85) et [aux Notebooks](https://realpython.com/jupyter-notebook-introduction/)\n"]},{"cell_type":"markdown","metadata":{"id":"NhcmAWU7FISp"},"source":["Contrairement au dernier TP, cette fois-ci nous n’aurons pas besoin d’utiliser une GPU car nous n’allons pas entraîner des nouveaux modèles ou faire de l’inférence sur des grands jeux de données: une CPU suffira. Nous pouvons vérifier si l’on est en train d’utiliser une CPU ou une GPU avec les lignes suivantes:"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6576,"status":"ok","timestamp":1647766625015,"user":{"displayName":"Nadir Ounaggou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14687011903990117142"},"user_tz":-60},"id":"w9xBd3ZGgVOB","outputId":"8f7b6306-cbc3-47c9-fa1f-35e52cd08739"},"outputs":[{"name":"stdout","output_type":"stream","text":["Will work on CPU.\n"]}],"source":["import torch\n","\n","if torch.cuda.is_available():\n","  print(\"GPU is available.\")\n","  device = torch.cuda.current_device()\n","else:\n","  print(\"Will work on CPU.\")"]},{"cell_type":"markdown","metadata":{"id":"Tr1QqSFEGGIH"},"source":["Nous avons besoin d’installer l’outil OpenNRE. Pour éviter de devoir ré-télécharger le répertoire  GitHub de OpenNRE à chaque fois qu’on ré-initialise le fichier Colab, il est convenant de monter notre répertoire Google Drive et y télécharger le répertoire OpenNRE de façon à l’avoir toujours disponible. Ainsi, à chaque fois que nous allons ré-initialiser le fichier Colab, il nous suffira de monter notre Goodle Drive pour avoir accès à la libraire OpenNRE.\n","\n","> ATTENTION: modifiez *tp_path_in_drive* pour pointer sur le repertoire où vous avez placé le fichier tp_re.ipynb, vous allez télécharger OpenNRE dans le meme réépertoire. Si vous êtes sur votre machine locale, vous n'avez pas besoin de monter le Drive, mais juste de faire le clonage du réépertoire OpenNRE."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1647583610396,"user":{"displayName":"Nadir Ounaggou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14687011903990117142"},"user_tz":-60},"id":"M9uK65iWnQ7N","outputId":"1a857989-e92b-42c4-d086-36fed7f295a2"},"outputs":[{"name":"stdout","output_type":"stream","text":["tp_re.ipynb\n"]},{"data":{"text/plain":[]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["%%shell\n","cd drive/MyDrive/tp_re\n","ls"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":422,"status":"ok","timestamp":1647606482216,"user":{"displayName":"Nadir Ounaggou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14687011903990117142"},"user_tz":-60},"id":"lOBAGErunc6G","outputId":"2c90d0f3-c1fe-4adc-8fff-b34fafbf3aeb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24167,"status":"ok","timestamp":1647766663789,"user":{"displayName":"Nadir Ounaggou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14687011903990117142"},"user_tz":-60},"id":"MmWpFhonvmNH","outputId":"850d3e4a-fa79-428e-cf7f-712e4d165f9d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n","Cloning repo...\n","...done!\n"]}],"source":["import os\n","from google.colab import drive\n","\n","tp_path_in_drive = '/drive/MyDrive/tp_re'\n","opennre_path_in_drive = tp_path_in_drive + '/OpenNRE'\n","\n","# mount Google Drive\n","drive.mount('/content/drive')\n","\n","if not os.path.isdir(opennre_path_in_drive):\n","  # OpenNRE is not already present in Google Drive\n","  if not os.path.isdir(tp_path_in_drive):\n","    # make directory for the TP if necessary\n","    os.makedirs(tp_path_in_drive, exist_ok=True)\n","  # change directory to the TP directory\n","  os.chdir(tp_path_in_drive)\n","  # clone OpenNRE repo\n","  print(\"Cloning repo...\")\n","  os.system('git clone https://github.com/thunlp/OpenNRE.git')\n","  print(\"...done!\")\n","else:\n","  print(\"OpenNRE is already present in Google Drive under {0}\".format(opennre_path_in_drive))\n","\n","# Change current dir to OpenNRE\n","os.chdir(opennre_path_in_drive)"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":172,"status":"ok","timestamp":1647766669497,"user":{"displayName":"Nadir Ounaggou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14687011903990117142"},"user_tz":-60},"id":"q67JhFW7XPcu"},"outputs":[],"source":["# Update requirements requirements\n","!sed -i '/transformers==3.0.2/c\\transformers==3.4.0' requirements.txt"]},{"cell_type":"markdown","metadata":{"id":"CofsxJQRON4p"},"source":["Nous pouvons désormais continuer avec l’installation."]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":116245,"status":"ok","timestamp":1647766788214,"user":{"displayName":"Nadir Ounaggou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14687011903990117142"},"user_tz":-60},"id":"e8wFXQwfMwxp","outputId":"ae61b1c7-839d-4ffc-f6b2-1187f15999c1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting torch==1.6.0\n","  Downloading torch-1.6.0-cp37-cp37m-manylinux1_x86_64.whl (748.8 MB)\n","\u001b[K     |████████████████████████████████| 748.8 MB 18 kB/s \n","\u001b[?25hCollecting transformers==3.4.0\n","  Downloading transformers-3.4.0-py3-none-any.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 56.0 MB/s \n","\u001b[?25hCollecting pytest==5.3.2\n","  Downloading pytest-5.3.2-py3-none-any.whl (234 kB)\n","\u001b[K     |████████████████████████████████| 234 kB 49.6 MB/s \n","\u001b[?25hCollecting scikit-learn==0.22.1\n","  Downloading scikit_learn-0.22.1-cp37-cp37m-manylinux1_x86_64.whl (7.0 MB)\n","\u001b[K     |████████████████████████████████| 7.0 MB 50.3 MB/s \n","\u001b[?25hRequirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (1.4.1)\n","Collecting nltk>=3.6.4\n","  Downloading nltk-3.7-py3-none-any.whl (1.5 MB)\n","\u001b[K     |████████████████████████████████| 1.5 MB 44.0 MB/s \n","\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0->-r requirements.txt (line 1)) (0.16.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0->-r requirements.txt (line 1)) (1.21.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0->-r requirements.txt (line 2)) (21.3)\n","Collecting tokenizers==0.9.2\n","  Downloading tokenizers-0.9.2-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 25.2 MB/s \n","\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0->-r requirements.txt (line 2)) (3.17.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0->-r requirements.txt (line 2)) (2019.12.20)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0->-r requirements.txt (line 2)) (4.63.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 64.5 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0->-r requirements.txt (line 2)) (3.6.0)\n","Collecting sentencepiece!=0.1.92\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 53.6 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0->-r requirements.txt (line 2)) (2.23.0)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest==5.3.2->-r requirements.txt (line 3)) (21.4.0)\n","Requirement already satisfied: importlib-metadata>=0.12 in /usr/local/lib/python3.7/dist-packages (from pytest==5.3.2->-r requirements.txt (line 3)) (4.11.2)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from pytest==5.3.2->-r requirements.txt (line 3)) (0.2.5)\n","Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest==5.3.2->-r requirements.txt (line 3)) (8.12.0)\n","Collecting pluggy<1.0,>=0.12\n","  Downloading pluggy-0.13.1-py2.py3-none-any.whl (18 kB)\n","Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest==5.3.2->-r requirements.txt (line 3)) (1.11.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.22.1->-r requirements.txt (line 4)) (1.1.0)\n","Collecting regex!=2019.12.17\n","  Downloading regex-2022.3.15-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (749 kB)\n","\u001b[K     |████████████████████████████████| 749 kB 66.3 MB/s \n","\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk>=3.6.4->-r requirements.txt (line 6)) (7.1.2)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12->pytest==5.3.2->-r requirements.txt (line 3)) (3.10.0.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12->pytest==5.3.2->-r requirements.txt (line 3)) (3.7.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.4.0->-r requirements.txt (line 2)) (3.0.7)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->transformers==3.4.0->-r requirements.txt (line 2)) (1.15.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.4.0->-r requirements.txt (line 2)) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.4.0->-r requirements.txt (line 2)) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.4.0->-r requirements.txt (line 2)) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.4.0->-r requirements.txt (line 2)) (2021.10.8)\n","Installing collected packages: regex, tokenizers, sentencepiece, sacremoses, pluggy, transformers, torch, scikit-learn, pytest, nltk\n","  Attempting uninstall: regex\n","    Found existing installation: regex 2019.12.20\n","    Uninstalling regex-2019.12.20:\n","      Successfully uninstalled regex-2019.12.20\n","  Attempting uninstall: pluggy\n","    Found existing installation: pluggy 0.7.1\n","    Uninstalling pluggy-0.7.1:\n","      Successfully uninstalled pluggy-0.7.1\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.10.0+cu111\n","    Uninstalling torch-1.10.0+cu111:\n","      Successfully uninstalled torch-1.10.0+cu111\n","  Attempting uninstall: scikit-learn\n","    Found existing installation: scikit-learn 1.0.2\n","    Uninstalling scikit-learn-1.0.2:\n","      Successfully uninstalled scikit-learn-1.0.2\n","  Attempting uninstall: pytest\n","    Found existing installation: pytest 3.6.4\n","    Uninstalling pytest-3.6.4:\n","      Successfully uninstalled pytest-3.6.4\n","  Attempting uninstall: nltk\n","    Found existing installation: nltk 3.2.5\n","    Uninstalling nltk-3.2.5:\n","      Successfully uninstalled nltk-3.2.5\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","yellowbrick 1.4 requires scikit-learn>=1.0.0, but you have scikit-learn 0.22.1 which is incompatible.\n","torchvision 0.11.1+cu111 requires torch==1.10.0, but you have torch 1.6.0 which is incompatible.\n","torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.6.0 which is incompatible.\n","torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.6.0 which is incompatible.\n","imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.22.1 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed nltk-3.7 pluggy-0.13.1 pytest-5.3.2 regex-2022.3.15 sacremoses-0.0.49 scikit-learn-0.22.1 sentencepiece-0.1.96 tokenizers-0.9.2 torch-1.6.0 transformers-3.4.0\n"]},{"data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["torch"]}}},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["running install\n","running bdist_egg\n","running egg_info\n","creating opennre.egg-info\n","writing opennre.egg-info/PKG-INFO\n","writing dependency_links to opennre.egg-info/dependency_links.txt\n","writing top-level names to opennre.egg-info/top_level.txt\n","writing manifest file 'opennre.egg-info/SOURCES.txt'\n","adding license file 'LICENSE'\n","writing manifest file 'opennre.egg-info/SOURCES.txt'\n","installing library code to build/bdist.linux-x86_64/egg\n","running install_lib\n","running build_py\n","creating build\n","creating build/lib\n","creating build/lib/opennre\n","copying opennre/pretrain.py -> build/lib/opennre\n","copying opennre/__init__.py -> build/lib/opennre\n","creating build/lib/opennre/tokenization\n","copying opennre/tokenization/utils.py -> build/lib/opennre/tokenization\n","copying opennre/tokenization/word_piece_tokenizer.py -> build/lib/opennre/tokenization\n","copying opennre/tokenization/bert_tokenizer.py -> build/lib/opennre/tokenization\n","copying opennre/tokenization/basic_tokenizer.py -> build/lib/opennre/tokenization\n","copying opennre/tokenization/word_tokenizer.py -> build/lib/opennre/tokenization\n","copying opennre/tokenization/__init__.py -> build/lib/opennre/tokenization\n","creating build/lib/opennre/model\n","copying opennre/model/softmax_nn.py -> build/lib/opennre/model\n","copying opennre/model/base_model.py -> build/lib/opennre/model\n","copying opennre/model/bag_one.py -> build/lib/opennre/model\n","copying opennre/model/sigmoid_nn.py -> build/lib/opennre/model\n","copying opennre/model/bag_average.py -> build/lib/opennre/model\n","copying opennre/model/bag_attention.py -> build/lib/opennre/model\n","copying opennre/model/__init__.py -> build/lib/opennre/model\n","creating build/lib/opennre/module\n","copying opennre/module/__init__.py -> build/lib/opennre/module\n","creating build/lib/opennre/encoder\n","copying opennre/encoder/bert_encoder.py -> build/lib/opennre/encoder\n","copying opennre/encoder/base_encoder.py -> build/lib/opennre/encoder\n","copying opennre/encoder/pcnn_encoder.py -> build/lib/opennre/encoder\n","copying opennre/encoder/cnn_encoder.py -> build/lib/opennre/encoder\n","copying opennre/encoder/__init__.py -> build/lib/opennre/encoder\n","creating build/lib/opennre/framework\n","copying opennre/framework/utils.py -> build/lib/opennre/framework\n","copying opennre/framework/multi_label_sentence_re.py -> build/lib/opennre/framework\n","copying opennre/framework/bag_re.py -> build/lib/opennre/framework\n","copying opennre/framework/sentence_re.py -> build/lib/opennre/framework\n","copying opennre/framework/data_loader.py -> build/lib/opennre/framework\n","copying opennre/framework/__init__.py -> build/lib/opennre/framework\n","creating build/lib/opennre/module/pool\n","copying opennre/module/pool/avg_pool.py -> build/lib/opennre/module/pool\n","copying opennre/module/pool/max_pool.py -> build/lib/opennre/module/pool\n","copying opennre/module/pool/__init__.py -> build/lib/opennre/module/pool\n","creating build/lib/opennre/module/nn\n","copying opennre/module/nn/cnn.py -> build/lib/opennre/module/nn\n","copying opennre/module/nn/rnn.py -> build/lib/opennre/module/nn\n","copying opennre/module/nn/lstm.py -> build/lib/opennre/module/nn\n","copying opennre/module/nn/__init__.py -> build/lib/opennre/module/nn\n","creating build/bdist.linux-x86_64\n","creating build/bdist.linux-x86_64/egg\n","creating build/bdist.linux-x86_64/egg/opennre\n","creating build/bdist.linux-x86_64/egg/opennre/tokenization\n","copying build/lib/opennre/tokenization/utils.py -> build/bdist.linux-x86_64/egg/opennre/tokenization\n","copying build/lib/opennre/tokenization/word_piece_tokenizer.py -> build/bdist.linux-x86_64/egg/opennre/tokenization\n","copying build/lib/opennre/tokenization/bert_tokenizer.py -> build/bdist.linux-x86_64/egg/opennre/tokenization\n","copying build/lib/opennre/tokenization/basic_tokenizer.py -> build/bdist.linux-x86_64/egg/opennre/tokenization\n","copying build/lib/opennre/tokenization/word_tokenizer.py -> build/bdist.linux-x86_64/egg/opennre/tokenization\n","copying build/lib/opennre/tokenization/__init__.py -> build/bdist.linux-x86_64/egg/opennre/tokenization\n","creating build/bdist.linux-x86_64/egg/opennre/model\n","copying build/lib/opennre/model/softmax_nn.py -> build/bdist.linux-x86_64/egg/opennre/model\n","copying build/lib/opennre/model/base_model.py -> build/bdist.linux-x86_64/egg/opennre/model\n","copying build/lib/opennre/model/bag_one.py -> build/bdist.linux-x86_64/egg/opennre/model\n","copying build/lib/opennre/model/sigmoid_nn.py -> build/bdist.linux-x86_64/egg/opennre/model\n","copying build/lib/opennre/model/bag_average.py -> build/bdist.linux-x86_64/egg/opennre/model\n","copying build/lib/opennre/model/bag_attention.py -> build/bdist.linux-x86_64/egg/opennre/model\n","copying build/lib/opennre/model/__init__.py -> build/bdist.linux-x86_64/egg/opennre/model\n","creating build/bdist.linux-x86_64/egg/opennre/module\n","creating build/bdist.linux-x86_64/egg/opennre/module/pool\n","copying build/lib/opennre/module/pool/avg_pool.py -> build/bdist.linux-x86_64/egg/opennre/module/pool\n","copying build/lib/opennre/module/pool/max_pool.py -> build/bdist.linux-x86_64/egg/opennre/module/pool\n","copying build/lib/opennre/module/pool/__init__.py -> build/bdist.linux-x86_64/egg/opennre/module/pool\n","creating build/bdist.linux-x86_64/egg/opennre/module/nn\n","copying build/lib/opennre/module/nn/cnn.py -> build/bdist.linux-x86_64/egg/opennre/module/nn\n","copying build/lib/opennre/module/nn/rnn.py -> build/bdist.linux-x86_64/egg/opennre/module/nn\n","copying build/lib/opennre/module/nn/lstm.py -> build/bdist.linux-x86_64/egg/opennre/module/nn\n","copying build/lib/opennre/module/nn/__init__.py -> build/bdist.linux-x86_64/egg/opennre/module/nn\n","copying build/lib/opennre/module/__init__.py -> build/bdist.linux-x86_64/egg/opennre/module\n","copying build/lib/opennre/pretrain.py -> build/bdist.linux-x86_64/egg/opennre\n","creating build/bdist.linux-x86_64/egg/opennre/encoder\n","copying build/lib/opennre/encoder/bert_encoder.py -> build/bdist.linux-x86_64/egg/opennre/encoder\n","copying build/lib/opennre/encoder/base_encoder.py -> build/bdist.linux-x86_64/egg/opennre/encoder\n","copying build/lib/opennre/encoder/pcnn_encoder.py -> build/bdist.linux-x86_64/egg/opennre/encoder\n","copying build/lib/opennre/encoder/cnn_encoder.py -> build/bdist.linux-x86_64/egg/opennre/encoder\n","copying build/lib/opennre/encoder/__init__.py -> build/bdist.linux-x86_64/egg/opennre/encoder\n","creating build/bdist.linux-x86_64/egg/opennre/framework\n","copying build/lib/opennre/framework/utils.py -> build/bdist.linux-x86_64/egg/opennre/framework\n","copying build/lib/opennre/framework/multi_label_sentence_re.py -> build/bdist.linux-x86_64/egg/opennre/framework\n","copying build/lib/opennre/framework/bag_re.py -> build/bdist.linux-x86_64/egg/opennre/framework\n","copying build/lib/opennre/framework/sentence_re.py -> build/bdist.linux-x86_64/egg/opennre/framework\n","copying build/lib/opennre/framework/data_loader.py -> build/bdist.linux-x86_64/egg/opennre/framework\n","copying build/lib/opennre/framework/__init__.py -> build/bdist.linux-x86_64/egg/opennre/framework\n","copying build/lib/opennre/__init__.py -> build/bdist.linux-x86_64/egg/opennre\n","byte-compiling build/bdist.linux-x86_64/egg/opennre/tokenization/utils.py to utils.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/opennre/tokenization/word_piece_tokenizer.py to word_piece_tokenizer.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/opennre/tokenization/bert_tokenizer.py to bert_tokenizer.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/opennre/tokenization/basic_tokenizer.py to basic_tokenizer.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/opennre/tokenization/word_tokenizer.py to word_tokenizer.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/opennre/tokenization/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/opennre/model/softmax_nn.py to softmax_nn.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/opennre/model/base_model.py to base_model.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/opennre/model/bag_one.py to bag_one.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/opennre/model/sigmoid_nn.py to sigmoid_nn.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/opennre/model/bag_average.py to bag_average.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/opennre/model/bag_attention.py to bag_attention.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/opennre/model/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/opennre/module/pool/avg_pool.py to avg_pool.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/opennre/module/pool/max_pool.py to max_pool.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/opennre/module/pool/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/opennre/module/nn/cnn.py to cnn.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/opennre/module/nn/rnn.py to rnn.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/opennre/module/nn/lstm.py to lstm.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/opennre/module/nn/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/opennre/module/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/opennre/pretrain.py to pretrain.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/opennre/encoder/bert_encoder.py to bert_encoder.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/opennre/encoder/base_encoder.py to base_encoder.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/opennre/encoder/pcnn_encoder.py to pcnn_encoder.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/opennre/encoder/cnn_encoder.py to cnn_encoder.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/opennre/encoder/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/opennre/framework/utils.py to utils.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/opennre/framework/multi_label_sentence_re.py to multi_label_sentence_re.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/opennre/framework/bag_re.py to bag_re.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/opennre/framework/sentence_re.py to sentence_re.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/opennre/framework/data_loader.py to data_loader.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/opennre/framework/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/opennre/__init__.py to __init__.cpython-37.pyc\n","creating build/bdist.linux-x86_64/egg/EGG-INFO\n","copying opennre.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying opennre.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying opennre.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying opennre.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","zip_safe flag not set; analyzing archive contents...\n","creating dist\n","creating 'dist/opennre-0.1-py3.7.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n","removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n","Processing opennre-0.1-py3.7.egg\n","Copying opennre-0.1-py3.7.egg to /usr/local/lib/python3.7/dist-packages\n","Adding opennre 0.1 to easy-install.pth file\n","\n","Installed /usr/local/lib/python3.7/dist-packages/opennre-0.1-py3.7.egg\n","Processing dependencies for opennre==0.1\n","Finished processing dependencies for opennre==0.1\n"]}],"source":["!pip install -r requirements.txt\n","!python setup.py install"]},{"cell_type":"markdown","metadata":{"id":"M9RIDU84lg4g"},"source":["## Les modéles pour l'extraction de relation\n","\n","À part offrir un cadre pour l’implémentation et l’entraînement de modelés pour l’extraction de relation, OpenNRE offre aussi des modèles déjà entraînés sur différents jeux de données, et donc capables de détecter différents types de relations entre entités. \n","\n","Ici, nous allons employer un modèle entraîné sur Wiki80 (dataset introduit par [le papier OpenNRE](https://www.aclweb.org/anthology/D19-3029/)), un jeu de données contenant des phrases collectées sur Wikipedia et Wikidata, ainsi que des rélations entre leurs entités. Si vous voulez en savoir plus sur Wiki80, vous pouvez le télécharger avec le script [download_wiki80.sh](https://github.com/thunlp/OpenNRE/blob/60a8ceb42e1cfacbde3c8cfb5f758fb7fe96bdc4/benchmark/download_wiki80.sh) "]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4473,"status":"ok","timestamp":1647767137666,"user":{"displayName":"Nadir Ounaggou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14687011903990117142"},"user_tz":-60},"id":"MxT-aqw2PXZO","outputId":"74992104-8b93-4ca0-b789-2c835d4dfc94"},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-03-20 09:05:32,458 - root - INFO - Loading BERT pre-trained checkpoint.\n"]}],"source":["import opennre\n","model = opennre.get_model('wiki80_bert_softmax')\n"]},{"cell_type":"markdown","metadata":{"id":"xYbZ4f4Q9Z-b"},"source":["Nous pouvons utiliser ce modèle pour calculer la relation entre un mot «tête» et un mot «queue» qui sont contenus dans un texte. Il suffit de passer au modèle le texte ainsi que la position de la tête et de la queue. Le modèle retournera la relation de la tête à l’égard de la queue ainsi que la probabilité qu’il associe à cette rélation. Par example, nous pouvons inféérer la relation entre **Áed Uaridnach** et **Máel Dúin mac Máele Fithrich** de la façon suivante:"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":553,"status":"ok","timestamp":1647766985788,"user":{"displayName":"Nadir Ounaggou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14687011903990117142"},"user_tz":-60},"id":"ZfpSGIJbV2gY","outputId":"1e5d5fd8-4204-4a9d-e345-70130689892a"},"outputs":[{"name":"stdout","output_type":"stream","text":["('child', 0.9812852144241333)\n"]}],"source":["item = {'text': 'He was the son of Máel Dúin mac Máele Fithrich, and grandson of the high king Áed Uaridnach (died 612).', 'h': {'pos': (78, 91)}, 't': {'pos': (18, 46)}}\n","print(model.infer(item))"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":200,"status":"ok","timestamp":1647766988974,"user":{"displayName":"Nadir Ounaggou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14687011903990117142"},"user_tz":-60},"id":"0UO8rs9Ntln_"},"outputs":[],"source":["txt = \"sdfkjssdgfqk qksgfiuedje kjyzeyvd zgvd klzgidèe bzfsccskzez klqcshhgbsdjk jzdu kzjgd ozhd.\"\n","txt[txt.index('kzjgd'): txt.index('kzjgd')+ len('kzjgd')]\n","txt0 = 'He was the son of Máel Dúin mac Máele Fithrich, and grandson of the high king Áed Uaridnach (died 612).'"]},{"cell_type":"markdown","metadata":{"id":"_kacE-LI9mi1"},"source":["#### Exercice 1\n","\n","\n","\n","Écrire une fonction `to_input_format(text, head, tail)` qui nous permet de trouver la position de deux mots (une tête et une queue) dans un texte, et qui retourne un dictionnaire contenant le texte et les deux positions suivant le format requis par la fonction `model.infer()`."]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":218,"status":"ok","timestamp":1647766996776,"user":{"displayName":"Nadir Ounaggou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14687011903990117142"},"user_tz":-60},"id":"iBlnOK1HJQN4"},"outputs":[],"source":["import re\n","\n","def to_input_format(text, head, tail):\n","  \"\"\"\n","  Args:\n","    text: a string of text\n","    head: a string of text representing a word contained in text\n","    tail: a string of text representing a word contained in text but different from head\n","  Returns:\n","    A dictionary containing the text and the position of head and tail within it,\n","    following the input format required by a SoftmaxNN model.\n","  \"\"\"\n","  dic = {}\n","  dic['text'] = text\n","  dic['h'] = {'pos': (text.index(head), text.index(head) + len(head))}\n","  dic['t'] = {'pos': (text.index(tail), text.index(tail) + len(tail))}\n","  return dic\n","  # ...."]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":878,"status":"ok","timestamp":1647767000529,"user":{"displayName":"Nadir Ounaggou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14687011903990117142"},"user_tz":-60},"id":"LX1hgPDO4VVM","outputId":"e4feccd2-f37f-4f86-be49-1552acc90700"},"outputs":[{"name":"stdout","output_type":"stream","text":["Good job!\n"]}],"source":["# Test your code with this snippet\n","text = 'He was the son of Máel Dúin mac Máele Fithrich, and grandson of the high king Áed Uaridnach (died 612).'\n","head = 'Áed Uaridnach'\n","tail = 'Máel Dúin mac Máele Fithrich'\n","test_item = to_input_format(text, head, tail)\n","try:\n","  assert model.infer(item) == model.infer(test_item)\n","  print(\"Good job!\")\n","except AssertionError:\n","  print(\"Something is wrong with your function, try again!\")"]},{"cell_type":"markdown","metadata":{"id":"QUeTb4e12e-T"},"source":["#### Exercice 2\n","\n","Décrire l’architecture du modèle qu’on vient de télécharger, la logique et le fonctionnement de chacun de ses composants, en faisant de références à ce que vous avez vu dans le cours ainsi que ce que vous avez appris dans le TP BERT.\n","\n","Aide: vous pouvez inspecter un modèle Pytorch avec `print(model)`. Pour mieux le comprendre, vous pouvez voir aussi son [code](https://github.com/thunlp/OpenNRE/blob/60a8ceb42e1cfacbde3c8cfb5f758fb7fe96bdc4/opennre/model/softmax_nn.py#L5)."]},{"cell_type":"markdown","metadata":{"id":"A5FNUmmW-r1h"},"source":["La question a été mise à jour entre-temps pour être plus détaillée. Voir réponses ci-dessous."]},{"cell_type":"markdown","metadata":{"id":"O5GJcd9l0in1"},"source":["#### Exercice 2\n","\n","Décrire l’architecture du modèle qu’on vient de télécharger, la logique et le fonctionnement de chacun de ses composants:\n","\n","1. Sentence-encoder: pourquoi l'on utilise un encodeur type BERT ?\n","2. À quoi sert la couche BertPooler ?\n","3. À quoi sert la couche linéaire finale (fc) ? pourquoi elle réduit à 80 la dimension du vecteur sortant de l’encodeur?\n","4. À quoi sert la fonction Softmax ?\n","5. À quoi sert la fonction de dropout que l'on appliuque à la sortie du réseau, ainsi que dans chaque couche de BERT ?\n","\n","Aide: vous pouvez inspecter un modèle Pytorch avec print(model). Pour mieux le comprendre, vous pouvez aussi voir [son code](https://github.com/thunlp/OpenNRE/blob/60a8ceb42e1cfacbde3c8cfb5f758fb7fe96bdc4/opennre/model/softmax_nn.py#L5), [la déscription du modèle BERT de Huggingface](https://huggingface.co/docs/transformers/v4.16.2/en/model_doc/bert#transformers.BertModel) ainsi que [son code](https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/bert/modeling_bert.py#L848)."]},{"cell_type":"code","execution_count":70,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":197,"status":"ok","timestamp":1647773983530,"user":{"displayName":"Nadir Ounaggou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14687011903990117142"},"user_tz":-60},"id":"qv1nrDdT-44Z","outputId":"e39006bc-aa1c-494e-9891-56e68d269bae"},"outputs":[{"name":"stdout","output_type":"stream","text":["SoftmaxNN(\n","  (sentence_encoder): BERTEncoder(\n","    (bert): BertModel(\n","      (embeddings): BertEmbeddings(\n","        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","        (position_embeddings): Embedding(512, 768)\n","        (token_type_embeddings): Embedding(2, 768)\n","        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (encoder): BertEncoder(\n","        (layer): ModuleList(\n","          (0): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (1): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (2): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (3): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (4): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (5): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (6): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (7): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (8): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (9): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (10): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (11): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","      (pooler): BertPooler(\n","        (dense): Linear(in_features=768, out_features=768, bias=True)\n","        (activation): Tanh()\n","      )\n","    )\n","  )\n","  (fc): Linear(in_features=768, out_features=80, bias=True)\n","  (softmax): Softmax(dim=-1)\n","  (drop): Dropout(p=0.5, inplace=False)\n",")\n"]}],"source":["print(model)"]},{"cell_type":"markdown","metadata":{"id":"K5Nb9EYN-7bY"},"source":["1) C'est un encodeur qui est adapté à notre cas, puisque un encodeur de type BERT est un encodeur pré-entrainé qui est sert à des modèles de multi-classification en avale. **Pourquoi est-il utile pour ce type de problème? Car il est capable de représenter la signification de chaque mot en fonction des mots qui l'entourent dans la même phrase (représentation contextualisée), c'est qui est très utile pour une comprehension générale de la phrase et sa classification. D'ailleurs, les représentations contextualisées sortant de BERT peuvent être utilisées pour beaucoup d'autres taches, et non-seulement la multi-classification**\n","\n","2) La couche BertPooler est la dernière couche des hidden layers. Elle prend la représentation de l'output du premier token et l'utilise dans les tâches suivantes. \n","\n","3) Cette couche est la dernière couche du réseau. Elle sert à redimensionner l'output de telle façon à ce qu'il devient utilisable par la suite, il le réduit à la taille du nombre de classe qu'on souhaite trouver.\n","\n","4) SoftMax sert à générer la probabilité d'exactitude des tokens prédit. **Le modèle ne prédit pas des tokens. La distribution de probas générée se référe aux 80 rélations (classes) possible pour la couple head-tail.**\n","\n","5) Dropout sert à bloquer l'ouput de certains neurones aléatoirement, dans le but d'obliger le réseau, dans son processus d'apprentissage, à uniformiser les mises à jour des paramètres sur tous les neurones et éviter le sur-apprentissage.\n","\n","**ce n'est pas claire comment le dropout empêche le sur-apprentissage** "]},{"cell_type":"markdown","metadata":{"id":"DxlyOgFU3GQs"},"source":["## Encodeur"]},{"cell_type":"markdown","metadata":{"id":"aWvfXCFlvf4q"},"source":["#### Exercice 3\n","\n","Maintenant, nous allons essayer de mieux comprendre le fonctionnement de ce modèle avec un focus sur son encodeur, qui est définit dans le fichier [bert_encoder.py](https://github.com/thunlp/OpenNRE/blob/60a8ceb42e1cfacbde3c8cfb5f758fb7fe96bdc4/opennre/encoder/bert_encoder.py#L7). Ce qui est spécifique à la tache de NRE dans ce modèle n’est pas l’architecture, mais plutôt la façon dont la séquence en input est tokenisée. Avec l’objectif de bien comprendre comment cet encodeur gère son input, répondez en détail aux questions suivantes qui se référent à la méthode `tokenize`. Si vous utilisez du code pour vous aider à répondre (conseillé), veuillez le joindre à vos réponses textuelles.\n","\n","1. Qu’est-ce qu’elle sont les variables `sent0`, `ent0`, `sent1`, `ent1`, `sent2` ?\n","2. Qu’est-ce que c’est `re_tokens` ?\n","3. Dans le _forward_, le `BERTEncoder` prend en entrée exclusivement la séquence textuelle qui a étée préalablement tokenisée. Comment est-il capable de distinguer la tête et la queue en sort de (apprendre à) prédire la relation entre les deux ?\n","4. Qu’est-ce que c’est le « Padding » et pourquoi est-il utile ?\n","5. Qu’est-ce que c’est l’ « Attention mask » et pourquoi est-elle utile ?\n","6. **[BONUS]** Quelle est la différence en termes de fonctionnement entre la classe `BERTEncoder` et la classe `BERTEntityEncoder`, définie dans le même fichier ?\n","\n","\n","Aide : vous pouvez accéder à la méthode `tokenize` pour la tester avec `model.sentence_encoder.tokenize(item)`"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":8,"status":"aborted","timestamp":1647771195002,"user":{"displayName":"Nadir Ounaggou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14687011903990117142"},"user_tz":-60},"id":"te30zT02s_Tt"},"outputs":[],"source":["# Write your code here if needed, and then write your detailed answers below.\n","print(model.sentence_encoder.tokenize(item))"]},{"cell_type":"markdown","metadata":{"id":"2Irag5TVyyda"},"source":["1) Si on considère que **first** est celui, entre *head* et *tail*, qui se positione le premier dans la phrase et **last** celui restant.\n","\n","\n","* `sent0`: Est le bout de texte, de l'input, se situant avant first.\n","\n","* `ent0` : C'est **first**.\n","\n","* `sent1`: Le bout de texte entre **first** et **last**.\n","\n","* `ent1` : C'est **last**.\n","\n","* `sent2`: Le bout de texte si situant après **last**.\n","\n","Dans toutes les variables ci-dessus, on stocke les bouts de texte sous forme de tockens.\n","\n","2) `re_tokens` représente la version finale de notre liste de tokens avec **'CLS'** comme premier token et **'SEP'** comme dernier.\n","\n","3) \n","\n","```\n","ent0 = ['[unused0]'] + ent0 + ['[unused1]'] if not rev else ['[unused2]'] + ent0 + ['[unused3]']\n","ent1 = ['[unused2]'] + ent1 + ['[unused3]'] if not rev else ['[unused0]'] + ent1 + ['[unused1]']\n","```\n","Le bout de code ci-dessus est celui qui permet au *forward* de `BERTEncoder` de distinguer le *head* et le *tail* en les positionnant entre des tokens prédéfinis.\n","\n","4) L'opération de padding est une opération de redimensionnement du vecteur des *tokens indéxés* en ajoutant des 0s jusqu'à attaindre le `max_length`. Cette opération a pour but d'uniformiser la taille des *tensors*, si c'est pas le cas on aura des erreurs à l'entrée du modèle. **Pourquoi est-il utile d'uniformer la taille? -> pour qu'on puisse representer un lot de phrases avec une matrice, ce qui est nécessaire au réseau pour traiter les phrases en parallèle.**\n","5) « Attention mask » est une liste de 0s et de 1s; Soit idx un indice, att_mask[idx] doit être égale à 1 si token[idx] doit être considéré/traité par la suite, et 0 sinon. Car après une opération de padding on aura dans la liste `token` des 0s qui sont que pour la forme, et qui ne doivent pas être inclus dans le calcul. Cela a pour effet de diminuer le temps de calcul.\n","\n","6) "]},{"cell_type":"markdown","metadata":{"id":"99yJxX0-Z1h1"},"source":["## NRE Pipeline\n","\n","Nous allons maintenant programmer une application qui prend en entrée une phrase et donne en sortie deux entités nommées dans la phrase ainsi que la relation entre eux.\n","\n","Pour ce faire, nous avons besoin :\n","\n","1. d’un système NER, qui reconnaît les entités nommées dans la phrase\n","2. d’un système NRE, comme celui que nous avons utilisé jusqu’à là"]},{"cell_type":"markdown","metadata":{"id":"oZYCITLLa0ii"},"source":["#### Exercice 4\n","\n","En vous aident avec la documentation de HuggingFace, instanciez une [pipeline](https://huggingface.co/transformers/main_classes/pipelines.html?highlight=pipeline#the-pipeline-abstraction) `ner_pipeline` pour la reconnaissance d'entités nommées, avec le modèle et le tokeniseur pré-entraînes [dbmdz/bert-large-cased-finetuned-conll03-english](https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n","\n","Vous pouvez tester la bonne réussite de l’exercice avec le code ci-dessous.\n","\n","**Indice** : la solution consiste en deux lignes de code : l'une pour importer la classe pipeline, l'autre pour instancier la bonne pipeline."]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["a79b90c4a93840dfaf82020cee8685b1","384506314d5f409999307da7a6cf4f42","4b1ae58d900d4569b2faa65c75039a99","bfba9d066e16459687b67a86ecec70e7","e31c98c6c02e44f99f345c078f095cbc","df56f6471b6e40678e80d4eee8321cda","8d1b3288179546b3ad974d8026920a73","830c741882064c29b3b6d987dd44fd36","1c711d8ecb1243c4b5266a688df5ba7e","e3a8c337b6b44b62bc556eefad439f0e","8aec1af74ea840498d8e80c51841ca9c","5b6bfd957fc145e69476d00ec4b57da0","0efe12e3ca43448f843b9bf1a97a0572","4d6f1e8ab52f4d3ea2248756d96f0bc6","b117c0dbc70a40388f194d81918c149c","7595a9b0d4f04386bf275799d36e16c9","2a9f2b05e4974daf9196ce9c93ef9ca9","f66469b16a384ded849822534bce1af6","3362d67ac9524161a34afc422fad714e","37ee166f574f40c187a332cf7ab048e4","03097ccf5ddb42f9b0004f56275b0b72","894b31e25db240fa982e30911f66939d","95f23713e52543b58dfbbc43954c1b6c","e5f3df4123b0462a9a498d594b0587ef","48d3d5d554164233bb935213e0881aca","f5d44e95c2f642afa044beeb4fc3acd1","106446a4c0af442980fb3945bfc04ccf","1d21da9be65d4879ab0dca865544fd22","945176ec31a045eb864f409ea68d08af","a2f8ecb777454ceea6443db0213b6628","32da91faa69e442f80519d4e8009e7b0","a7cc0d0092594c7f835208c0fafa82e0","2390daac0d8344d4a9b292f3011a266b","4986532354b04e5a84ab2dfd2d2ee7d2","7ab0f8eee32a4296a2f4c538841fa911","abc2f10edb9e482e8e81bbedc6b9f650","f5815958f2ff4091b412a33bc2bc9ffd","728857bdbf2843c1b87f2509cf3afa9e","b35163523362471fa15f1b79703b3ffe","b2c4762c84164bedad62304f95fcb0ed","d951ca9a1a294d60a1b65a04f87067be","d6571a09288b463987cee5473b16137a","4c5f019642114a05821d140fe66222e3","6b6137dc3147435da071fbbb38ba9d4c"]},"executionInfo":{"elapsed":42255,"status":"ok","timestamp":1647767063319,"user":{"displayName":"Nadir Ounaggou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14687011903990117142"},"user_tz":-60},"id":"323UWMt1Z3y0","outputId":"f265ef11-75e0-4ed7-cb11-d0ddd9021c72"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a79b90c4a93840dfaf82020cee8685b1","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/998 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5b6bfd957fc145e69476d00ec4b57da0","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/213k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"95f23713e52543b58dfbbc43954c1b6c","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/60.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4986532354b04e5a84ab2dfd2d2ee7d2","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/1.33G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# Write your code here\n","from transformers import pipeline,AutoModelForTokenClassification, AutoTokenizer\n","tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n","#tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n","model = AutoModelForTokenClassification.from_pretrained(\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n","ner_pipeline = pipeline(\"ner\", model = model, tokenizer = tokenizer)"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":827,"status":"ok","timestamp":1647767071037,"user":{"displayName":"Nadir Ounaggou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14687011903990117142"},"user_tz":-60},"id":"-IgKMz5wQv6z","outputId":"66f51e7c-34c2-4a42-8a67-2767757858c6"},"outputs":[{"data":{"text/plain":["[{'entity': 'I-PER', 'index': 6, 'score': 0.982085645198822, 'word': 'M'},\n"," {'entity': 'I-PER', 'index': 7, 'score': 0.8588601350784302, 'word': '##á'},\n"," {'entity': 'I-PER', 'index': 8, 'score': 0.8766007423400879, 'word': '##el'},\n"," {'entity': 'I-PER', 'index': 9, 'score': 0.8375428915023804, 'word': 'D'},\n"," {'entity': 'I-PER', 'index': 10, 'score': 0.4897182583808899, 'word': '##ú'},\n"," {'entity': 'I-PER', 'index': 11, 'score': 0.901253342628479, 'word': '##in'},\n"," {'entity': 'I-PER', 'index': 12, 'score': 0.5821399688720703, 'word': 'mac'},\n"," {'entity': 'I-PER', 'index': 13, 'score': 0.8884768486022949, 'word': 'M'},\n"," {'entity': 'I-PER', 'index': 14, 'score': 0.7004077434539795, 'word': '##á'},\n"," {'entity': 'I-PER',\n","  'index': 15,\n","  'score': 0.8791088461875916,\n","  'word': '##ele'},\n"," {'entity': 'I-PER', 'index': 16, 'score': 0.9720047116279602, 'word': 'Fi'},\n"," {'entity': 'I-PER', 'index': 17, 'score': 0.697806715965271, 'word': '##th'},\n"," {'entity': 'I-PER',\n","  'index': 18,\n","  'score': 0.697088360786438,\n","  'word': '##rich'},\n"," {'entity': 'I-PER', 'index': 26, 'score': 0.9203088283538818, 'word': 'Á'},\n"," {'entity': 'I-PER', 'index': 27, 'score': 0.9416706562042236, 'word': '##ed'},\n"," {'entity': 'I-PER', 'index': 28, 'score': 0.9702795147895813, 'word': 'U'},\n"," {'entity': 'I-PER',\n","  'index': 29,\n","  'score': 0.8428962230682373,\n","  'word': '##ari'},\n"," {'entity': 'I-PER',\n","  'index': 31,\n","  'score': 0.7077912092208862,\n","  'word': '##ach'}]"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["txt = 'He was the son of Máel Dúin mac Máele Fithrich, and grandson of the high king Áed Uaridnach (died 612).'\n","ner_pipeline(txt)"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":792,"status":"ok","timestamp":1647767078594,"user":{"displayName":"Nadir Ounaggou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14687011903990117142"},"user_tz":-60},"id":"HhdvbovPBZmP","outputId":"16adda51-5829-46a0-8cef-3d8a97101c07"},"outputs":[{"name":"stdout","output_type":"stream","text":["Something might be wrong with your pipeline.\n"]}],"source":["# Apply your ner_pipeline to some sentences to see how it works,\n","# Then you can test your code with this snippet\n","text = 'He was the son of Máel Dúin mac Máele Fithrich, and grandson of the high king Áed Uaridnach (died 612).'\n","try:\n","  assert ner_pipeline(text) == [\n","                                {'entity': 'I-PER', 'index': 6, 'score': 0.982085645198822, 'word': 'M'},\n","                                {'entity': 'I-PER', 'index': 7, 'score': 0.8588606715202332, 'word': '##á'},\n","                                {'entity': 'I-PER', 'index': 8, 'score': 0.876600980758667, 'word': '##el'},\n","                                {'entity': 'I-PER', 'index': 9, 'score': 0.8375431299209595, 'word': 'D'},\n","                                {'entity': 'I-PER', 'index': 10, 'score': 0.4897184371948242, 'word': '##ú'},\n","                                {'entity': 'I-PER', 'index': 11, 'score': 0.9012535810470581, 'word': '##in'},\n","                                {'entity': 'I-PER', 'index': 12, 'score': 0.5821399688720703, 'word': 'mac'},\n","                                {'entity': 'I-PER', 'index': 13, 'score': 0.8884767889976501, 'word': 'M'},\n","                                {'entity': 'I-PER', 'index': 14, 'score': 0.7004088759422302, 'word': '##á'},\n","                                {'entity': 'I-PER', 'index': 15, 'score': 0.8791091442108154, 'word': '##ele'},\n","                                {'entity': 'I-PER', 'index': 16, 'score': 0.9720048308372498, 'word': 'Fi'},\n","                                {'entity': 'I-PER', 'index': 17, 'score': 0.6978078484535217, 'word': '##th'},\n","                                {'entity': 'I-PER', 'index': 18, 'score': 0.6970881223678589, 'word': '##rich'},\n","                                {'entity': 'I-PER', 'index': 26, 'score': 0.9203091859817505, 'word': 'Á'},\n","                                {'entity': 'I-PER', 'index': 27, 'score': 0.9416706562042236, 'word': '##ed'},\n","                                {'entity': 'I-PER', 'index': 28, 'score': 0.9702795147895813, 'word': 'U'},\n","                                {'entity': 'I-PER', 'index': 29, 'score': 0.8428964614868164, 'word': '##ari'},\n","                                {'entity': 'I-PER', 'index': 31, 'score': 0.707791805267334, 'word': '##ach'}\n","                                ]\n","  print(\"Good job!\")\n","except AssertionError:\n","  print(\"Something might be wrong with your pipeline.\") "]},{"cell_type":"markdown","metadata":{"id":"mOzSPqsJKkve"},"source":["#### Exercice 5\n","\n","\n","Nous pouvons finalement développer une pipeline NRE reposante sur notre modèle de NRE et notre pipeline NER. \n","\n","Écrivez ci-dessous une classe `NREPipeline` équipée (entre autres) d'une méthode `__call__(self, text)` qui prend un texte en entrée et effectue les opérations suivantes :\n","\n","- elle reconnaît les entités dans le texte\n","    - retenir seulement les deux entités auxquelles la pipeline NER associe la probabilité la plus élevée, écarter les autres (si presentes)\n","    - si la pipeline NER ne reconnaît qu’une seule entités dans le texte, `__call__(self, text)` retourne None (voir le test en bas) car il n’y a aucune relation à prédire\n","- elle donne en sortie une liste en format `[e1, e2, rel, p]` où :\n","    - `e1` est la première entité reconnue dans le texte (entre les deux plus probables, la première qui apparaître dans le texte)\n","    - `e2` est la deuxième entité  reconnue dans le texte (entre les deux plus probables, la deuxième qui apparaître dans le texte)\n","    - `rel` est la relation qu’il y a entre `e1` et `e2`\n","    - `p` est la probabilité associée à la relation `rel` par le modèle de NRE\n","\n","Pour vérifier la bonne qualité de votre classe `NREPipeline`, utilisez l’extrait de code ci-dessous. Le résultat devrait ressabler à celui-ci :\n","\n","````\n","Sentence 0: He was the son of Máel Dúin mac Máele Fithrich, and grandson of the high king Áed Uaridnach (died 612).\n","System out:  ['Máel Dúin mac Máele Fithrich', 'Áed Uari', 'father', 0.9923498034477234]\n","------------------------------\n","Sentence 1: He was the son of Máel Dúin\n","System out:  None\n","------------------------------\n","Sentence 2: Ōda is home to the Ōda Iwami Ginzan Silver Mine , a World Heritage Site .\n","System out:  ['Iwami Ginzan', 'World Heritage Site', 'heritage designation', 0.9991846680641174]\n","------------------------------\n","Sentence 3: It has been shown to be equally effective as leuprorelin , which is a second - line medication against endometriosis .\n","System out:  None\n","------------------------------\n","Sentence 4: Located at Earleville and listed on the National Register of Historic Places are : Bohemia Farm , Mount Harmon , Rose Hill , and St. Stephen 's Episcopal Church .\n","System out:  ['Earleville', \"St . Stephen ' s Episcopal Church\", 'location', 0.9127373099327087]\n","------------------------------\n","````"]},{"cell_type":"code","execution_count":65,"metadata":{"executionInfo":{"elapsed":189,"status":"ok","timestamp":1647773276937,"user":{"displayName":"Nadir Ounaggou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14687011903990117142"},"user_tz":-60},"id":"ToAxtF4nZ_Bq"},"outputs":[],"source":["# Write your pipeline in this cell. The fun begins here, because we are coding a whole Python class here !\n","from itertools import combinations\n","class NREPipeline(object):\n","  def __init__(self, ner_pipeline, nre_model):\n","    # ...\n","    self.ner = ner_pipeline\n","    self.nre = nre_model\n","\n","  # ...\n","\n","  def __call__(self, text):\n","    ner_output = ner_pipeline(text)\n","    # discard 'UNK'\n","    ner_output = [elem for elem in ner_output if elem['word'] != '[UNK]']\n","    index_word = [(i['index'], i['word']) for i in ner_output]\n","    # assemble entities from ner_output\n","    i = 1\n","    while i < len(index_word):\n","      if index_word[i -1][0] + 1 != index_word[i][0] or index_word[i][1][:2] != \"##\":\n","        index_word.insert(i, (index_word[i -1][0] + 1, ' '))\n","        i += 1\n","      i += 1\n","    entities = []\n","    start = 0\n","    for i in range(1, len(index_word)):\n","      if index_word[i - 1][1] == ' ' and index_word[i - 1][0] != index_word[i][0]:\n","        entities.append([index_word[j][1] for j in range(start, i - 1)])\n","        start = i\n","    \n","    entities.append([index_word[j][1] for j in range(start, len(index_word))])\n","    entities = [''.join(l).replace('##', '') for l in entities]\n","    entities = [''.join(l).replace(\" ' \", \" '\") for l in entities]\n","    entities = [''.join(l).replace(\" . \", \". \") for l in entities]\n","    res = (0, 0)\n","    if len(entities) > 1:\n","      for elem in combinations(entities, 2):\n","        # print(elem[0], '|', elem[1])\n","        item = to_input_format(text, elem[0], elem[1])\n","        if model.infer(item)[1] > res[1]:\n","          res = model.infer(item)\n","          elemres = elem\n","      if elem[0] == \"Earleville\" and elem[1] == \"St. Stephen 's Episcopal Church\":\n","        print(model.infer(item))\n","      return list(elemres + res)\n","    else:\n","      return None\n","    \n","   # ..."]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13273,"status":"ok","timestamp":1647767852088,"user":{"displayName":"Nadir Ounaggou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14687011903990117142"},"user_tz":-60},"id":"qaWrZEJc4IDK","outputId":"6e69a8db-3204-4214-fb4e-7b9b3378c315"},"outputs":[{"name":"stdout","output_type":"stream","text":["Sentence 0: He was the son of Máel Dúin mac Máele Fithrich, and grandson of the high king Áed Uaridnach (died 612).\n","System out:  ('Máel Dúin mac Máele Fithrich', 'Áed Uari', 'father', 0.9923498034477234)\n","------------------------------\n","Sentence 1: He was the son of Máel Dúin\n","System out:  None\n","------------------------------\n","Sentence 2: Ōda is home to the Ōda Iwami Ginzan Silver Mine , a World Heritage Site .\n","System out:  ('Iwami Ginzan', 'World Heritage Site', 'heritage designation', 0.9992959499359131)\n","------------------------------\n","Sentence 3: It has been shown to be equally effective as leuprorelin , which is a second - line medication against endometriosis .\n","System out:  None\n","------------------------------\n","Sentence 4: Located at Earleville and listed on the National Register of Historic Places are : Bohemia Farm , Mount Harmon , Rose Hill , and St. Stephen 's Episcopal Church .\n","System out:  ('Earleville', 'National Register of Historic Places', 'heritage designation', 0.9995023012161255)\n","------------------------------\n"]}],"source":["# Test your code with this snippet\n","\n","sequences = [\n","             'He was the son of Máel Dúin mac Máele Fithrich, and grandson of the high king Áed Uaridnach (died 612).', # Easy sentence\n","             'He was the son of Máel Dúin', # There is only one entity in this sentence, therefore our pipeline should return None\n","             'Ōda is home to the Ōda Iwami Ginzan Silver Mine , a World Heritage Site .', # Ōda is tokenized by the NER tokenizer as a \"[UNK]\" and it is detected as an entitity. For simplicity, you can discard [UNK] entities as if they were not detected.\n","             'It has been shown to be equally effective as leuprorelin , which is a second - line medication against endometriosis .', # the NER system can not recognise any entity here, therefore the pipeline should return None\n","             \"Located at Earleville and listed on the National Register of Historic Places are : Bohemia Farm , Mount Harmon , Rose Hill , and St. Stephen 's Episcopal Church .\" # This sentence is not trivial because the 's has to be managed properly\n","\n","]\n","\n","nre = NREPipeline(ner_pipeline, model)\n","for n, sequence in enumerate(sequences):\n","  out = nre(sequence)\n","  print(\"Sentence {0}: {1}\".format(n, sequence))\n","  print(\"System out: \", out)\n","  print('------------------------------')"]},{"cell_type":"markdown","metadata":{"id":"sl-hqEfaLvI-"},"source":["## Application de le pipeline"]},{"cell_type":"markdown","metadata":{"id":"aKfvPq_KLmD-"},"source":["#### Exercice 6\n","\n","1. Appliquez la pipeline NRE aux phrases contenues dans le fichier _sentences.txt_, qui ont étées extraites à partir de Wikipedia et Wikidata.\n","\n","2. Donnez un avis qualitatif sur sa performance, les problèmes rencontrés ainsi que des idées pour améliorations des résultats (e.g. entraînement sur des données différentes, modèle différent, etc.).\n","\n","3. Appliquez la pipeline NRE aux premières 50 phrases contenues dans le fichier _Sentences_AllAgree.txt_ que vous avez utilisé pour  TP BERT, qui parlent d’événements financiers\n","\n","4. Remarquez-vous des différences en terme de performances par rapport à la question 2 ? Pourquoi ? Commentez…"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4T2moXc3IA3f"},"outputs":[],"source":["# Write your code here and then write your detailed answers below. Do not hesitate to use more code cells if needed"]},{"cell_type":"code","execution_count":39,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2576,"status":"ok","timestamp":1647768241487,"user":{"displayName":"Nadir Ounaggou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14687011903990117142"},"user_tz":-60},"id":"q142iK_OZGbV","outputId":"c0fa50e0-3ef3-40d9-d244-6a36ba5b9b29"},"outputs":[{"name":"stdout","output_type":"stream","text":["[{'word': 'I', 'score': 0.6765465140342712, 'entity': 'I-MISC', 'index': 3}, {'word': '-', 'score': 0.5596017837524414, 'entity': 'I-MISC', 'index': 4}, {'word': '5', 'score': 0.7006650567054749, 'entity': 'I-MISC', 'index': 5}, {'word': 'Walter', 'score': 0.4088774025440216, 'entity': 'I-PER', 'index': 8}, {'word': 'W', 'score': 0.6508683562278748, 'entity': 'I-LOC', 'index': 9}, {'word': '##irt', 'score': 0.23423130810260773, 'entity': 'I-ORG', 'index': 10}, {'word': '##h', 'score': 0.35906338691711426, 'entity': 'I-ORG', 'index': 11}, {'word': 'Lake', 'score': 0.8282280564308167, 'entity': 'I-LOC', 'index': 12}, {'word': 'M', 'score': 0.8583234548568726, 'entity': 'I-LOC', 'index': 14}, {'word': '##c', 'score': 0.7494085431098938, 'entity': 'I-LOC', 'index': 15}, {'word': '##N', 'score': 0.4825979471206665, 'entity': 'I-LOC', 'index': 16}, {'word': '##ary', 'score': 0.7962921261787415, 'entity': 'I-LOC', 'index': 17}, {'word': 'Field', 'score': 0.9498450756072998, 'entity': 'I-LOC', 'index': 18}, {'word': 'Salem', 'score': 0.9683857560157776, 'entity': 'I-LOC', 'index': 20}, {'word': 'Municipal', 'score': 0.9484637379646301, 'entity': 'I-LOC', 'index': 21}, {'word': 'Airport', 'score': 0.9657371044158936, 'entity': 'I-LOC', 'index': 22}, {'word': 'Four', 'score': 0.9253845810890198, 'entity': 'I-LOC', 'index': 37}, {'word': 'Corner', 'score': 0.9598390460014343, 'entity': 'I-LOC', 'index': 38}, {'word': '##s', 'score': 0.9893515706062317, 'entity': 'I-LOC', 'index': 39}]\n","[(3, 'I'), (4, ' '), (4, '-'), (5, ' '), (5, '5'), (6, ' '), (8, 'Walter'), (9, ' '), (9, 'W'), (10, '##irt'), (11, '##h'), (12, ' '), (12, 'Lake'), (13, ' '), (14, 'M'), (15, '##c'), (16, '##N'), (17, '##ary'), (18, ' '), (18, 'Field'), (19, ' '), (20, 'Salem'), (21, ' '), (21, 'Municipal'), (22, ' '), (22, 'Airport'), (23, ' '), (37, 'Four'), (38, ' '), (38, 'Corner'), (39, '##s')]\n","['I - 5', 'Walter Wirth Lake', 'McNary Field', 'Salem Municipal Airport', 'Four Corners']\n"]}],"source":["txt = \"Along the I-5 stretch , Walter Wirth Lake and McNary Field ( Salem Municipal Airport ) are on the left ; near Route 22 , the unincorporated neighborhood of Four Corners is on the right .\"\n","ner_output = ner_pipeline(txt)\n","ner_output = [elem for elem in ner_output if elem['word'] != '[UNK]']\n","lm = [(i['index'], i['word']) for i in ner_output]\n","i = 1\n","while i < len(lm):\n","  # print(lm[i - 1][0], lm[i][0])\n","  if lm[i -1][0] + 1 != lm[i][0] or lm[i][1][:2] != \"##\":\n","    lm.insert(i, (lm[i -1][0] + 1, ' '))\n","    i += 1\n","  i += 1\n","lf = []\n","idx = 0\n","for i in range(1, len(lm)):\n","  if lm[i - 1][1] == ' ' and lm[i - 1][0] != lm[i][0]:\n","    lf.append([lm[j][1] for j in range(idx, i - 1)])\n","    idx = i\n","lf.append([lm[j][1] for j in range(idx, len(lm))])\n","lf = [''.join(l).replace('##', '') for l in lf]\n","lf = [''.join(l).replace(\" ' \", \" '\") for l in lf]\n","lf = [''.join(l).replace(\" . \", \". \") for l in lf]\n","print(ner_pipeline(txt))\n","print(lm)\n","print(lf)"]},{"cell_type":"code","execution_count":69,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":183332,"status":"ok","timestamp":1647773881204,"user":{"displayName":"Nadir Ounaggou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14687011903990117142"},"user_tz":-60},"id":"RYyYlIx3oE4y","outputId":"8d7b8b45-e4c8-42fc-befd-3bf12d1b20bc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Sentence 1: The Willard and Josephine Hubbard House was individually listed on the National Register of Historic Places in 2016 .\n","\n","System out:  ['Josephine Hubbard House', 'National Register of Historic Places', 'heritage designation', 0.9995538592338562]\n","------------------------------\n","Sentence 2: His station commander , Group Captain Claude Hilton Keith , found a letter among the missing airman 's personal possessions .\n","\n","System out:  None\n","------------------------------\n","Sentence 3: One was Quintus Caecilius Metellus Creticus , who was praetor in 74 BC and consul in 69 BC .\n","\n","System out:  None\n","------------------------------\n","Sentence 4: April 2009 In addition to musical acts , the label recorded beat poets Lawrence Ferlinghetti and Allen Ginsberg and comic Lenny Bruce .\n","\n","System out:  ['Lawrence Ferlinghetti', 'Lenny Bruce', 'sibling', 0.828484058380127]\n","------------------------------\n","Sentence 5: Walter Neusel ( November 25 , 1907 â October 3 , 1964 ) was a German heavyweight boxer .\n","\n","System out:  ['Walter Neusel', 'German', 'country of citizenship', 0.9982714653015137]\n","------------------------------\n","Sentence 6: HÃ©rcules debut defending the national team was a 1938 FIFA World Cup game , played on June 5 , 1938 , against Poland .\n","\n","System out:  ['FIFA World Cup', 'Poland', 'participating team', 0.9968666434288025]\n","------------------------------\n","Sentence 8: Michael Bradley and Landon Donovan scored the United States ' two goals in the match .\n","\n","System out:  ['Landon Donovan', 'United States', 'country of citizenship', 0.9977351427078247]\n","------------------------------\n","Sentence 9: The film was remade in Hindi as \" Love Ke Liye Kuch Bhi Karega \" and is loosely based on the American film \" Ruthless People \" .\n","\n","System out:  ['Hindi', 'Love Ke Liye Kuch Bhi Karega', 'original language of film or TV show', 0.9980554580688477]\n","------------------------------\n","Sentence 10: Incorporated in 1988 , Vertex Venture Holdings is based in Singapore , with offices Southeast Asia , Silicon Valley , China , India , Israel , and Taiwan .\n","\n","System out:  ['Vertex Venture Holdings', 'Singapore', 'headquarters location', 0.9967149496078491]\n","------------------------------\n","Sentence 11: Anna Caterina Antonacci , ( born 5 April 1961 ) is an Italian soprano known for roles in the bel canto and Baroque repertories .\n","\n","System out:  ['Anna Caterina Antonacci', 'Baroque', 'movement', 0.9981166124343872]\n","------------------------------\n","Sentence 12: On 2 April 2017 the former municipalities of Cresciano , Iragna and Osogna merged into the new municipality of Riviera .\n","\n","System out:  ['Osogna', 'Riviera', 'located in the administrative territorial entity', 0.9483221173286438]\n","------------------------------\n","Sentence 13: Dimitar Ivanov Makriev (; born 7 January 1984 ) is a Bulgarian footballer who currently plays as a forward for Cypriot First Division side Nea Salamina Famagusta .\n","\n","System out:  ['Dimitar Ivanov Makriev', 'Bulgarian', 'country of citizenship', 0.9971875548362732]\n","------------------------------\n","Sentence 14: The 23d Fighter Group was assigned to the 347th Wing of Air Combat Command at Moody Air Force Base , Georgia but the group remained at Pope as a Geographically Separated Unit ( GSU ) .\n","\n","System out:  ['23d Fighter Group', 'Unit', 'instance of', 0.9977903366088867]\n","------------------------------\n","Sentence 15: \" Ð \" Ð³ÑÑÐ¿Ð° , 2012/13 , 16 ÐºÑÑÐ³ , 01.03.2013 15:30 Stachowiak participated in all games of the club in Europa League during seasons 2013 - 14 and 2014 - 15 .\n","\n","System out:  ['Stachowiak', 'Europa League', 'league', 0.9759933352470398]\n","------------------------------\n","Sentence 16: Dartnell offered his services to the British Army on the outbreak of the First World War , and was commissioned into the 25th ( Frontiersmen ) Battalion , Royal Fusiliers in February 1915 .\n","\n","System out:  ['Dartnell', 'British Army', 'military branch', 0.9985640645027161]\n","------------------------------\n","Sentence 17: In September 1260 , the two sides met in the plains south of Nazareth in a major confrontation known as the Battle of Ain Jalut . Cummins 2011 , p. 80 .\n","\n","System out:  ['Battle of Ain Jalut', 'Cummins', 'participant', 0.9975071549415588]\n","------------------------------\n","Sentence 18: Sir Hugh de Morville(d.1202 ) fled to the house after taking part as 1 of 4 knights in the murder on 29 December 1170 of Thomas Becket , Archbishop of Canterbury .\n","\n","System out:  ['Thomas Becket', 'Canterbury', 'work location', 0.9825677275657654]\n","------------------------------\n","Sentence 19: The claim was made in 1264 as senior descendant and rightful heir of Alice of Champagne , second daughter of Queen Isabella I , Hugh being the son of their eldest daughter .\n","\n","System out:  ['Alice', 'Isabella', 'mother', 0.9984573125839233]\n","------------------------------\n","Sentence 20: The Elected Member is a Booker Prize - winning novel by Welsh writer Bernice Rubens .\n","\n","System out:  ['Booker Prize', 'Bernice Rubens', 'winner', 0.9977321624755859]\n","------------------------------\n","Sentence 21: He currently serves as an Offensive Skills coach at the Brisbane Lions , and also as an assistant coach of the Lions ' NEAFL reserves team .\n","\n","System out:  ['Brisbane Lions', 'NEAFL', 'league', 0.9975814819335938]\n","------------------------------\n","Sentence 22: In 2008 he produced , alongside Christian Colson , the critically acclaimed feature film \" Eden Lake \" ( 2008 ) , written and directed by James Watkins .\n","\n","System out:  ['Christian Colson', 'Eden Lake', 'notable work', 0.9960183501243591]\n","------------------------------\n","Sentence 23: The West Middlesex Waterworks Company was founded in 1806 to supply water to the Marylebone and Paddington areas of London .\n","\n","System out:  ['West Middlesex Waterworks Company', 'Paddington', 'location', 0.9922093152999878]\n","------------------------------\n","Sentence 24: Neutraface is a geometric sans - serif typeface designed by Christian Schwartz for House Industries , an American digital type foundry .\n","\n","System out:  ['Neutraface', 'American', 'country of origin', 0.997370719909668]\n","------------------------------\n","Sentence 25: The APG II states that Alangiaceae is a synonym of Cornaceae ( the Dogwood family ) , but still recognizes it as a \" nom .\n","\n","System out:  ['Alangiaceae', 'Dogwood', 'taxon rank', 0.9884356260299683]\n","------------------------------\n","Sentence 26: But because CKGM Montreal is the dominant class A station on 690 , CBU must use a directional signal to avoid causing interference .\n","\n","System out:  ['CKGM Montreal', 'CBU', 'licensed to broadcast to', 0.9959573149681091]\n","------------------------------\n","Sentence 27: It takes place when a quark of one hadron and an antiquark of another hadron annihilate , creating a virtual photon or Z boson which then decays into a pair of oppositely - charged leptons .\n","\n","System out:  None\n","------------------------------\n","Sentence 28: The first \" Uncle Slam \" album was \" Say Uncle \" , released in 1988 through Caroline Records .\n","\n","System out:  ['Uncle Slam', 'Caroline Records', 'record label', 0.9990322589874268]\n","------------------------------\n","Sentence 30: The Church of The Epiphany was designed by noted Philadelphia architect Thomas Ustick Walter in the Greek Revival style .\n","\n","System out:  ['Thomas Ustick Walter', 'Greek Revival', 'movement', 0.997984766960144]\n","------------------------------\n","Sentence 31: Meaker Food Company Warehouse , Harriet May Mills House , St. Paul 's Armenian Apostolic Church , Alton Simmons House , and West Brothers Knitting Company are listed on the National Register of Historic Places .\n","\n","System out:  ['West Brothers Knitting Company', 'National Register of Historic Places', 'heritage designation', 0.9995450377464294]\n","------------------------------\n","Sentence 32: This appointment was harshly criticized by Fiji Labour Party leader Mahendra Chaudhry .\n","\n","System out:  ['Fiji Labour Party', 'Mahendra Chaudhry', 'member of political party', 0.9914173483848572]\n","------------------------------\n","Sentence 33: In the summer of 2007 , Varea joined Deportivo EspaÃ±ol in the third division , where he played 11 matches and scored two goals until December 2007 .\n","\n","System out:  ['Varea', 'Deportivo', 'occupant', 0.31711703538894653]\n","------------------------------\n","Sentence 34: \" Aparajito \" was preceded by \" Pather Panchali \" ( 1955 ) and followed by \" Apur Sansar \" ( \" The World of Apu \" ) in 1959 .\n","\n","System out:  ['Aparajito', 'Pather Panchali', 'follows', 0.9626705050468445]\n","------------------------------\n","Sentence 35: NeÄe rijeka zrakom teÄi is the second studio album by Croatian rock band Silente .\n","\n","System out:  ['N', 'Silente', 'performer', 0.9820192456245422]\n","------------------------------\n","Sentence 36: This project was heavily opposed by the Apulian governor Michele Emiliano . Gasdotto Tap , il governo tira dritto dopo il no del Mibac .\n","\n","System out:  ['Michele Emiliano', 'Mibac', 'member of political party', 0.99796462059021]\n","------------------------------\n","Sentence 38: Sprinkling Tarn is a body of water at the foot of Great End , in the Southern Fells in Lake District , 3 Â  km from Seathwaite , Cumbria , England .\n","\n","System out:  ['rinkling Tarn', 'England', 'country', 0.9937072396278381]\n","------------------------------\n","Sentence 39: Michel made her WTA tour debut at the 2013 Internationaux de Strasbourg , partnering Claire Feuerstein in doubles .\n","\n","System out:  ['WTA', 'Internationaux de Strasbourg', 'location', 0.9495422840118408]\n","------------------------------\n","Sentence 40: He took part in the Council of Agde in 506 , where 34 Catholic bishops of the Visigothic kingdom met under the chairmanship of Saint Caesarius of Arles .\n","\n","System out:  ['Catholic', 'Caesarius', 'religion', 0.9989388585090637]\n","------------------------------\n","Sentence 41: A license obtained from the British Motor Corporation led to the Siam di Tella 1500 ; based on the British BMC Farina series of the late 1950s .\n","\n","System out:  ['British Motor Corporation', 'Siam di Tella 1500', 'manufacturer', 0.9976040720939636]\n","------------------------------\n","Sentence 43: Hot 2Nite was produced by Ryan Leslie initially for New Edition 's album , One Love , released in 2004 under the label Bad Boy Records .\n","\n","System out:  ['Ryan Leslie', 'Bad Boy Records', 'record label', 0.9988422989845276]\n","------------------------------\n","Sentence 44: SN 1996ah was a supernova located in the spiral galaxy NGC 5640 in the constellation of Camelopardalis .\n","\n","System out:  ['S', 'Camelopardalis', 'constellation', 0.9993067979812622]\n","------------------------------\n","Sentence 45: She made her debut at The Proms in 2000 , singing Mozart 's Mass in C minor and Alban Berg 's \" Altenberg Lieder \" with the Bochumer Symphoniker , conducted by Simon Rattle .\n","\n","System out:  ['Mozart', 'Alban Berg', 'composer', 0.9975906610488892]\n","------------------------------\n","Sentence 46: The Albanian Wikipedia ( ) is the Albanian language edition of Wikipedia started on October 12 , 2003 .\n","\n","System out:  ['Albanian Wikipedia', 'Albanian', 'language of work or name', 0.9848596453666687]\n","------------------------------\n","Sentence 47: For her performance in this episode , Elaine Stritch received a Primetime Emmy Award nomination in the category for Outstanding Guest Actress in a Comedy Series .\n","\n","System out:  ['Outstanding', 'Comedy Series', 'nominated for', 0.9826334118843079]\n","------------------------------\n","Sentence 48: He later worked as a journalist for the French language paper \" Le Matin \" .\n","\n","System out:  ['French', 'Le Matin', 'language of work or name', 0.9966747760772705]\n","------------------------------\n","Sentence 49: Loughton to Epping became part of the London Underground Central line on 25 September 1949 , leaving the single track line from Epping to Ongar as the last steam - worked section .\n","\n","System out:  ['London Underground Central', 'Ongar', 'has part', 0.9327189326286316]\n","------------------------------\n","Sentence 50: Though Vivekananda gave up the idea of becoming Pavhari Baba 's disciple after seeing Ramakrishna 's melancholy face in his dream the night before his religious initiation , Baba deeply influenced him .\n","\n","System out:  ['Vivekananda', 'Pavhari Baba', 'notable work', 0.9692802429199219]\n","------------------------------\n","la précision moyenne est : 0.9703475070554156\n"]}],"source":["fname = '../../../../content/sentences.txt'\n","f = open(fname, 'rt', encoding=\"ISO-8859-1\")\n","n = 1\n","nb_sambles = 46\n","mean_proba = 0\n","nre = NREPipeline(ner_pipeline, model)\n","for line in f:\n","  # On élimine 4 phrases qui créent des problèmes, et ne passent pas dans l'algo\n","  if n not in (7, 29, 37, 42):\n","    out = nre(line)\n","    print(\"Sentence {0}: {1}\".format(n, line))\n","    print(\"System out: \", out)\n","    print('------------------------------')\n","    if out != None:\n","      mean_proba += out[3]\n","    else:\n","      nb_sambles -= 1\n","  n += 1\n","mean_proba /= nb_sambles\n","print('la précision moyenne est :', mean_proba)"]},{"cell_type":"code","execution_count":71,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":223375,"status":"ok","timestamp":1647774474301,"user":{"displayName":"Nadir Ounaggou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14687011903990117142"},"user_tz":-60},"id":"gE_5ADfgukUM","outputId":"1ac97301-811f-4837-ee25-da703d68c6e5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Sentence 1: According to Gran , the company has no plans to move all production to Russia , although that is where the company is growing .@neutral\n","\n","System out:  ['Gran', 'Russia', 'owned by', 0.881830096244812]\n","------------------------------\n","Sentence 2: For the last quarter of 2010 , Componenta 's net sales doubled to EUR131m from EUR76m for the same period a year earlier , while it moved to a zero pre-tax profit from a pre-tax loss of EUR7m .@positive\n","\n","System out:  ['EU', 'EU', 'applies to jurisdiction', 0.8518947958946228]\n","------------------------------\n","Sentence 3: In the third quarter of 2010 , net sales increased by 5.2 % to EUR 205.5 mn , and operating profit by 34.9 % to EUR 23.5 mn .@positive\n","\n","System out:  ['EU', 'EU', 'member of', 0.6252642869949341]\n","------------------------------\n","Sentence 4: Operating profit rose to EUR 13.1 mn from EUR 8.7 mn in the corresponding period in 2007 representing 7.7 % of net sales .@positive\n","\n","System out:  ['EU', 'EU', 'applies to jurisdiction', 0.3409990072250366]\n","------------------------------\n","Sentence 5: Operating profit totalled EUR 21.1 mn , up from EUR 18.6 mn in 2007 , representing 9.7 % of net sales .@positive\n","\n","System out:  ['EU', 'EU', 'member of', 0.3967757821083069]\n","------------------------------\n","Sentence 6: Finnish Talentum reports its operating profit increased to EUR 20.5 mn in 2005 from EUR 9.3 mn in 2004 , and net sales totaled EUR 103.3 mn , up from EUR 96.4 mn .@positive\n","\n","System out:  ['Finnish Talentum', 'EU', 'owned by', 0.6705114245414734]\n","------------------------------\n","Sentence 7: Clothing retail chain Sepp+ï¿½l+ï¿½ 's sales increased by 8 % to EUR 155.2 mn , and operating profit rose to EUR 31.1 mn from EUR 17.1 mn in 2004 .@positive\n","\n","System out:  ['EU', 'EU', 'applies to jurisdiction', 0.9792049527168274]\n","------------------------------\n","Sentence 8: Consolidated net sales increased 16 % to reach EUR74 .8 m , while operating profit amounted to EUR0 .9 m compared to a loss of EUR0 .7 m in the prior year period .@positive\n","\n","System out:  ['EU', 'EU', 'has part', 0.47248727083206177]\n","------------------------------\n","Sentence 9: Foundries division reports its sales increased by 9.7 % to EUR 63.1 mn from EUR 57.5 mn in the corresponding period in 2006 , and sales of the Machine Shop division increased by 16.4 % to EUR 41.2 mn from EUR 35.4 mn in the corresponding period in 2006 .@positive\n","\n","System out:  ['Foundries', 'EU', 'subsidiary', 0.8531225323677063]\n","------------------------------\n","Sentence 10: HELSINKI ( AFX ) - Shares closed higher , led by Nokia after it announced plans to team up with Sanyo to manufacture 3G handsets , and by Nokian Tyres after its fourth-quarter earnings report beat analysts ' expectations , dealers said .@positive\n","\n","System out:  ['ELSINK', 'Nokia', 'owned by', 0.9196527600288391]\n","------------------------------\n","Sentence 11: Its board of directors will propose a dividend of EUR0 .12 per share for 2010 , up from the EUR0 .08 per share paid in 2009 .@positive\n","\n","System out:  ['EU', 'EU', 'has part', 0.9053260087966919]\n","------------------------------\n","Sentence 12: MegaFon 's subscriber base increased 16.1 % in 2009 to 50.5 million users as of December 31 , while its market share by the number of customers amounted to 24 % as of late 2009 , up from 23 % as of late 2008 , according to TeliaSonera estimates .@positive\n","\n","System out:  ['MegaFon', 'TeliaSonera', 'owned by', 0.9980899691581726]\n","------------------------------\n","Sentence 13: Net income from life insurance doubled to EUR 6.8 mn from EUR 3.2 mn , and net income from non-life insurance rose to EUR 5.2 mn from EUR 1.5 mn in the corresponding period in 2009 .@positive\n","\n","System out:  ['EU', 'EU', 'applies to jurisdiction', 0.6576498746871948]\n","------------------------------\n","Sentence 14: Net sales increased to EUR193 .3 m from EUR179 .9 m and pretax profit rose by 34.2 % to EUR43 .1 m. ( EUR1 = USD1 .4 )@positive\n","\n","System out:  ['EU', 'EU', 'has part', 0.6302096843719482]\n","------------------------------\n","Sentence 15: Net sales surged by 18.5 % to EUR167 .8 m. Teleste said that EUR20 .4 m , or 12.2 % , of the sales came from the acquisitions made in 2009 .@positive\n","\n","System out:  ['EU', 'Teleste', 'owned by', 0.9832639098167419]\n","------------------------------\n","Sentence 16: Nordea Group 's operating profit increased in 2010 by 18 percent year-on-year to 3.64 billion euros and total revenue by 3 percent to 9.33 billion euros .@positive\n","\n","System out:  None\n","------------------------------\n","Sentence 17: Operating profit for the nine-month period increased from EUR13 .6 m , while net sales increased from EUR394 .7 m , as compared to the corresponding period in 2005 .@positive\n","\n","System out:  ['EU', 'EU', 'has part', 0.6604467630386353]\n","------------------------------\n","Sentence 18: Operating profit for the three-month period increased from EUR1 .2 m , while revenue increased from EUR20 .2 m , as compared to the corresponding period in 2005 .@positive\n","\n","System out:  ['EU', 'EU', 'member of', 0.4905962347984314]\n","------------------------------\n","Sentence 19: The company 's net profit rose 11.4 % on the year to 82.2 million euros in 2005 on sales of 686.5 million euros , 13.8 % up on the year , the company said earlier .@positive\n","\n","System out:  None\n","------------------------------\n","Sentence 21: Viking Line 's cargo revenue increased by 5.4 % to EUR 21.46 mn , and cargo volume increased by 2.4 % to 70,116 cargo units .@positive\n","\n","System out:  ['Viking Line', 'EU', 'subsidiary', 0.28862079977989197]\n","------------------------------\n","Sentence 22: The fair value of the property portfolio doubled as a result of the Kapiteeli acquisition and totalled EUR 2,686.2 1,259.7 million .@positive\n","\n","System out:  ['Kapiteeli', 'EU', 'subsidiary', 0.9218896627426147]\n","------------------------------\n","Sentence 23: 10 February 2011 - Finnish media company Sanoma Oyj HEL : SAA1V said yesterday its 2010 net profit almost tripled to EUR297 .3 m from EUR107 .1 m for 2009 and announced a proposal for a raised payout .@positive\n","\n","System out:  ['Sanoma Oyj HEL', 'SAA1V', 'owned by', 0.9930821061134338]\n","------------------------------\n","Sentence 24: A Helsinki : ELIiV today reported EPS of EUR1 .13 for 2009 , an increase over EPS of EUR1 .12 in 2008 .@positive\n","\n","System out:  ['Helsinki', 'ELIiV', 'headquarters location', 0.9890927076339722]\n","------------------------------\n","Sentence 25: Commission income increased by 22 % to EUR 4.4 mn , and lending volume rose by 13.5 % .@positive\n","\n","System out:  None\n","------------------------------\n","Sentence 26: In January , traffic , measured in revenue passenger kilometres RPK , went up by 3.2 % and capacity , measured in available seat kilometres ASK , rose by 12.2 % .@positive\n","\n","System out:  None\n","------------------------------\n","Sentence 27: In January-September 2010 , Fiskars ' net profit went up by 14 % year-on-year to EUR 65.4 million and net sales to EUR 525.3 million from EUR 487.7 million .@positive\n","\n","System out:  ['Fiskars', 'EU', 'owned by', 0.6901155710220337]\n","------------------------------\n","Sentence 28: Net income from life insurance rose to EUR 16.5 mn from EUR 14.0 mn , and net income from non-life insurance to EUR 22.6 mn from EUR 15.2 mn in 2009 .@positive\n","\n","System out:  ['EU', 'EU', 'applies to jurisdiction', 0.7869088649749756]\n","------------------------------\n","Sentence 29: Sales have risen in other export markets .@positive\n","\n","System out:  None\n","------------------------------\n","Sentence 30: Sales increased due to growing market rates and increased operations .@positive\n","\n","System out:  None\n","------------------------------\n","Sentence 31: The agreement strengthens our long-term partnership with Nokia Siemens Networks .@positive\n","\n","System out:  None\n","------------------------------\n","Sentence 32: The company 's order book stood at 1.5 bln euro $ 2.2 bln on September 30 , 2007 , up by 24.2 pct on the year , with international orders amounting to 365 mln euro $ 534.3 mln .@positive\n","\n","System out:  None\n","------------------------------\n","Sentence 33: The company said that paper demand increased in all of its main markets , including of publication papers , and that it increased average paper prices by 4 percent compared with last year .@positive\n","\n","System out:  None\n","------------------------------\n","Sentence 34: The world 's second largest stainless steel maker said net profit in the three-month period until Dec. 31 surged to euro603 million US$ 781 million , or euro3 .33 US$ 4.31 per share , from euro172 million , or euro0 .94 per share , the previous year .@positive\n","\n","System out:  ['US', 'US', 'instance of', 0.4733259975910187]\n","------------------------------\n","Sentence 35: Shares of Standard Chartered ( STAN ) rose 1.2 % in the FTSE 100 , while Royal Bank of Scotland ( RBS ) shares rose 2 % and Barclays shares ( BARC ) ( BCS ) were up 1.7 % .@positive\n","\n","System out:  ['Standard Chartered', 'RBS', 'subsidiary', 0.9930809140205383]\n","------------------------------\n","Sentence 36: Shares of Nokia Corp. rose Thursday after the cell phone maker said its third-quarter earnings almost doubled and its share of the global handset market increased .@positive\n","\n","System out:  None\n","------------------------------\n","Sentence 37: In its financial report , published on Friday , SEB said its net profit soared to SEK6 .745 bn in 2010 from a year-earlier SEK1 .114 bn and proposed a 50 % dividend increase to SEK1 .50 per share .@positive\n","\n","System out:  ['SEB', 'SE', 'subsidiary', 0.9945185780525208]\n","------------------------------\n","Sentence 39: STOCK EXCHANGE ANNOUNCEMENT 20 July 2006 1 ( 1 ) BASWARE SHARE SUBSCRIPTIONS WITH WARRANTS AND INCREASE IN SHARE CAPITAL A total of 119 850 shares have been subscribed with BasWare Warrant Program .@neutral\n","\n","System out:  ['Bas', 'are', 'operating system', 0.8845176696777344]\n","------------------------------\n","Sentence 40: A maximum of 666,104 new shares can further be subscribed for by exercising B options under the 2004 stock option plan .@neutral\n","\n","System out:  None\n","------------------------------\n","Sentence 41: Tiimari operates 194 stores in six countries -- including its core Finnish market -- and generated a turnover of 76.5 mln eur in 2005 .@neutral\n","\n","System out:  ['Tiimari', 'Finnish', 'owned by', 0.5955591797828674]\n","------------------------------\n","Sentence 42: The acquisition will considerably increase Kemira 's sales and market position in the Russian metal industry coatings market .@positive\n","\n","System out:  ['Kemira', 'Russian', 'owned by', 0.4899732172489166]\n","------------------------------\n","Sentence 43: In January-September 2007 , Finnlines ' net sales rose to EUR 505.4 mn from EUR 473.5 mn in the corresponding period in 2006 .@positive\n","\n","System out:  ['EU', 'EU', 'applies to jurisdiction', 0.9113056063652039]\n","------------------------------\n","Sentence 44: Adjusted for changes in the Group structure , the Division 's net sales increased by 1.7 % .@positive\n","\n","System out:  None\n","------------------------------\n","Sentence 45: 4 February 2011 - Finnish broadband data communication systems provider Teleste Oyj HEL : TLT1V saw its net profit jump to EUR2 .1 m for the last quarter of 2010 from EUR995 ,000 for the same period of 2009 .@positive\n","\n","System out:  ['Teleste Oyj HEL', 'TLT1V', 'subsidiary', 0.9209908843040466]\n","------------------------------\n","Sentence 46: Finnish Aktia Group 's operating profit rose to EUR 17.5 mn in the first quarter of 2010 from EUR 8.2 mn in the first quarter of 2009 .@positive\n","\n","System out:  ['EU', 'EU', 'has part', 0.695516049861908]\n","------------------------------\n","Sentence 48: Finnish financial group Aktia reports operating profit of EUR 44.4 mn in January-September 2009 , up from EUR 37.3 mn in the corresponding period in 2008 .@positive\n","\n","System out:  ['Finnish', 'Aktia', 'owned by', 0.9477015733718872]\n","------------------------------\n","Sentence 49: Finnish high technology provider Vaahto Group reports net sales of EUR 41.8 mn in the accounting period September 2007 - February 2008 , an increase of 11.2 % from a year earlier .@positive\n","\n","System out:  ['Vaahto Group', 'EU', 'subsidiary', 0.9379241466522217]\n","------------------------------\n","Sentence 51: Biohit already services many current Genesis customers and the customer base is expected to expand as a result of this agreement .@positive\n","\n","System out:  ['Biohit', 'Genesis', 'developer', 0.7340360283851624]\n","------------------------------\n","Sentence 52: Both operating profit and turnover for the three-month period increased , respectively from EUR0 .9 m and EUR8 .3 m , as compared to the corresponding period in 2005 .@positive\n","\n","System out:  ['EU', 'EU', 'member of', 0.6839923858642578]\n","------------------------------\n","Sentence 53: Circulation revenue has increased by 5 % in Finland and 4 % in Sweden in 2008 .@positive\n","\n","System out:  ['Finland', 'Sweden', 'part of', 0.8563876152038574]\n","------------------------------\n","Sentence 54: Clothing chain Sepp+ï¿½l+ï¿½ 's net sales increased by 7.0 % to EUR 30.8 mn .@positive\n","\n","System out:  None\n","------------------------------\n","Sentence 55: Construction volumes meanwhile grow at a rate of 10-15 percent annually .@positive\n","\n","System out:  None\n","------------------------------\n","Sentence 56: However , Biohit estimates its total net sales will continue to grow in 2009 , and that favourable trends in net sales will lead to a profit in 2009 .@positive\n","\n","System out:  None\n","------------------------------\n","Sentence 57: In 2009 , Fiskars ' cash flow from operating activities amounted to EUR121m , up from EUR97m in the previous year .@positive\n","\n","System out:  ['Fiskars', 'EU', 'owned by', 0.896958589553833]\n","------------------------------\n","Sentence 58: In Lithuania , operating profit rose to EUR 190,000 from EUR 70,000 in the corresponding period in 2005 .@positive\n","\n","System out:  ['EU', 'EU', 'has part', 0.5818565487861633]\n","------------------------------\n","Sentence 59: In the fourth quarter of 2008 , net sales increased by 2 % to EUR 1,050.7 mn from EUR 1,027.0 mn in the fourth quarter of 2007 .@positive\n","\n","System out:  ['EU', 'EU', 'member of', 0.7471012473106384]\n","------------------------------\n","Sentence 60: International sales rose by 59.8 % to EUR 1,244.4 mn .@positive\n","\n","System out:  None\n","------------------------------\n","Sentence 61: Net sales grew in the period to  x20ac 402 million $ 585US million from  x20ac 401 million in 2006 .@positive\n","\n","System out:  None\n","------------------------------\n","Sentence 62: Net sales increased to EUR655m in April to June 2010 from EUR438m a year earlier .@positive\n","\n","System out:  ['EU', 'EU', 'has part', 0.5720096230506897]\n","------------------------------\n","Sentence 63: Net sales rose by 25.5 % year-on-year to EUR59 .6 m , as the number of chargers delivered went up by 41 % to 65.9 million pieces .@positive\n","\n","System out:  None\n","------------------------------\n","Sentence 64: Net sales totaled EUR 93.6 mn , up from EUR 93.2 mn in the corresponding period in 2005 .@positive\n","\n","System out:  ['EU', 'EU', 'member of', 0.5256420969963074]\n","------------------------------\n","Sentence 65: Operating profit increased by 145.1 % to EUR 8.3 mn from EUR 3.4 mn .@positive\n","\n","System out:  ['EU', 'EU', 'applies to jurisdiction', 0.4564551115036011]\n","------------------------------\n","Sentence 66: Operating profit margin increased from 11.2 % to 11.7 % .@positive\n","\n","System out:  None\n","------------------------------\n","Sentence 67: Operating profit rose to EUR 3.11 mn from EUR 1.22 mn in the corresponding period in 2009 .@positive\n","\n","System out:  ['EU', 'EU', 'applies to jurisdiction', 0.42612963914871216]\n","------------------------------\n","Sentence 68: Operating profit rose to EUR 5mn from EUR 2.8 mn in the fourth quarter of 2008 .@positive\n","\n","System out:  ['EU', 'EU', 'member of', 0.6273043751716614]\n","------------------------------\n","Sentence 69: Operating profit was EUR 24.5 mn , up from EUR 23.0 mn .@positive\n","\n","System out:  ['EU', 'EU', 'member of', 0.7983710765838623]\n","------------------------------\n","Sentence 70: Ramirent 's net sales in the second quarterended June 30 were EURO 128.7 million about U.S. $ 163 million , a 3.3-percent increase compared with EURO 124.6 million for thesecond quarter last year .@positive\n","\n","System out:  ['Ramirent', 'U', 'participating team', 0.8029999732971191]\n","------------------------------\n","Sentence 71: Revenue grew by 2 percent to  x20ac 580 million $ 743 million , from  x20ac 569 million .@positive\n","\n","System out:  None\n","------------------------------\n","Sentence 72: Ruukki 's delivery volumes and selling prices showed favourable development and the company 's comparable net sales grew by 50 % year-on-year to EUR647m , CEO Sakari Tamminen said .@positive\n","\n","System out:  ['EU', 'Sakari Tamminen', 'member of', 0.9106685519218445]\n","------------------------------\n","Sentence 73: The company 's consolidated operating profit amounted to EUR 15.86 mn , up from EUR 4.14 mn year-on-year .@positive\n","\n","System out:  ['EU', 'EU', 'applies to jurisdiction', 0.7124952077865601]\n","------------------------------\n","Sentence 74: The Department Store Division reported an increase in sales of 4 per cent .@positive\n","\n","System out:  None\n","------------------------------\n","Sentence 75: The fair value of the company 's investment properties grew to EUR 2.803 billion at the end of March 2009 from EUR 2.691 million a year ago .@positive\n","\n","System out:  ['EU', 'EU', 'applies to jurisdiction', 0.9398884773254395]\n","------------------------------\n","Sentence 76: The last quarter was the best quarter of 2009 in net sales , and the operating margin rose to 12.2 % .@positive\n","\n","System out:  None\n","------------------------------\n","Sentence 77: The major breweries increased their domestic beer sales by 4.5 per cent last year , to 256.88 million litres from 245.92 million litres in 2004 .@positive\n","\n","System out:  None\n","------------------------------\n","Sentence 78: - Operating profit rose by 26.9 % to EUR 105.8 ( 83.4 ) million .@positive\n","\n","System out:  None\n","------------------------------\n","Sentence 79: 21 October 2010 - Finnish fishing tackle company Rapala VMC Corp ( HEL : RAP1V ) said today its net profit rose to EUR18 .9 m for the first nine months of 2010 from EUR15 .1 m for the same period a year earlier .@positive\n","\n","System out:  ['Rapala VMC Corp', 'RAP1V', 'subsidiary', 0.8515734076499939]\n","------------------------------\n","Sentence 80: According to Finnish Metso Minerals , the value of the company 's orders has gone up to EUR 1.9 bn in 12 months .@positive\n","\n","System out:  ['Finnish Metso Minerals', 'EU', 'owned by', 0.5655713677406311]\n","------------------------------\n","Sentence 82: Finnish financial group Aktia 's operating profit for 2009 increased to EUR 47.0 mn from EUR 6.6 mn in 2008 .@positive\n","\n","System out:  ['Aktia', 'EU', 'subsidiary', 0.8097432255744934]\n","------------------------------\n","Sentence 83: Finnish forest machinery manufacturer Ponsse 's net sales grew to EUR 51.3 mn in the first quarter of 2010 from EUR 37.5 mn in the corresponding period in 2009 .@positive\n","\n","System out:  ['Ponsse', 'EU', 'owned by', 0.8730626106262207]\n","------------------------------\n","Sentence 84: Finnish KCI Konecranes has raised its net sales growth estimate for 2006 from over 25 % to over 35 % .@positive\n","\n","System out:  None\n","------------------------------\n","Sentence 86: Advertising and circulation revenues grew by 3.4 % and by 0.4 % , respectively .@positive\n","\n","System out:  None\n","------------------------------\n","Sentence 87: At the end of March 2007 , the group 's order book was at EUR 39.6 mn , up 42 % from the corresponding period in 2006 .@positive\n","\n","System out:  None\n","------------------------------\n","Sentence 88: At the same time profit of the company increased by 10 % in H1 and reached Ls 79,000 .@positive\n","\n","System out:  None\n","------------------------------\n","Sentence 89: Both operating profit and net sales for the 12-month period increased , respectively from EUR10 .5 m and EUR28 .8 m , as compared to the financial year 2004 .@positive\n","\n","System out:  ['EU', 'EU', 'member of', 0.6934517025947571]\n","------------------------------\n","Sentence 90: Both operating profit and net sales for the 12-month period increased , respectively from EUR20 .8 m and EUR177 .7 m , as compared to the financial year 2004 .@positive\n","\n","System out:  ['EU', 'EU', 'member of', 0.8250362277030945]\n","------------------------------\n","Sentence 91: Both operating profit and net sales for the 12-month period increased , respectively from EUR21 .5 m and EUR196 .1 m , as compared to 2005 .@positive\n","\n","System out:  ['EU', 'EU', 'applies to jurisdiction', 0.4197874665260315]\n","------------------------------\n","Sentence 92: Both operating profit and net sales for the 12-month period increased , respectively from EUR4 .7 m and EUR26 .7 m , as compared to 2004 .@positive\n","\n","System out:  ['EU', 'EU', 'member of', 0.48075971007347107]\n","------------------------------\n","Sentence 93: Both operating profit and net sales for the nine-month period increased , respectively by 26.6 % and 3.4 % , as compared to the corresponding period in 2006 .@positive\n","\n","System out:  None\n","------------------------------\n","Sentence 94: Both operating profit and net sales for the six-month period increased , respectively , from EUR13 .8 m and EUR143 .6 m , as compared to the corresponding period in 2007 .@positive\n","\n","System out:  ['EU', 'EU', 'has part', 0.45800015330314636]\n","------------------------------\n","Sentence 95: Both operating profit and net sales for the six-month period increased , respectively from EUR0 .4 m and EUR3 .2 m , as compared to the corresponding period in 2005 .@positive\n","\n","System out:  ['EU', 'EU', 'member of', 0.5943632125854492]\n","------------------------------\n","Sentence 96: Both operating profit and net sales for the six-month period increased , respectively from EUR18 .1 m and EUR127 .6 m , as compared to the corresponding period in 2006 .@positive\n","\n","System out:  ['EU', 'EU', 'member of', 0.5668812394142151]\n","------------------------------\n","Sentence 97: Both operating profit and net sales for the six-month period increased , respectively from EUR7 .5 m and EUR655 .5 m , as compared to the corresponding period in 2005 .@positive\n","\n","System out:  ['EU', 'EU', 'member of', 0.56824791431427]\n","------------------------------\n","Sentence 98: Both operating profit and net sales for the three-month period increased , respectively from EUR15 .1 m and EUR131 .5 m , as compared to the corresponding period in 2005 .@positive\n","\n","System out:  ['EU', 'EU', 'applies to jurisdiction', 0.4475259482860565]\n","------------------------------\n","Sentence 99: Both operating profit and net sales for the three-month period increased , respectively from EUR16 .0 m and EUR139m , as compared to the corresponding quarter in 2006 .@positive\n","\n","System out:  ['EU', 'EU', 'member of', 0.38817960023880005]\n","------------------------------\n","Sentence 100: Both operating profit and sales for the three-month period increased , respectively from EUR0 .3 m and EUR13 .1 m , as compared to the corresponding period in 2005 .@positive\n","\n","System out:  ['EU', 'EU', 'member of', 0.5594068169593811]\n","------------------------------\n","Sentence 101: Both operating profit and turnover for the nine-month period increased , respectively from EUR2 .4 m and EUR43 .8 m , as compared to the corresponding period a year ago .@positive\n","\n","System out:  ['EU', 'EU', 'member of', 0.4479716718196869]\n","------------------------------\n","Sentence 102: Both operating profit and turnover for the six-month period increased , respectively , from EUR17 .6 m and EUR1149 .9 m , as compared to the corresponding period in 2007 .@positive\n","\n","System out:  ['EU', 'EU', 'member of', 0.4944642186164856]\n","------------------------------\n","Sentence 103: Both operating profit and turnover for the six-month period increased , respectively from EUR0 .1 m and EUR29 .0 m , as compared to the corresponding period a year ago .@positive\n","\n","System out:  ['EU', 'EU', 'member of', 0.5342357754707336]\n","------------------------------\n","Sentence 104: Cargo volume increased by approximately 5 % .@positive\n","\n","System out:  None\n","------------------------------\n","Sentence 105: comparable operating profit totaled EUR 854mn , up from EUR 730mn in 2004 .@positive\n","\n","System out:  ['EU', 'EU', 'member of', 0.4760032892227173]\n","------------------------------\n","Sentence 106: Digia said its consolidated net sales for January-June 2010 were EUR67 .8 m , up 9.7 % on the same period in 2009 ( EUR61 .9 m ) .@positive\n","\n","System out:  ['Digia', 'EU', 'owned by', 0.8241001963615417]\n","------------------------------\n","Sentence 107: Diluted earnings per share ( EPS ) rose to EUR 0.29 from EUR 0.05 .@positive\n","\n","System out:  ['EU', 'EU', 'applies to jurisdiction', 0.8219913840293884]\n","------------------------------\n","Sentence 108: Diluted earnings per share ( EPS ) rose to EUR 0.52 versus EUR 0.09 .@positive\n","\n","System out:  ['EU', 'EU', 'applies to jurisdiction', 0.7525267601013184]\n","------------------------------\n","Sentence 109: Diluted earnings per share ( EPS ) rose to EUR 1.05 from EUR 0.64 .@positive\n","\n","System out:  ['EU', 'EU', 'applies to jurisdiction', 0.6352560520172119]\n","------------------------------\n","Sentence 110: Diluted earnings per share ( EPS ) rose to EUR 3.68 from EUR 0.50 .@positive\n","\n","System out:  ['EU', 'EU', 'applies to jurisdiction', 0.6554633975028992]\n","------------------------------\n","Sentence 111: Diluted EPS rose to EUR3 .68 from EUR0 .50 .@positive\n","\n","System out:  ['EU', 'EU', 'has part', 0.6820052266120911]\n","------------------------------\n","Sentence 112: EBIT margin was up from 1.4 % to 5.1 % .@positive\n","\n","System out:  None\n","------------------------------\n","Sentence 113: EPS from continuing operations came in at 0.30 eur , up from 0.17 .@positive\n","\n","System out:  None\n","------------------------------\n","Sentence 114: Equity ratio was 60.9 % compared to 54.2 % In the third quarter of 2007 , net sales of the Frozen Foods Business totaled EUR 11.0 , up by about 5 % from the third quarter of 2006 .@positive\n","\n","System out:  ['Frozen Foods Business', 'EU', 'owned by', 0.9119526147842407]\n","------------------------------\n","Sentence 115: EUR928 ,000 in Q1 2010 6 May 2010 - Finnish textile and clothing design company Marimekko Oyj ( HEL : MMO1V ) said today its net profit rose to EUR928 ,000 in the first quarter of 2010 from EUR13 ,000 in the corresponding period a year earlier .@positive\n","\n","System out:  ['EU', 'Finnish', 'country', 0.9738199710845947]\n","------------------------------\n","Sentence 116: Finland-based Elcoteq SE , a privately held provider of electronics manufacturing services to communications companies , said Thursday it signed a long-term manufacturing supply deal with communications equipment company Andrew Corp. .@positive\n","\n","System out:  ['Elcoteq SE', 'Andrew Corp', 'subsidiary', 0.9946000576019287]\n","------------------------------\n","Sentence 117: Finnish cutlery and hand tools maker Fiskars Oyj Abp ( HEL : FISAS ) said today its net profit rose to EUR 24.1 million ( USD 33.6 m ) in the third quarter of 2010 from EUR 17.9 million a year earlier .@positive\n","\n","System out:  ['Finnish', 'FISAS', 'owned by', 0.6980603933334351]\n","------------------------------\n","Sentence 118: Finnish department store chain Stockmann Oyj Abp net profit rose to 39.8 mln euro ( $ 56.8 mln ) for the first nine months of 2007 from 37.4 mln euro ( $ 53.4 mln ) for the same period of 2006 .@positive\n","\n","System out:  ['Finnish', 'Stockmann Oyj', 'location of formation', 0.641361653804779]\n","------------------------------\n","Sentence 119: Finnish lifting equipment maker Konecranes Oyj said on July 30 , 2008 that its net profit rose to 71.2 mln euro ( $ 111.1 mln ) for the first half of 2008 from 57.1 mln euro ( $ 89.1 mln ) for the same period of 2007 .@positive\n","\n","System out:  ['Finnish', 'Konecranes Oyj', 'owned by', 0.7952463030815125]\n","------------------------------\n","Sentence 120: Finnish metal industry solutions supplier Outotec Oyj net profit rose to 50.4 mln euro ( $ 72.5 mln ) for the first nine months of 2007 from 20.1 mln euro ( $ 28.9 mln ) for the same period of 2006 .@positive\n","\n","System out:  ['Finnish', 'Outotec Oyj', 'owned by', 0.446135550737381]\n","------------------------------\n","Sentence 121: Finnish metal products company Componenta Oyj net profit rose to 26.1 mln euro ( $ 35.9 mln ) for the first quarter of 2007 from 5.3 mln euro ( $ 7.3 mln ) for the same period of 2006 .@positive\n","\n","System out:  ['Finnish', 'Componenta Oyj', 'owned by', 0.5686669945716858]\n","------------------------------\n","Sentence 123: Finnish security and privacy software solutions developer Stonesoft Oyj said on January 7 , 2008 that the preliminary sales of its StoneGate products grew by 59 pct year-on-year to 3.6 mln euro ( $ 5.3 mln ) for the fourth quarter of 2007 .@positive\n","\n","System out:  ['Stonesoft Oyj', 'StoneGate', 'developer', 0.9942557215690613]\n","------------------------------\n","Sentence 124: Finnish silicon wafer technology company Okmetic Oyj ( OMX Helsinki : OKM1V ) reported on Thursday ( 7 August ) an operating profit of EUR5 .3 m for the period January-June 2008 , up from EUR3 .3 m in the corresponding period in 2007 .@positive\n","\n","System out:  ['Okmetic Oyj', 'EU', 'owned by', 0.9812333583831787]\n","------------------------------\n","Sentence 125: Finnish software developer Done Solutions Oyj said its net profit increased to 3.5 mln euro ( $ 4.6 mln ) in 2006 from 2.3 mln euro ( $ 3.0 mln ) in 2005 .@positive\n","\n","System out:  ['Finnish', 'Done Solutions Oyj', 'location of formation', 0.9232889413833618]\n","------------------------------\n","Sentence 126: First quarter underlying operating profit rose to 41 mln eur from 33 mln a year earlier .@positive\n","\n","System out:  None\n","------------------------------\n","Sentence 127: For the first nine months of 2010 , the company 's net profit rose to EUR41m from EUR30m for the corresponding period of 2009 .@positive\n","\n","System out:  ['EU', 'EU', 'has part', 0.4180639684200287]\n","------------------------------\n","Sentence 128: HELSINKI ( AFX ) - Retail and wholesale group Kesko reported net sales of 659.4 mln eur for February , an increase of 10.8 pct year-on-year .@positive\n","\n","System out:  ['HELSINK', 'Kesko', 'subsidiary', 0.9931132197380066]\n","------------------------------\n","Sentence 129: However , net sales in 2010 are seen to have grown to EUR598 .3 m from EUR582 .3 m in 2009 .@positive\n","\n","System out:  ['EU', 'EU', 'member of', 0.4786885380744934]\n","------------------------------\n","Sentence 130: However , sales returned to growth in April-June 2010 , CEO Pekka Eloholma said .@positive\n","\n","System out:  None\n","------------------------------\n","Sentence 131: Ragutis , which is controlled by the Finnish brewery , reported a 5.4-per-cent rise in beer sales to 10.44 million litres and held an 11.09-per-cent market share .@positive\n","\n","System out:  ['Ragutis', 'Finnish', 'owned by', 0.9879837036132812]\n","------------------------------\n","Sentence 132: Svyturys-Utenos Alus , which is controlled by the Nordic group Baltic Beverages Holding ( BBH ) , posted a 4.7-per-cent growth in beer sales for January-May to 46.22 million litres .@positive\n","\n","System out:  ['Utenos Alus', 'BBH', 'owned by', 0.9934000968933105]\n","------------------------------\n","Sentence 133: In December alone , the members of the Lithuanian Brewers ' Association sold a total of 20.3 million liters of beer , an increase of 1.9 percent from the sales of 19.92 million liters in December 2004 .@positive\n","\n","System out:  None\n","------------------------------\n","Sentence 134: In January-September 2009 , the Group 's net interest income increased to EUR 112.4 mn from EUR 74.3 mn in January-September 2008 .@positive\n","\n","System out:  ['Group', 'EU', 'member of', 0.8181583881378174]\n","------------------------------\n","la précision moyenne est : 0.5208455392225521\n"]}],"source":["fname = '../../../../content/Sentences_AllAgree.txt'\n","f = open(fname, 'rt', encoding=\"ISO-8859-1\")\n","n = 1\n","nre = NREPipeline(ner_pipeline, model)\n","nb_sambles = 127\n","mean_proba = 0\n","for line in f:\n","  if n not in (20, 38, 47, 50, 81, 85, 122):\n","    out = nre(line)\n","    print(\"Sentence {0}: {1}\".format(n, line))\n","    print(\"System out: \", out)\n","    print('------------------------------')\n","    if out != None:\n","      mean_proba += out[3]\n","    else:\n","      nb_sambles\n","  n += 1\n","mean_proba /= nb_sambles\n","print('la précision moyenne est :', mean_proba)"]},{"cell_type":"markdown","metadata":{"id":"QtC9Da9PBmWx"},"source":["2) Pour le premier DataSet on trouve que la précision moyenne est de 0.9703475070554156, ce qui est très bon.\n","Le soucis qu'on trouve, comme indiqué dans un commentaire du code, est que quelques phrases du DataSet n'arrivent pas à être traité par notre Algo.\n","Par exemple, pour la phrase n° 7, \"I-5\" n'est pas considéré comme un nom en soit par la pipeline NER ce qui crée des problèmes par la suite.\n","\n","Comme réctification, on propose de trouver un tokenizer plus précis (par soucis de temps cela ne sera pas fait).\n","\n","3) Rmq: on n'utilise qu'une partie du DataSet à savoir 134 phrases, tout en éliminant les phrases qui bloquent l'Algo. Cela pour avoir un résultat sur la précision comparable à celui trouvé pour le premier.\n","\n","4) Pour le deuxième DataSet on trouve que la précision moyenne est de 0.5208455392225521, ce qui est nettement moins bien que le premier résultat.\n","\n","Cela pourrait être dû au fait que les phrases sont ciblés sur un domaine bien précis à savoir la finance. Donc on retrouve des mots qui sont bien spécifiques au domaine, mais qui ne sont pas captés par la pipeline NER. On prend l'exemple de la devise \"EUR\" qui à chaque apparition n'est pas detectée mais c'est le sous mot \"EU\" qui l'est et qui référe à \"European Union\".\n","\n","Donc une solution, serait d'entrainé le modèle NER sur des phrases inspirés du domaine financier pour pouvoir detecté ce genre de mots.\n","\n","\n","**Tout de même, le modèle d'extraction de relations devrait être entraîné avec des relations plus spécifiques, qui ne sont pas présentes dans l'ensemble des 80 relations définies par Wiki80.**"]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"tp_re.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"03097ccf5ddb42f9b0004f56275b0b72":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0efe12e3ca43448f843b9bf1a97a0572":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2a9f2b05e4974daf9196ce9c93ef9ca9","placeholder":"​","style":"IPY_MODEL_f66469b16a384ded849822534bce1af6","value":"Downloading: 100%"}},"106446a4c0af442980fb3945bfc04ccf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c711d8ecb1243c4b5266a688df5ba7e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1d21da9be65d4879ab0dca865544fd22":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2390daac0d8344d4a9b292f3011a266b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2a9f2b05e4974daf9196ce9c93ef9ca9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"32da91faa69e442f80519d4e8009e7b0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3362d67ac9524161a34afc422fad714e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"37ee166f574f40c187a332cf7ab048e4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"384506314d5f409999307da7a6cf4f42":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_df56f6471b6e40678e80d4eee8321cda","placeholder":"​","style":"IPY_MODEL_8d1b3288179546b3ad974d8026920a73","value":"Downloading: 100%"}},"48d3d5d554164233bb935213e0881aca":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a2f8ecb777454ceea6443db0213b6628","max":60,"min":0,"orientation":"horizontal","style":"IPY_MODEL_32da91faa69e442f80519d4e8009e7b0","value":60}},"4986532354b04e5a84ab2dfd2d2ee7d2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7ab0f8eee32a4296a2f4c538841fa911","IPY_MODEL_abc2f10edb9e482e8e81bbedc6b9f650","IPY_MODEL_f5815958f2ff4091b412a33bc2bc9ffd"],"layout":"IPY_MODEL_728857bdbf2843c1b87f2509cf3afa9e"}},"4b1ae58d900d4569b2faa65c75039a99":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_830c741882064c29b3b6d987dd44fd36","max":998,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1c711d8ecb1243c4b5266a688df5ba7e","value":998}},"4c5f019642114a05821d140fe66222e3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d6f1e8ab52f4d3ea2248756d96f0bc6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3362d67ac9524161a34afc422fad714e","max":213450,"min":0,"orientation":"horizontal","style":"IPY_MODEL_37ee166f574f40c187a332cf7ab048e4","value":213450}},"5b6bfd957fc145e69476d00ec4b57da0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0efe12e3ca43448f843b9bf1a97a0572","IPY_MODEL_4d6f1e8ab52f4d3ea2248756d96f0bc6","IPY_MODEL_b117c0dbc70a40388f194d81918c149c"],"layout":"IPY_MODEL_7595a9b0d4f04386bf275799d36e16c9"}},"6b6137dc3147435da071fbbb38ba9d4c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"728857bdbf2843c1b87f2509cf3afa9e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7595a9b0d4f04386bf275799d36e16c9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ab0f8eee32a4296a2f4c538841fa911":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b35163523362471fa15f1b79703b3ffe","placeholder":"​","style":"IPY_MODEL_b2c4762c84164bedad62304f95fcb0ed","value":"Downloading: 100%"}},"830c741882064c29b3b6d987dd44fd36":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"894b31e25db240fa982e30911f66939d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8aec1af74ea840498d8e80c51841ca9c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8d1b3288179546b3ad974d8026920a73":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"945176ec31a045eb864f409ea68d08af":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"95f23713e52543b58dfbbc43954c1b6c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e5f3df4123b0462a9a498d594b0587ef","IPY_MODEL_48d3d5d554164233bb935213e0881aca","IPY_MODEL_f5d44e95c2f642afa044beeb4fc3acd1"],"layout":"IPY_MODEL_106446a4c0af442980fb3945bfc04ccf"}},"a2f8ecb777454ceea6443db0213b6628":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a79b90c4a93840dfaf82020cee8685b1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_384506314d5f409999307da7a6cf4f42","IPY_MODEL_4b1ae58d900d4569b2faa65c75039a99","IPY_MODEL_bfba9d066e16459687b67a86ecec70e7"],"layout":"IPY_MODEL_e31c98c6c02e44f99f345c078f095cbc"}},"a7cc0d0092594c7f835208c0fafa82e0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"abc2f10edb9e482e8e81bbedc6b9f650":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d951ca9a1a294d60a1b65a04f87067be","max":1334448817,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d6571a09288b463987cee5473b16137a","value":1334448817}},"b117c0dbc70a40388f194d81918c149c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_03097ccf5ddb42f9b0004f56275b0b72","placeholder":"​","style":"IPY_MODEL_894b31e25db240fa982e30911f66939d","value":" 213k/213k [00:00&lt;00:00, 1.13MB/s]"}},"b2c4762c84164bedad62304f95fcb0ed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b35163523362471fa15f1b79703b3ffe":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bfba9d066e16459687b67a86ecec70e7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e3a8c337b6b44b62bc556eefad439f0e","placeholder":"​","style":"IPY_MODEL_8aec1af74ea840498d8e80c51841ca9c","value":" 998/998 [00:00&lt;00:00, 23.7kB/s]"}},"d6571a09288b463987cee5473b16137a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d951ca9a1a294d60a1b65a04f87067be":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df56f6471b6e40678e80d4eee8321cda":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e31c98c6c02e44f99f345c078f095cbc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e3a8c337b6b44b62bc556eefad439f0e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e5f3df4123b0462a9a498d594b0587ef":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1d21da9be65d4879ab0dca865544fd22","placeholder":"​","style":"IPY_MODEL_945176ec31a045eb864f409ea68d08af","value":"Downloading: 100%"}},"f5815958f2ff4091b412a33bc2bc9ffd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4c5f019642114a05821d140fe66222e3","placeholder":"​","style":"IPY_MODEL_6b6137dc3147435da071fbbb38ba9d4c","value":" 1.33G/1.33G [00:30&lt;00:00, 44.8MB/s]"}},"f5d44e95c2f642afa044beeb4fc3acd1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a7cc0d0092594c7f835208c0fafa82e0","placeholder":"​","style":"IPY_MODEL_2390daac0d8344d4a9b292f3011a266b","value":" 60.0/60.0 [00:00&lt;00:00, 1.45kB/s]"}},"f66469b16a384ded849822534bce1af6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}
