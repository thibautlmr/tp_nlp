{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLKNFGMXa1gH"
      },
      "outputs": [],
      "source": [
        "!pip install OpenNMT-py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XgyV9UXKg4Er"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3b-HcnjgXRC"
      },
      "outputs": [],
      "source": [
        "%cd /content/drive/MyDrive/TP_NMT/tp_nmt/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4pPoQ7nvPDZ"
      },
      "source": [
        "## Préparation des données"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_AuCKYHjQk4"
      },
      "source": [
        "**Q1**\n",
        "> Ces fichiers contiennent les données que nous allons utilisées pour entraîner notre réseau de neurones.\n",
        "Sur chaque ligne, nous avons la phrase source et la phrase target."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsirQg2xkVBW",
        "outputId": "b229ce80-38ba-4c0c-fae9-719e4379f2fb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%shell\n",
        "cd BTEC-en-fr\n",
        "for i in ./train/* ./dev/* ./test/*\n",
        "do\n",
        "  awk -F '\\' '{print $NF}' $i > ${i}_out.clean.txt \n",
        "done"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J0gp1wQgmpHA"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "perl ./tokenizer.perl -l en -lc < ./BTEC-en-fr/train/IWSLT10_BTEC.train.en.txt_out.clean.txt > BTEC-en-fr/train/IWSLT10_BTEC.train.en.txt_out.tok.txt\n",
        "perl ./tokenizer.perl -l fr -lc < ./BTEC-en-fr/train/IWSLT10_BTEC.train.fr.txt_out.clean.txt > BTEC-en-fr/train/IWSLT10_BTEC.train.fr.txt_out.tok.txt\n",
        "\n",
        "perl ./tokenizer.perl -l en -lc < ./BTEC-en-fr/dev/IWSLT10.devset1_CSTAR03.en.txt_out.clean.txt > BTEC-en-fr/dev/IWSLT10.devset1_CSTAR03.en.txt_out.tok.txt\n",
        "perl ./tokenizer.perl -l fr -lc < ./BTEC-en-fr/dev/IWSLT10.devset1_CSTAR03.fr.txt_out.clean.txt > BTEC-en-fr/dev/IWSLT10.devset1_CSTAR03.fr.txt_out.tok.txt\n",
        "\n",
        "perl ./tokenizer.perl -l en -lc < ./BTEC-en-fr/test/IWSLT09_BTEC.testset.en.txt_out.clean.txt > BTEC-en-fr/test/IWSLT09_BTEC.testset.en.txt_out.tok.txt\n",
        "perl ./tokenizer.perl -l fr -lc < ./BTEC-en-fr/test/IWSLT09_BTEC.testset.fr.txt_out.clean.txt > BTEC-en-fr/test/IWSLT09_BTEC.testset.fr.txt_out.tok.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jI29zOkJsagX"
      },
      "source": [
        "**Q2**\n",
        "> Dans les fichiers .tok, les symboles de ponctuations sont étiquetés et certains espaces sont ajoutés autour d'eux dans le but d'avoir une data plus structurée et donc de facilité son traitement.\n",
        "\n",
        "<span style=\"color:red\"> Ca veut dire quoi data plus structurés? Le but est de pouvoir construire un vocabulaire de taille raisonnable à partir de ces donnée. Si on ne sépare pas les mots et la ponctuation on sera obligé à avoir plu de tokens dans le vocabularie. E.g. \"Salut\", \"Salut!\", \"Salut,\", \"Salut?\", etc. </span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqbfjjV1uG46"
      },
      "source": [
        "**Q3**\n",
        "\n",
        "> Le training set permet d'entraîner le réseaux via la modification des poids\n",
        "\n",
        "> Le dev set permet lui l'ajustement du modèle en agissant sur la modification des hyperparamètres\n",
        "\n",
        "> Le test set permet de fournir une évaluation impartiale de notre modèle (ce jeu de données n'a pas servit à entraîner le modèle)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtf4hfcNvLmf"
      },
      "source": [
        "## Création d’un modèle de TA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eeozgTgKvaXm"
      },
      "outputs": [],
      "source": [
        "!onmt_build_vocab -config config-base.yaml -n_sample -1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9wHMqDmxK0B"
      },
      "source": [
        "**Q4**\n",
        "\n",
        "> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYYhIFKAxc2H"
      },
      "source": [
        "**Q5**\n",
        "\n",
        "> Ces lignes nous donnent le nombre de mots que nos langages source et target contiennent. <span style=\"color:red\">plus précisement: le nombre de tokens uniques présents dans le vocabulaire source et cible.</span> "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48TojbaLySlo"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "onmt_train -config config-baseQ6.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dC9uVxIi4Mf3"
      },
      "source": [
        "**Q6**\n",
        "\n",
        "> acc correspond précision du modèle en pourcentage (ratio succès sur tentatives). Il faut donc que cette valeur soit maximale.\n",
        "\n",
        "> ppl correspond à la perplexité : La perplexité est une mesure de la capacité d'une distribution de probabilité ou d'un modèle de probabilité à prédire un échantillon. Plus elle est petite, mieux le modèle est performant."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfVQ0n226SJW"
      },
      "source": [
        "**Q7**\n",
        "\n",
        "- train_step : le nombre d'entraînements du réseaux <span style=\"color:red\">Nombre total d'étapes d'optimisation des poids du modèle, où chaque étape est constitué d'un passage en avant d'un lot (batch) de données d'apprentissage dans le modèle (forward pass) et d'un passage en arrière des gradients générés par la fonction de perte (backward pass). </span>\n",
        "- valid_step : le pas auquel on teste notre modèle sur les données de validations <span style=\"color:red\">nombre d'étapes d'entrainement entre une étape de validation et la suivante. </span>\n",
        "- enc_layers : nombre de couche de l'encodeur\n",
        "- dec_layers : nombre de couche du décodeur\n",
        "- enc_rnn_size : nombre de neurones par couche pour l'encodeur\n",
        "- dec_rnn_size : nombre de neurones par couche pour le décodeur\n",
        "- batch_size : nombre de phrases maximum processées à chaque itération (cf coefficient d'homogénéisation des données que l'on procède) <span style=\"color:red\">itération de quoi? </span>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yajMlQP9MI2"
      },
      "source": [
        "##  Evaluation d’un modèle de TA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6_hJFOB_XD4"
      },
      "outputs": [],
      "source": [
        "!onmt_translate -model models/baseQ6/model_step_625.pt -src ./BTEC-en-fr/test/IWSLT09_BTEC.testset.fr.txt_out.tok.txt -output models/Q6_pred625.txt\n",
        "!onmt_translate -model models/baseQ6/model_step_1250.pt -src ./BTEC-en-fr/test/IWSLT09_BTEC.testset.fr.txt_out.tok.txt -output models/Q6_pred1250.txt\n",
        "!onmt_translate -model models/baseQ6/model_step_1875.pt -src ./BTEC-en-fr/test/IWSLT09_BTEC.testset.fr.txt_out.tok.txt -output models/Q6_pred1875.txt\n",
        "!onmt_translate -model models/baseQ6/model_step_2000.pt -src ./BTEC-en-fr/test/IWSLT09_BTEC.testset.fr.txt_out.tok.txt -output models/Q6_pred2000.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFLDubGsBFRy",
        "outputId": "569ad115-0795-427f-aa19-5a49fc73845c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BLEU = 8.57, 46.2/15.2/8.2/2.4 (BP=0.790, ratio=0.809, hyp_len=2892, ref_len=3574)\n",
            "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
            "BLEU = 13.98, 44.5/18.0/10.4/4.6 (BP=1.000, ratio=1.035, hyp_len=3698, ref_len=3574)\n",
            "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
            "BLEU = 17.96, 53.0/24.0/15.1/7.9 (BP=0.908, ratio=0.912, hyp_len=3260, ref_len=3574)\n",
            "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
            "BLEU = 19.47, 55.7/26.9/16.9/8.8 (BP=0.897, ratio=0.902, hyp_len=3224, ref_len=3574)\n",
            "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n"
          ]
        }
      ],
      "source": [
        "!perl multi-bleu.perl ./BTEC-en-fr/test/IWSLT09_BTEC.testset.en.txt_out.tok.txt < models/Q6_pred625.txt\n",
        "!perl multi-bleu.perl ./BTEC-en-fr/test/IWSLT09_BTEC.testset.en.txt_out.tok.txt < models/Q6_pred1250.txt\n",
        "!perl multi-bleu.perl ./BTEC-en-fr/test/IWSLT09_BTEC.testset.en.txt_out.tok.txt < models/Q6_pred1875.txt\n",
        "!perl multi-bleu.perl ./BTEC-en-fr/test/IWSLT09_BTEC.testset.en.txt_out.tok.txt < models/Q6_pred2000.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGEih7lhCF9Y"
      },
      "source": [
        "**Q8**\n",
        "> Le score BLEU est compris entre 0 et 100%. On cherche à avoir ce score le plus proche possible de 100% car ce score indique dans quelle mesure le texte candidat est similaire aux textes de référence et donc en conséquence les valeurs plus proches de 100% représentant des textes plus similaires.\n",
        "\n",
        "**Q9**\n",
        "> Le model qui obtient le meilleur score est le dernier. Celui enregistrer à la fin de l'étape 2000."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F56sjsIRfDN5"
      },
      "source": [
        "## Optimisation des paramètres\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_AlwfL-fnJJ"
      },
      "source": [
        "**Q10**\n",
        "> Nous testons dans un premier temps d'augmenter le nombre d'étapes à 5000 et procédons à l'entrainement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OjOej3ZKfzAn"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "onmt_train -config config-baseQ10.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-r4XCjG4gk-0"
      },
      "source": [
        "Evaluons le dernier modèle enregistré après les 5000 étapes =>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TBWsjqdg0pF",
        "outputId": "7239a7bd-2b6a-408a-c0be-4be0b307b0a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "[2022-02-27 18:32:08,631 INFO] Translating shard 0.\n",
            "/usr/local/lib/python3.7/dist-packages/onmt/translate/beam_search.py:282: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  self._batch_index = self.topk_ids // vocab_size\n",
            "[2022-02-27 18:32:13,212 INFO] PRED AVG SCORE: -0.6617, PRED PPL: 1.9381\n",
            "BLEU = 29.92, 64.3/37.6/25.7/16.6 (BP=0.938, ratio=0.940, hyp_len=3579, ref_len=3808)\n",
            "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n"
          ]
        }
      ],
      "source": [
        "!onmt_translate -model models/baseQ10/model_step_5000.pt -src ./BTEC-en-fr/dev/IWSLT10.devset1_CSTAR03.fr.txt_out.tok.txt -output models/Q10_pred5000.txt\n",
        "!perl multi-bleu.perl ./BTEC-en-fr/dev/IWSLT10.devset1_CSTAR03.en.txt_out.tok.txt < models/Q10_pred5000.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eSo_mJyhIF7"
      },
      "source": [
        "> Nous sommes passé de 19.01% pour 2000 steps à 29.92% pour 5000 steps. Le BLEU augmente plus le nombre de training steps augmente. Il augmente donc en cohérence avec le principe d'apprentissage des réseaux de neurones. Plus on entraîne le modèle, plus il est performant.\n",
        "\n",
        "> Cependant à partir d'un certain nombre d'entraînement, la performance du modèle n'augmente plus, les données d'entraînement ne suffisent plus pour permettre une amélioration. Il y a donc un nombre d'entraînement optimal à partir duquel le modèle ne s'améliore plus. Nous alons le trouver à partir de l'option `early7.2.3_stopping`. Nous allons donc mettre un très grand nombre de training steps et voir à quel moment le modèle arrète de s'entraîner suite à l'absence d'amélioration.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iS0mlkVVjSFN"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "onmt_train -config config-baseQ10-1.yaml -early_stopping 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JTzhwk5mz_Z"
      },
      "source": [
        "> Dans notre cas, le modèle a arreté de s'entrainer après 2 étapes de validation consécutives sans amélioration.\n",
        "\n",
        "> Calculons le BLEU correspondant au dernier modèle enregistré."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQPqreQnnKoG",
        "outputId": "b92a56a9-a7bb-4d35-f219-3c1bd249a657"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "[2022-02-27 18:32:56,484 INFO] Translating shard 0.\n",
            "/usr/local/lib/python3.7/dist-packages/onmt/translate/beam_search.py:282: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  self._batch_index = self.topk_ids // vocab_size\n",
            "[2022-02-27 18:33:00,946 INFO] PRED AVG SCORE: -0.5624, PRED PPL: 1.7548\n",
            "BLEU = 34.47, 68.1/42.5/30.4/21.6 (BP=0.927, ratio=0.930, hyp_len=3541, ref_len=3808)\n",
            "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n"
          ]
        }
      ],
      "source": [
        "!onmt_translate -model models/baseQ10_1/model_step_6875.pt -src ./BTEC-en-fr/dev/IWSLT10.devset1_CSTAR03.fr.txt_out.tok.txt -output models/Q10_1_pred6875.txt\n",
        "!perl multi-bleu.perl ./BTEC-en-fr/dev/IWSLT10.devset1_CSTAR03.en.txt_out.tok.txt < models/Q10_1_pred6875.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXYjafYmniAL"
      },
      "source": [
        "> Le score maximal que l'on arrive donc a obtenir en augmentant le nombre de training steps est 34.47%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwbrBuLOnspk"
      },
      "source": [
        "**Q11**\n",
        "> Relançons donc l'entrainement avec 3 couches sur l'encodeur."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTvjW9BvoGFr"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "onmt_train -config config-baseQ11.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5T_XCWdp1JW",
        "outputId": "42df9145-0a5a-438b-c781-3895485b5ffd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2022-02-27 18:33:48,906 INFO] Translating shard 0.\n",
            "/usr/local/lib/python3.7/dist-packages/onmt/translate/beam_search.py:282: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  self._batch_index = self.topk_ids // vocab_size\n",
            "[2022-02-27 18:33:53,532 INFO] PRED AVG SCORE: -0.9749, PRED PPL: 2.6509\n",
            "BLEU = 18.74, 55.8/26.4/15.9/8.1 (BP=0.899, ratio=0.903, hyp_len=3440, ref_len=3808)\n",
            "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n"
          ]
        }
      ],
      "source": [
        "!onmt_translate -model models/baseQ11/model_step_2000.pt -src ./BTEC-en-fr/dev/IWSLT10.devset1_CSTAR03.fr.txt_out.tok.txt -output models/Q11_pred2000.txt\n",
        "!perl multi-bleu.perl ./BTEC-en-fr/dev/IWSLT10.devset1_CSTAR03.en.txt_out.tok.txt < models/Q11_pred2000.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vd8X_PWTqWSD"
      },
      "source": [
        "> Nous obtenons un score BLEU de 18.74%. Augmenter les couches de l'encodeur de semble pas augmenter la performance du modèle.\n",
        "\n",
        "> Testons à présent d'augmenter le nombre de couche du décodeur."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M3jV6dMcqu4B"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "onmt_train -config config-baseQ11-1.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1q1lfQHuFSl",
        "outputId": "6516435f-f355-466d-9ca7-ee7671fc9e5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2022-02-27 18:34:15,998 INFO] Translating shard 0.\n",
            "/usr/local/lib/python3.7/dist-packages/onmt/translate/beam_search.py:282: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  self._batch_index = self.topk_ids // vocab_size\n",
            "[2022-02-27 18:34:22,652 INFO] PRED AVG SCORE: -1.2544, PRED PPL: 3.5056\n",
            "BLEU = 11.41, 41.1/16.0/8.5/3.0 (BP=1.000, ratio=1.028, hyp_len=3915, ref_len=3808)\n",
            "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n"
          ]
        }
      ],
      "source": [
        "!onmt_translate -model models/baseQ11_1/model_step_2000.pt -src ./BTEC-en-fr/dev/IWSLT10.devset1_CSTAR03.fr.txt_out.tok.txt -output models/Q11_1_pred2000.txt\n",
        "!perl multi-bleu.perl ./BTEC-en-fr/dev/IWSLT10.devset1_CSTAR03.en.txt_out.tok.txt < models/Q11_1_pred2000.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GH1w-hKSulom"
      },
      "source": [
        "> Nous obtenons à présent un score de 11.41%. Essayons d'augmenter le nombre de steps pour voir si on peut avoir un meilleur score BLEU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CIZVoTWdGPZ8"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "onmt_train -config config-baseQ11-2.yaml -early_stopping 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHfDASK0KJKr",
        "outputId": "875da7f4-3fbc-420c-9e06-c8fb861ad3d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2022-02-27 18:34:48,745 INFO] Translating shard 0.\n",
            "/usr/local/lib/python3.7/dist-packages/onmt/translate/beam_search.py:282: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  self._batch_index = self.topk_ids // vocab_size\n",
            "[2022-02-27 18:34:54,689 INFO] PRED AVG SCORE: -0.6172, PRED PPL: 1.8537\n",
            "BLEU = 28.81, 60.4/34.6/24.0/16.0 (BP=0.963, ratio=0.964, hyp_len=3671, ref_len=3808)\n",
            "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n"
          ]
        }
      ],
      "source": [
        "!onmt_translate -model models/baseQ11_2/model_step_10625.pt -src ./BTEC-en-fr/dev/IWSLT10.devset1_CSTAR03.fr.txt_out.tok.txt -output models/Q11_2_pred10625.txt\n",
        "!perl multi-bleu.perl ./BTEC-en-fr/dev/IWSLT10.devset1_CSTAR03.en.txt_out.tok.txt < models/Q11_2_pred10625.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qq1_7wUhKXSd"
      },
      "source": [
        "> On obtient un score BLEU de 28,81%. Augmenter le nombre de couche à 3 ne semble pas améliorer notre modèle.\n",
        "\n",
        "> Testons avec 2 couches :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGT9QY8uj_f3"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "onmt_train -config config-baseQ11-3.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjyZ0wKTkD3N",
        "outputId": "150e86a0-e800-4547-d3bb-abfd772e29e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2022-02-27 19:08:41,801 INFO] Translating shard 0.\n",
            "/usr/local/lib/python3.7/dist-packages/onmt/translate/beam_search.py:282: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  self._batch_index = self.topk_ids // vocab_size\n",
            "[2022-02-27 19:08:47,178 INFO] PRED AVG SCORE: -1.0243, PRED PPL: 2.7851\n",
            "BLEU = 14.63, 51.1/21.7/12.3/5.0 (BP=0.906, ratio=0.910, hyp_len=3467, ref_len=3808)\n",
            "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n"
          ]
        }
      ],
      "source": [
        "!onmt_translate -model models/baseQ11_3/model_step_2000.pt -src ./BTEC-en-fr/dev/IWSLT10.devset1_CSTAR03.fr.txt_out.tok.txt -output models/Q11_3_pred2000.txt\n",
        "!perl multi-bleu.perl ./BTEC-en-fr/dev/IWSLT10.devset1_CSTAR03.en.txt_out.tok.txt < models/Q11_3_pred2000.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3gTl7AflgxD"
      },
      "source": [
        "> Avoir 2 couches ne semble toujours pas améliorer le modèle."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DCPCW6JKzei"
      },
      "source": [
        "**Q12**\n",
        "\n",
        "Relançons donc l'entrainement avec différents nombres unités sur l'encodeur et le décodeur."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZQr3zzrLJPi"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "for i in 256 300 350 400 450 500\n",
        "do\n",
        "  onmt_train -config config-baseQ12_${i}.yaml\n",
        "done\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knPUKANSLmhN",
        "outputId": "65a38e79-189a-4cd9-a22a-c5d7a89dfc69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "[2022-02-27 18:55:43,348 INFO] Translating shard 0.\n",
            "/usr/local/lib/python3.7/dist-packages/onmt/translate/beam_search.py:282: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  self._batch_index = self.topk_ids // vocab_size\n",
            "[2022-02-27 18:55:47,587 INFO] PRED AVG SCORE: -0.9397, PRED PPL: 2.5592\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "[2022-02-27 18:55:49,519 INFO] Translating shard 0.\n",
            "/usr/local/lib/python3.7/dist-packages/onmt/translate/beam_search.py:282: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  self._batch_index = self.topk_ids // vocab_size\n",
            "[2022-02-27 18:55:54,816 INFO] PRED AVG SCORE: -0.9650, PRED PPL: 2.6247\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "[2022-02-27 18:55:56,758 INFO] Translating shard 0.\n",
            "/usr/local/lib/python3.7/dist-packages/onmt/translate/beam_search.py:282: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  self._batch_index = self.topk_ids // vocab_size\n",
            "[2022-02-27 18:56:02,451 INFO] PRED AVG SCORE: -0.9645, PRED PPL: 2.6234\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "[2022-02-27 18:56:04,409 INFO] Translating shard 0.\n",
            "/usr/local/lib/python3.7/dist-packages/onmt/translate/beam_search.py:282: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  self._batch_index = self.topk_ids // vocab_size\n",
            "[2022-02-27 18:56:11,317 INFO] PRED AVG SCORE: -0.9656, PRED PPL: 2.6263\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "[2022-02-27 18:56:13,368 INFO] Translating shard 0.\n",
            "/usr/local/lib/python3.7/dist-packages/onmt/translate/beam_search.py:282: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  self._batch_index = self.topk_ids // vocab_size\n",
            "[2022-02-27 18:56:20,928 INFO] PRED AVG SCORE: -0.8812, PRED PPL: 2.4138\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "[2022-02-27 18:56:22,982 INFO] Translating shard 0.\n",
            "/usr/local/lib/python3.7/dist-packages/onmt/translate/beam_search.py:282: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  self._batch_index = self.topk_ids // vocab_size\n",
            "[2022-02-27 18:56:31,249 INFO] PRED AVG SCORE: -0.9966, PRED PPL: 2.7091\n",
            "BLEU = 18.83, 56.3/26.8/16.7/8.6 (BP=0.873, ratio=0.881, hyp_len=3353, ref_len=3808)\n",
            "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
            "BLEU = 17.93, 54.9/25.7/14.8/6.4 (BP=0.937, ratio=0.939, hyp_len=3574, ref_len=3808)\n",
            "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
            "BLEU = 17.91, 55.4/25.8/14.8/7.2 (BP=0.906, ratio=0.910, hyp_len=3467, ref_len=3808)\n",
            "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
            "BLEU = 19.41, 54.2/25.6/15.7/8.3 (BP=0.941, ratio=0.943, hyp_len=3591, ref_len=3808)\n",
            "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
            "BLEU = 20.48, 57.5/27.9/17.2/8.9 (BP=0.921, ratio=0.924, hyp_len=3517, ref_len=3808)\n",
            "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
            "BLEU = 18.89, 54.5/25.6/15.2/7.3 (BP=0.952, ratio=0.953, hyp_len=3628, ref_len=3808)\n",
            "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n"
          ]
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%shell\n",
        "for i in 256 300 350 400 450 500\n",
        "do\n",
        "  onmt_translate -model models/baseQ12_${i}/model_step_2000.pt -src ./BTEC-en-fr/dev/IWSLT10.devset1_CSTAR03.fr.txt_out.tok.txt -output models/Q12_${i}_pred2000.txt\n",
        "done\n",
        "for i in 256 300 350 400 450 500\n",
        "do\n",
        "  perl multi-bleu.perl ./BTEC-en-fr/dev/IWSLT10.devset1_CSTAR03.en.txt_out.tok.txt < models/Q12_${i}_pred2000.txt\n",
        "done"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-z22M7LL1H1"
      },
      "source": [
        "> On obtient comme maximum 20,48% pour 450 unités contre 18,83% pour 256 unités. Augmenter le nombre d'unités semble permettre une petite amélioration du modèle mais trop l'augmenter (ex : 500) ne semble pas apporter grand chose.\n",
        "\n",
        "<span style=\"color:red\">Vous auriez du donner des explications pour vos observations. Aussi, il aurait fallu utiliser l'option early_stopping pour bien repondre à cette question (ainsi que celle précédente). En effet, si l'on utilise pas cette option, on risque de comparer des modèles qui sont sous-entrainé ou sur-entrainés (overfitted),  sans donc pouvoir en tirer des conclusions. En effet, le nombre d'étapes d'entrainement nécessaires à l'optimization du modèle varie selon la quantité de paramétres (poids) à optimizer, ce qui est le cas lorsqu'on varie le nombre de couches ou leur taille.</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLj33q2fMc1i"
      },
      "source": [
        "**Q14**\n",
        "Le beam search est un algorithme de recherche heuristique qui explore un graphe en ne considérant qu'un ensemble limité de fils de chaque nœud. Cet algorithme est une optimisation de l'algorithme de parcours en largeur, en réduisant la mémoire nécessaire à son exécution.\n",
        "\n",
        "<span style=\"color:red\"> C'est quoi les noeuds et les fils dans notre cas ? (les tokens de chaque étape de décodage de la phrase cible, c.à.d. de la traduction) </span>\n",
        "\n",
        "La valeur par défault est 5.\n",
        "\n",
        "**Q15**\n",
        "Faisont varier cette valeur :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NslvTEjSRZD",
        "outputId": "11957e5a-8686-42aa-9d34-b514d5b4ce29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "[2022-02-27 19:09:55,896 INFO] Translating shard 0.\n",
            "/usr/local/lib/python3.7/dist-packages/onmt/translate/beam_search.py:282: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  self._batch_index = self.topk_ids // vocab_size\n",
            "[2022-02-27 19:09:57,770 INFO] PRED AVG SCORE: -1.1265, PRED PPL: 3.0848\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "[2022-02-27 19:09:59,848 INFO] Translating shard 0.\n",
            "/usr/local/lib/python3.7/dist-packages/onmt/translate/beam_search.py:282: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  self._batch_index = self.topk_ids // vocab_size\n",
            "[2022-02-27 19:10:02,559 INFO] PRED AVG SCORE: -1.0296, PRED PPL: 2.7999\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "[2022-02-27 19:10:04,604 INFO] Translating shard 0.\n",
            "/usr/local/lib/python3.7/dist-packages/onmt/translate/beam_search.py:282: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  self._batch_index = self.topk_ids // vocab_size\n",
            "[2022-02-27 19:10:08,024 INFO] PRED AVG SCORE: -1.0016, PRED PPL: 2.7227\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "[2022-02-27 19:10:10,101 INFO] Translating shard 0.\n",
            "/usr/local/lib/python3.7/dist-packages/onmt/translate/beam_search.py:282: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  self._batch_index = self.topk_ids // vocab_size\n",
            "[2022-02-27 19:10:14,215 INFO] PRED AVG SCORE: -0.9879, PRED PPL: 2.6855\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "[2022-02-27 19:10:16,302 INFO] Translating shard 0.\n",
            "/usr/local/lib/python3.7/dist-packages/onmt/translate/beam_search.py:282: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  self._batch_index = self.topk_ids // vocab_size\n",
            "[2022-02-27 19:10:21,174 INFO] PRED AVG SCORE: -0.9815, PRED PPL: 2.6685\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "[2022-02-27 19:10:23,269 INFO] Translating shard 0.\n",
            "/usr/local/lib/python3.7/dist-packages/onmt/translate/beam_search.py:282: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  self._batch_index = self.topk_ids // vocab_size\n",
            "[2022-02-27 19:10:28,804 INFO] PRED AVG SCORE: -0.9763, PRED PPL: 2.6546\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "[2022-02-27 19:10:30,927 INFO] Translating shard 0.\n",
            "/usr/local/lib/python3.7/dist-packages/onmt/translate/beam_search.py:282: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  self._batch_index = self.topk_ids // vocab_size\n",
            "[2022-02-27 19:10:37,213 INFO] PRED AVG SCORE: -0.9732, PRED PPL: 2.6463\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "[2022-02-27 19:10:39,340 INFO] Translating shard 0.\n",
            "/usr/local/lib/python3.7/dist-packages/onmt/translate/beam_search.py:282: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  self._batch_index = self.topk_ids // vocab_size\n",
            "[2022-02-27 19:10:46,233 INFO] PRED AVG SCORE: -0.9780, PRED PPL: 2.6592\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "[2022-02-27 19:10:48,288 INFO] Translating shard 0.\n",
            "/usr/local/lib/python3.7/dist-packages/onmt/translate/beam_search.py:282: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  self._batch_index = self.topk_ids // vocab_size\n",
            "[2022-02-27 19:10:55,968 INFO] PRED AVG SCORE: -0.9777, PRED PPL: 2.6584\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "[2022-02-27 19:10:58,065 INFO] Translating shard 0.\n",
            "/usr/local/lib/python3.7/dist-packages/onmt/translate/beam_search.py:282: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  self._batch_index = self.topk_ids // vocab_size\n",
            "[2022-02-27 19:11:06,520 INFO] PRED AVG SCORE: -0.9788, PRED PPL: 2.6612\n",
            "BLEU = 17.39, 51.1/22.6/13.3/6.0 (BP=1.000, ratio=1.015, hyp_len=3864, ref_len=3808)\n",
            "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
            "BLEU = 18.32, 54.8/25.0/14.9/7.0 (BP=0.941, ratio=0.943, hyp_len=3590, ref_len=3808)\n",
            "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
            "BLEU = 18.14, 55.7/25.7/15.2/7.2 (BP=0.910, ratio=0.914, hyp_len=3480, ref_len=3808)\n",
            "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
            "BLEU = 18.57, 56.8/26.4/15.9/7.9 (BP=0.891, ratio=0.896, hyp_len=3413, ref_len=3808)\n",
            "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
            "BLEU = 18.52, 57.3/26.5/16.2/8.1 (BP=0.876, ratio=0.883, hyp_len=3362, ref_len=3808)\n",
            "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
            "BLEU = 18.44, 57.5/26.7/16.5/8.3 (BP=0.862, ratio=0.870, hyp_len=3314, ref_len=3808)\n",
            "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
            "BLEU = 18.49, 58.4/27.0/16.7/8.6 (BP=0.847, ratio=0.857, hyp_len=3265, ref_len=3808)\n",
            "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
            "BLEU = 18.43, 59.0/27.4/17.1/8.9 (BP=0.828, ratio=0.841, hyp_len=3204, ref_len=3808)\n",
            "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
            "BLEU = 18.67, 59.4/27.9/17.5/9.1 (BP=0.823, ratio=0.837, hyp_len=3187, ref_len=3808)\n",
            "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
            "BLEU = 18.69, 59.7/28.3/17.6/9.1 (BP=0.819, ratio=0.833, hyp_len=3173, ref_len=3808)\n",
            "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n"
          ]
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%shell\n",
        "for i in {1..10}\n",
        "do\n",
        "  onmt_translate --beam_size $i -model models/baseQ6/model_step_2000.pt -src ./BTEC-en-fr/dev/IWSLT10.devset1_CSTAR03.fr.txt_out.tok.txt -output models/Q14_${i}_pred2000.txt\n",
        "done\n",
        "for i in {1..10}\n",
        "do\n",
        "  perl multi-bleu.perl ./BTEC-en-fr/dev/IWSLT10.devset1_CSTAR03.en.txt_out.tok.txt < models/Q14_${i}_pred2000.txt\n",
        "done\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V04POrgoVYWB"
      },
      "source": [
        "> On remarque que le score BLEU croît jusqu'à la valeur du beam à 10.\n",
        "\n",
        "<span style=\"color:red\"> Pourquoi? </span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViIz6Fo3V731"
      },
      "source": [
        "**Q16**\n",
        "> Testons d'obtenir le meilleur score BLEU avec les paramètres suivants :\n",
        "\n",
        "* Un maximum de training steps avec l'option d'arrêt automatique\n",
        "* 1 couche pour l'encodeur et 1 couche pour le décodeur\n",
        "* 450 d'unités pour l'encodeur et le décodeur\n",
        "* Un beam search de taille 10\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7OwLpBQdZaDR"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "onmt_train -config config-baseQ16.yaml -early_stopping 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uo3Hk2ntWH3I",
        "outputId": "774395a8-3e8a-458e-8651-cd12eb4c229f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "[2022-02-27 19:37:05,510 INFO] Translating shard 0.\n",
            "/usr/local/lib/python3.7/dist-packages/onmt/translate/beam_search.py:282: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  self._batch_index = self.topk_ids // vocab_size\n",
            "[2022-02-27 19:37:19,735 INFO] PRED AVG SCORE: -0.4875, PRED PPL: 1.6283\n",
            "BLEU = 35.67, 67.9/42.7/30.8/22.1 (BP=0.952, ratio=0.953, hyp_len=3628, ref_len=3808)\n",
            "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n"
          ]
        }
      ],
      "source": [
        "!onmt_translate --beam_size 10 -model models/baseQ16/model_step_6875.pt -src ./BTEC-en-fr/dev/IWSLT10.devset1_CSTAR03.fr.txt_out.tok.txt -output models/Q16_pred6875.txt\n",
        "!perl multi-bleu.perl ./BTEC-en-fr/dev/IWSLT10.devset1_CSTAR03.en.txt_out.tok.txt < models/Q16_pred6875.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-87_wMjvbvks"
      },
      "source": [
        "> On obtient le score de 35.67%\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ya6XPH-ib225"
      },
      "source": [
        "**Q17**\n",
        "\n",
        "Regardons les prédiction sur le test set pour le comparer au model de la Q6.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q7a8yl-utX1s"
      },
      "outputs": [],
      "source": [
        "!onmt_translate --beam_size 10 -model models/baseQ16/model_step_6875.pt -src ./BTEC-en-fr/test/IWSLT09_BTEC.testset.fr.txt_out.tok.txt -output models/Q16_pred6875_test.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3ag6x4EtYFo"
      },
      "source": [
        "\n",
        "**Exemples**\n",
        "\n",
        "Target : How long will we have to wait ? (line 11)\n",
        "\n",
        "Q6 : How long will it take ?\n",
        "\n",
        "Q17 : How long will we have to wait ?\n",
        "\n",
        "Target : Every ten minutes . (line 17)\n",
        "\n",
        "Q6 : All three days .\n",
        "\n",
        "Q17 : Every ten minutes .\n",
        "\n",
        "Target : Could I get you some coffee or tea ? (line 78)\n",
        "\n",
        "Q6 : Could I have a blanket and a blanket ?\n",
        "\n",
        "Q17 : Could I have a coffee or a coffee ?\n",
        "\n",
        "Target : I believe that this is my seat .\n",
        "(line 233)\n",
        "\n",
        "Q6 : I think this is my room .\n",
        "\n",
        "Q17 : I think this is my seat ."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "TP_NMT_RAMBAUD_PEYRICHOU.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
