{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjf5pW7H0Guf"
      },
      "source": [
        "# TP Relation Extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kuQK4zd1kbL"
      },
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efVai6Q31Cbh"
      },
      "source": [
        "Dans ce TP nous allons:\n",
        "\n",
        "1. Découvrir la tache d’extraction de relation par réseaux neuronaux  (« neural relation extraction », NRE)\n",
        "2.  Comprendre le fonctionnement d’un modèle d’extraction de relation avec un encodeur BERT\n",
        "3. Découvrir la tache de reconnaissance d'entités nommées (« named-entity recognition », NER)\n",
        "4. Coder une pipeline d’extraction de relation par réseaux neuronaux pour des jeux de données textuels\n",
        "\n",
        "Avec les outils suivants:\n",
        "1. La libraire [OpenNRE](https://github.com/thunlp/OpenNRE), basée sur Pytorch et HuggingFace’s Transformers, pour la tache d’extraction de relation par réseaux neuronaux\n",
        "2. [HuggingFace’s Transformers](https://huggingface.co/transformers/) : une bibliothèque basée sur Pytorch pour le traitement automatique des langues et notamment les modèles neuronaux de type Transformer (comme BERT)\n",
        "3. Google Colab, qui héberge ce *Jupyter Notebook*. Avant de commencer le TP, vous pouvez consulter des pages d'introductions [à Colab](https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l01c01_introduction_to_colab_and_python.ipynb#scrollTo=YHI3vyhv5p85) et [aux Notebooks](https://realpython.com/jupyter-notebook-introduction/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhcmAWU7FISp"
      },
      "source": [
        "Contrairement au dernier TP, cette fois-ci nous n’aurons pas besoin d’utiliser une GPU car nous n’allons pas entraîner des nouveaux modèles ou faire de l’inférence sur des grands jeux de données: une CPU suffira. Nous pouvons vérifier si l’on est en train d’utiliser une CPU ou une GPU avec les lignes suivantes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9xBd3ZGgVOB",
        "outputId": "de45e52f-6997-44d1-8920-c6a1b742ef3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Will work on CPU.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  print(\"GPU is available.\")\n",
        "  device = torch.cuda.current_device()\n",
        "else:\n",
        "  print(\"Will work on CPU.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tr1QqSFEGGIH"
      },
      "source": [
        "Nous avons besoin d’installer l’outil OpenNRE. Pour éviter de devoir ré-télécharger le répertoire  GitHub de OpenNRE à chaque fois qu’on ré-initialise le fichier Colab, il est convenant de monter notre répertoire Google Drive et y télécharger le répertoire OpenNRE de façon à l’avoir toujours disponible. Ainsi, à chaque fois que nous allons ré-initialiser le fichier Colab, il nous suffira de monter notre Goodle Drive pour avoir accès à la libraire OpenNRE.\n",
        "\n",
        "> ATTENTION: modifiez *tp_path_in_drive* pour pointer vers le repertoire où vous avez placé le fichier tp_re.ipynb, vous allez télécharger OpenNRE dans le meme réépertoire. Si vous êtes sur votre machine locale, vous n'avez pas besoin de monter le Drive, mais juste de faire le clonage du réépertoire OpenNRE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmWpFhonvmNH",
        "outputId": "1d66f7ac-4119-41ba-b297-c6bbbee26c01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "OpenNRE is already present in Google Drive under /content/drive/My Drive/tp_nlp/tp_re/OpenNRE\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "tp_path_in_drive = '/content/drive/My Drive/tp_nlp/tp_re'\n",
        "opennre_path_in_drive = tp_path_in_drive + '/OpenNRE'\n",
        "\n",
        "# mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "if not os.path.isdir(opennre_path_in_drive):\n",
        "  # OpenNRE is not already present in Google Drive\n",
        "  if not os.path.isdir(tp_path_in_drive):\n",
        "    # make directory for the TP if necessary\n",
        "    os.makedirs(tp_path_in_drive, exist_ok=True)\n",
        "  # change directory to the TP directory\n",
        "  os.chdir(tp_path_in_drive)\n",
        "  # clone OpenNRE repo\n",
        "  print(\"Cloning repo...\")\n",
        "  os.system('git clone https://github.com/thunlp/OpenNRE.git')\n",
        "  print(\"...done!\")\n",
        "else:\n",
        "  print(\"OpenNRE is already present in Google Drive under {0}\".format(opennre_path_in_drive))\n",
        "\n",
        "# Change current dir to OpenNRE\n",
        "os.chdir(opennre_path_in_drive)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q67JhFW7XPcu"
      },
      "outputs": [],
      "source": [
        "# Update requirements\n",
        "!sed -i '/transformers==3.0.2/c\\transformers==3.4.0' requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CofsxJQRON4p"
      },
      "source": [
        "Nous pouvons désormais continuer avec l’installation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8wFXQwfMwxp",
        "outputId": "83c0b1e7-1aa5-4f2c-bebf-3acd818606f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch==1.6.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.6.0)\n",
            "Requirement already satisfied: transformers==3.4.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (3.4.0)\n",
            "Requirement already satisfied: pytest==5.3.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (5.3.2)\n",
            "Requirement already satisfied: scikit-learn==0.22.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (0.22.1)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (1.4.1)\n",
            "Requirement already satisfied: nltk>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (3.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0->-r requirements.txt (line 1)) (1.21.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0->-r requirements.txt (line 1)) (0.16.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0->-r requirements.txt (line 2)) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0->-r requirements.txt (line 2)) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0->-r requirements.txt (line 2)) (2022.3.15)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0->-r requirements.txt (line 2)) (3.17.3)\n",
            "Requirement already satisfied: tokenizers==0.9.2 in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0->-r requirements.txt (line 2)) (0.9.2)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0->-r requirements.txt (line 2)) (0.0.49)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0->-r requirements.txt (line 2)) (3.6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0->-r requirements.txt (line 2)) (4.63.0)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0->-r requirements.txt (line 2)) (0.1.96)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest==5.3.2->-r requirements.txt (line 3)) (8.12.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.12 in /usr/local/lib/python3.7/dist-packages (from pytest==5.3.2->-r requirements.txt (line 3)) (4.11.2)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest==5.3.2->-r requirements.txt (line 3)) (1.11.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest==5.3.2->-r requirements.txt (line 3)) (21.4.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from pytest==5.3.2->-r requirements.txt (line 3)) (0.2.5)\n",
            "Requirement already satisfied: pluggy<1.0,>=0.12 in /usr/local/lib/python3.7/dist-packages (from pytest==5.3.2->-r requirements.txt (line 3)) (0.13.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.22.1->-r requirements.txt (line 4)) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk>=3.6.4->-r requirements.txt (line 6)) (7.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12->pytest==5.3.2->-r requirements.txt (line 3)) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12->pytest==5.3.2->-r requirements.txt (line 3)) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.4.0->-r requirements.txt (line 2)) (3.0.7)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->transformers==3.4.0->-r requirements.txt (line 2)) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.4.0->-r requirements.txt (line 2)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.4.0->-r requirements.txt (line 2)) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.4.0->-r requirements.txt (line 2)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.4.0->-r requirements.txt (line 2)) (3.0.4)\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "writing opennre.egg-info/PKG-INFO\n",
            "writing dependency_links to opennre.egg-info/dependency_links.txt\n",
            "writing top-level names to opennre.egg-info/top_level.txt\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'opennre.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/opennre\n",
            "copying build/lib/opennre/__init__.py -> build/bdist.linux-x86_64/egg/opennre\n",
            "copying build/lib/opennre/pretrain.py -> build/bdist.linux-x86_64/egg/opennre\n",
            "creating build/bdist.linux-x86_64/egg/opennre/encoder\n",
            "copying build/lib/opennre/encoder/cnn_encoder.py -> build/bdist.linux-x86_64/egg/opennre/encoder\n",
            "copying build/lib/opennre/encoder/pcnn_encoder.py -> build/bdist.linux-x86_64/egg/opennre/encoder\n",
            "copying build/lib/opennre/encoder/__init__.py -> build/bdist.linux-x86_64/egg/opennre/encoder\n",
            "copying build/lib/opennre/encoder/bert_encoder.py -> build/bdist.linux-x86_64/egg/opennre/encoder\n",
            "copying build/lib/opennre/encoder/base_encoder.py -> build/bdist.linux-x86_64/egg/opennre/encoder\n",
            "creating build/bdist.linux-x86_64/egg/opennre/framework\n",
            "copying build/lib/opennre/framework/sentence_re.py -> build/bdist.linux-x86_64/egg/opennre/framework\n",
            "copying build/lib/opennre/framework/multi_label_sentence_re.py -> build/bdist.linux-x86_64/egg/opennre/framework\n",
            "copying build/lib/opennre/framework/__init__.py -> build/bdist.linux-x86_64/egg/opennre/framework\n",
            "copying build/lib/opennre/framework/data_loader.py -> build/bdist.linux-x86_64/egg/opennre/framework\n",
            "copying build/lib/opennre/framework/utils.py -> build/bdist.linux-x86_64/egg/opennre/framework\n",
            "copying build/lib/opennre/framework/bag_re.py -> build/bdist.linux-x86_64/egg/opennre/framework\n",
            "creating build/bdist.linux-x86_64/egg/opennre/model\n",
            "copying build/lib/opennre/model/base_model.py -> build/bdist.linux-x86_64/egg/opennre/model\n",
            "copying build/lib/opennre/model/bag_average.py -> build/bdist.linux-x86_64/egg/opennre/model\n",
            "copying build/lib/opennre/model/sigmoid_nn.py -> build/bdist.linux-x86_64/egg/opennre/model\n",
            "copying build/lib/opennre/model/bag_one.py -> build/bdist.linux-x86_64/egg/opennre/model\n",
            "copying build/lib/opennre/model/bag_attention.py -> build/bdist.linux-x86_64/egg/opennre/model\n",
            "copying build/lib/opennre/model/softmax_nn.py -> build/bdist.linux-x86_64/egg/opennre/model\n",
            "copying build/lib/opennre/model/__init__.py -> build/bdist.linux-x86_64/egg/opennre/model\n",
            "creating build/bdist.linux-x86_64/egg/opennre/module\n",
            "copying build/lib/opennre/module/__init__.py -> build/bdist.linux-x86_64/egg/opennre/module\n",
            "creating build/bdist.linux-x86_64/egg/opennre/module/nn\n",
            "copying build/lib/opennre/module/nn/cnn.py -> build/bdist.linux-x86_64/egg/opennre/module/nn\n",
            "copying build/lib/opennre/module/nn/rnn.py -> build/bdist.linux-x86_64/egg/opennre/module/nn\n",
            "copying build/lib/opennre/module/nn/lstm.py -> build/bdist.linux-x86_64/egg/opennre/module/nn\n",
            "copying build/lib/opennre/module/nn/__init__.py -> build/bdist.linux-x86_64/egg/opennre/module/nn\n",
            "creating build/bdist.linux-x86_64/egg/opennre/module/pool\n",
            "copying build/lib/opennre/module/pool/__init__.py -> build/bdist.linux-x86_64/egg/opennre/module/pool\n",
            "copying build/lib/opennre/module/pool/avg_pool.py -> build/bdist.linux-x86_64/egg/opennre/module/pool\n",
            "copying build/lib/opennre/module/pool/max_pool.py -> build/bdist.linux-x86_64/egg/opennre/module/pool\n",
            "creating build/bdist.linux-x86_64/egg/opennre/tokenization\n",
            "copying build/lib/opennre/tokenization/word_piece_tokenizer.py -> build/bdist.linux-x86_64/egg/opennre/tokenization\n",
            "copying build/lib/opennre/tokenization/bert_tokenizer.py -> build/bdist.linux-x86_64/egg/opennre/tokenization\n",
            "copying build/lib/opennre/tokenization/__init__.py -> build/bdist.linux-x86_64/egg/opennre/tokenization\n",
            "copying build/lib/opennre/tokenization/utils.py -> build/bdist.linux-x86_64/egg/opennre/tokenization\n",
            "copying build/lib/opennre/tokenization/word_tokenizer.py -> build/bdist.linux-x86_64/egg/opennre/tokenization\n",
            "copying build/lib/opennre/tokenization/basic_tokenizer.py -> build/bdist.linux-x86_64/egg/opennre/tokenization\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/pretrain.py to pretrain.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/encoder/cnn_encoder.py to cnn_encoder.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/encoder/pcnn_encoder.py to pcnn_encoder.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/encoder/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/encoder/bert_encoder.py to bert_encoder.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/encoder/base_encoder.py to base_encoder.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/framework/sentence_re.py to sentence_re.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/framework/multi_label_sentence_re.py to multi_label_sentence_re.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/framework/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/framework/data_loader.py to data_loader.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/framework/utils.py to utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/framework/bag_re.py to bag_re.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/model/base_model.py to base_model.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/model/bag_average.py to bag_average.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/model/sigmoid_nn.py to sigmoid_nn.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/model/bag_one.py to bag_one.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/model/bag_attention.py to bag_attention.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/model/softmax_nn.py to softmax_nn.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/model/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/module/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/module/nn/cnn.py to cnn.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/module/nn/rnn.py to rnn.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/module/nn/lstm.py to lstm.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/module/nn/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/module/pool/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/module/pool/avg_pool.py to avg_pool.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/module/pool/max_pool.py to max_pool.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/tokenization/word_piece_tokenizer.py to word_piece_tokenizer.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/tokenization/bert_tokenizer.py to bert_tokenizer.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/tokenization/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/tokenization/utils.py to utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/tokenization/word_tokenizer.py to word_tokenizer.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/opennre/tokenization/basic_tokenizer.py to basic_tokenizer.cpython-37.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying opennre.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying opennre.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying opennre.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying opennre.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "creating 'dist/opennre-0.1-py3.7.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing opennre-0.1-py3.7.egg\n",
            "Removing /usr/local/lib/python3.7/dist-packages/opennre-0.1-py3.7.egg\n",
            "Copying opennre-0.1-py3.7.egg to /usr/local/lib/python3.7/dist-packages\n",
            "opennre 0.1 is already the active version in easy-install.pth\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/opennre-0.1-py3.7.egg\n",
            "Processing dependencies for opennre==0.1\n",
            "Finished processing dependencies for opennre==0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt\n",
        "!python setup.py install"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9RIDU84lg4g"
      },
      "source": [
        "## Les modéles pour l'extraction de relation\n",
        "\n",
        "À part offrir un cadre pour l’implémentation et l’entraînement de modelés pour l’extraction de relation, OpenNRE offre aussi des modèles déjà entraînés sur différents jeux de données, et donc capables de détecter différents types de relations entre entités. \n",
        "\n",
        "Ici, nous allons employer un modèle entraîné sur Wiki80 (dataset introduit par [le papier OpenNRE](https://www.aclweb.org/anthology/D19-3029/)), un jeu de données contenant des phrases collectées sur Wikipedia et Wikidata, ainsi que des rélations entre leurs entités. Si vous voulez en savoir plus sur Wiki80, vous pouvez le télécharger avec le script [download_wiki80.sh](https://github.com/thunlp/OpenNRE/blob/60a8ceb42e1cfacbde3c8cfb5f758fb7fe96bdc4/benchmark/download_wiki80.sh) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxT-aqw2PXZO",
        "outputId": "766492cb-4220-46d8-8b0e-e00725e2baad"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-03-21 23:42:26,514 - root - INFO - Loading BERT pre-trained checkpoint.\n"
          ]
        }
      ],
      "source": [
        "import opennre\n",
        "model = opennre.get_model('wiki80_bert_softmax')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYbZ4f4Q9Z-b"
      },
      "source": [
        "Nous pouvons utiliser ce modèle pour calculer la relation entre un mot «tête» et un mot «queue» qui sont contenus dans un texte. Il suffit de passer au modèle le texte ainsi que la position de la tête et de la queue. Le modèle retournera la relation de la queue à l’égard de la tête, ainsi que la probabilité qu’il associe à cette rélation. Par example, nous pouvons inféérer la relation entre **Áed Uaridnach** et **Máel Dúin mac Máele Fithrich** de la façon suivante:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfpSGIJbV2gY",
        "outputId": "d5142fb8-1ec8-4548-9a80-2973b2c01c99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('child', 0.9812852144241333)\n"
          ]
        }
      ],
      "source": [
        "item = {'text': 'He was the son of Máel Dúin mac Máele Fithrich, and grandson of the high king Áed Uaridnach (died 612).', 'h': {'pos': (78, 91)}, 't': {'pos': (18, 46)}}\n",
        "print(model.infer(item))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kacE-LI9mi1"
      },
      "source": [
        "#### Exercice 1\n",
        "\n",
        "\n",
        "\n",
        "Écrire une fonction `to_input_format(text, head, tail)` qui nous permet de trouver la position de deux mots (une tête et une queue) dans un texte, et qui retourne un dictionnaire contenant le texte et les deux positions suivant le format requis par la fonction `model.infer()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBlnOK1HJQN4"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def to_input_format(text, head, tail):\n",
        "  \"\"\"\n",
        "  Args:\n",
        "    text: a string of text\n",
        "    head: a string of text representing a word contained in text\n",
        "    tail: a string of text representing a word contained in text but different from head\n",
        "  Returns:\n",
        "    A dictionary containing the text and the position of the head and tail within it,\n",
        "    following the input format required by an OpenNRE model (see exemple above).\n",
        "  \"\"\"\n",
        "  # ....\n",
        "  dict ={}\n",
        "  dict['text'] = text\n",
        "  dict['h'] = {'pos' : (text.index(head) , text.index(head)+len(head))}\n",
        "  dict['t'] = {'pos' : (text.index(tail) , text.index(tail)+len(tail))}\n",
        "  return(dict)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LX1hgPDO4VVM",
        "outputId": "6f04d3b4-05a9-4904-8e6b-f6514904ff61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Good job!\n"
          ]
        }
      ],
      "source": [
        "# Test your code with this snippet\n",
        "text = 'He was the son of Máel Dúin mac Máele Fithrich, and grandson of the high king Áed Uaridnach (died 612).'\n",
        "head = 'Áed Uaridnach'\n",
        "tail = 'Máel Dúin mac Máele Fithrich'\n",
        "test_item = to_input_format(text, head, tail)\n",
        "try:\n",
        "  assert model.infer(item) == model.infer(test_item)\n",
        "  print(\"Good job!\")\n",
        "except AssertionError:\n",
        "  print(\"Something is wrong with your function, try again!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUeTb4e12e-T"
      },
      "source": [
        "#### Exercice 2\n",
        "\n",
        "Décrire l’architecture du modèle qu’on vient de télécharger, la logique et le fonctionnement de chacun de ses composants:\n",
        "\n",
        "1. Sentence-encoder: pourquoi l'on utilise un encodeur type BERT ?\n",
        "2. À quoi sert la couche BertPooler ?\n",
        "3. À quoi sert la couche linéaire finale (fc) ? pourquoi elle réduit à 80 la dimension du vecteur sortant de l’encodeur?\n",
        "4. À quoi sert la fonction Softmax ?\n",
        "5. À quoi sert la fonction de dropout que l'on appliuque à la sortie du réseau, ainsi que dans chaque couche de BERT ?\n",
        "\n",
        "Aide: vous pouvez inspecter un modèle Pytorch avec `print(model)`. Pour mieux le comprendre, vous pouvez aussi voir [son code](https://github.com/thunlp/OpenNRE/blob/60a8ceb42e1cfacbde3c8cfb5f758fb7fe96bdc4/opennre/model/softmax_nn.py#L5), [la déscription du modèle BERT de Huggingface](https://huggingface.co/docs/transformers/v4.16.2/en/model_doc/bert#transformers.BertModel) ainsi que [son code](https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/models/bert/modeling_bert.py#L848)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcQ_7_W2EEr1",
        "outputId": "70952b19-da57-49f8-9a7d-e6a827aed05b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SoftmaxNN(\n",
            "  (sentence_encoder): BERTEncoder(\n",
            "    (bert): BertModel(\n",
            "      (embeddings): BertEmbeddings(\n",
            "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "        (position_embeddings): Embedding(512, 768)\n",
            "        (token_type_embeddings): Embedding(2, 768)\n",
            "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (encoder): BertEncoder(\n",
            "        (layer): ModuleList(\n",
            "          (0): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (1): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (2): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (3): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (4): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (5): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (6): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (7): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (8): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (9): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (10): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (11): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (pooler): BertPooler(\n",
            "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (activation): Tanh()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (fc): Linear(in_features=768, out_features=80, bias=True)\n",
            "  (softmax): Softmax(dim=-1)\n",
            "  (drop): Dropout(p=0.5, inplace=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5-D4fx9AYn8"
      },
      "source": [
        "1. Contrairement aux modèles unidirectionnels, qui lisent le texte saisi de manière séquentielle (de gauche à droite ou de droite à gauche), l'encodeur du Transformer dans le modèle de BERT lit toute la séquence de mots en une fois. Cette caractéristique permet au modèle d'apprendre le contexte d'un mot en fonction de tout son environnement (gauche et droite du mot).\n",
        "\n",
        "2. la couche BertPooler prend la représentation de sortie correspondant au premier jeton et l'utilise pour les tâches en avale. La couche applique une transformation tanh sur la représentation du premier token. La transformation tanh est entraînée en utilisant la stratégie de prédiction de la phrase suivante (NSP). **tanh est une fonction d'activation. On n'entraîne pas les fonctions d'activation. C'est la transformation linéaire précédente qui est entraînée**\n",
        "\n",
        "3. La couche linéaire finale est une couche totalement connectée qui projette simplement la sortie précédente dans un espace de la taille de notre vocab. **la taille de sortie est le nombre de rélations (classes) possibles, définies par wiki80 (donc 80 classes)**\n",
        "\n",
        "4. La fonction Softmax sert à générer une distribution de probabilité des mots prédits.Elle donne alors l'élément le plus probable à prédire (on prend le mot de la colonne qui donne la probabilité la plus haute). **Non. Le modèle prédit une rélation entre head et tail (parmi les 80 disponibles), et non pas des mots.**\n",
        "\n",
        "5. La fonction dropout est une fonction qui bloque la sortie de certains neurones de façon à pousser le modèle à apprendre l'information sans tomber dans le sur-apprentissage. **Ce n'est pas très claire comment le dropout aide le modèle à ne pas faire de l'overfitting. Ca veut dire quoi \"sur-apprentissage\"?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxlyOgFU3GQs"
      },
      "source": [
        "## Encodeur"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWvfXCFlvf4q"
      },
      "source": [
        "#### Exercice 3\n",
        "\n",
        "Maintenant, nous allons essayer de mieux comprendre le fonctionnement de ce modèle avec un focus sur son encodeur, qui est définit dans le fichier [bert_encoder.py](https://github.com/thunlp/OpenNRE/blob/60a8ceb42e1cfacbde3c8cfb5f758fb7fe96bdc4/opennre/encoder/bert_encoder.py#L7). Ce qui est spécifique à la tache de NRE dans ce modèle n’est pas l’architecture, mais plutôt la façon dont la séquence en input est tokenisée. Avec l’objectif de bien comprendre comment cet encodeur gère son input, répondez en détail aux questions suivantes qui se référent à la méthode `tokenize`. Si vous utilisez du code pour vous aider à répondre (conseillé), veuillez le joindre à vos réponses textuelles.\n",
        "\n",
        "1. Qu’est-ce qu’elle sont les variables `sent0`, `ent0`, `sent1`, `ent1`, `sent2` ?\n",
        "2. Qu’est-ce que c’est `re_tokens` ?\n",
        "3. Dans le _forward_, le `BERTEncoder` prend en entrée exclusivement la séquence textuelle qui a étée préalablement tokenisée. Comment est-il capable de distinguer la tête et la queue en sort de (apprendre à) prédire la relation entre les deux ?\n",
        "4. Qu’est-ce que c’est le « Padding » et pourquoi est-il utile ?\n",
        "5. Qu’est-ce que c’est l’ « Attention mask » et pourquoi est-elle utile ? [Aide ici](https://huggingface.co/docs/transformers/v4.16.2/en/glossary#attention-mask)\n",
        "6. **[BONUS]** Quelle est la différence entre la classe `BERTEncoder` et la classe `BERTEntityEncoder`, définie dans le même fichier ?\n",
        "\n",
        "\n",
        "Aide : vous pouvez accéder à la méthode `tokenize` pour la tester avec `model.sentence_encoder.tokenize(item)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "te30zT02s_Tt",
        "outputId": "8c3b821c-b035-47b1-ea78-63b7efb5b370"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(tensor([[  101,  2002,  2001,  1996,  2365,  1997,     3, 11530,  2140,  4241,\n",
            "          2378,  6097, 11530,  2571,  4906, 26378,  2818,     4,  1010,  1998,\n",
            "          7631,  1997,  1996,  2152,  2332,     1, 29347,  2094, 25423, 14615,\n",
            "         18357,  2232,     2,  1006,  2351,  6079,  2475,  1007,  1012,   102,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]), tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]]), tensor([[25]]), tensor([[6]]))\n"
          ]
        }
      ],
      "source": [
        "# Write your code here if needed, and then write your detailed answers below.\n",
        "print(model.sentence_encoder.tokenize(item))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fh5CP5HA0dLq"
      },
      "source": [
        "1.\n",
        ">**sent 0 :** représente la partie de la phrase qui se trouve avant head si celui-ci n'est pas inversé avec tail . Si tail vient en premier dans la phrase, sent0 représente la partie de la phrase qui est avant tail.\n",
        "\n",
        ">**ent0 :**  représente head si sa position vient avant celle du tail, sinon tail.\n",
        "\n",
        ">**sent1 :** représente la partie de la phrase entre head et tail.\n",
        "\n",
        ">**ent1 :** représente tail si sa position vient après head. Il représentent head si head et tail sont inversés.\n",
        "\n",
        ">**sent2 :**  représente la partie de la phrase après le tail, s'il est pas inversé avec head.\n",
        "\n",
        "2. re_tokens représente la séquence textuelle tokenisée finale. C'est la phrase avec les tokens et les tokens spéciaux [CLS] et [SEP].\n",
        "\n",
        "3. la variable rev permet à la fonction forward de BERTEncoder de distinguer head et tail et de les positionner dans la séquence textuelle. **le réseau BERTEncoder apprend à distinguer la tête et la queue du reste du texte grace aux tokens \"unused\" qui ont été introduits à la tokenization**\n",
        "\n",
        "4. Le modèle BERT reçoit en entrée une phrase de longueur fixe. Pour les phrases qui sont plus courtes que cette longueur maximale, nous devrons ajouter des paddings pour compenser la longueur. **Pourquoi est-il utile d'uniformer la longueur? -> pour qu'on puisse representer un lot de phrases avec une matrice, ce qui est nécessaire au réseau pour traiter les phrases en parallèle.**\n",
        "\n",
        "\n",
        "5. Attention mask est une sorte de couche contenant des 0 et des 1 permettons de propager l'information ou pas à la couche suivante. Il permet de controler les inputs pris en considération dans les calcul et d'annuler ceux qui sont inutiles comme [PAD] qui est un token utilisé seulement pour la forme."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99yJxX0-Z1h1"
      },
      "source": [
        "## NRE Pipeline\n",
        "\n",
        "Nous allons maintenant programmer une application qui prend en entrée une phrase et donne en sortie deux entités nommées dans la phrase ainsi que la relation entre eux.\n",
        "\n",
        "Pour ce faire, nous avons besoin :\n",
        "\n",
        "1. d’un système NER, qui reconnaît les entités nommées dans la phrase\n",
        "2. d’un système NRE, comme celui que nous avons utilisé jusqu’à là"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZYCITLLa0ii"
      },
      "source": [
        "#### Exercice 4\n",
        "\n",
        "En vous aident avec la documentation de HuggingFace, instanciez une [pipeline](https://huggingface.co/transformers/main_classes/pipelines.html?highlight=pipeline#the-pipeline-abstraction) `ner_pipeline` pour la reconnaissance d'entités nommées, avec le modèle et le tokeniseur pré-entraînes [dbmdz/bert-large-cased-finetuned-conll03-english](https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
        "\n",
        "Vous pouvez tester la bonne réussite de l’exercice avec le code ci-dessous.\n",
        "\n",
        "**Indice** : la solution consiste en deux lignes de code : l'une pour importer la classe pipeline, l'autre pour instancier la bonne pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "323UWMt1Z3y0"
      },
      "outputs": [],
      "source": [
        "# Write your code here\n",
        "from transformers import pipeline,AutoModelForTokenClassification, AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n",
        "model = AutoModelForTokenClassification.from_pretrained(\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n",
        "ner_pipeline = pipeline(\"ner\", model = model, tokenizer = tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhdvbovPBZmP",
        "outputId": "782e772c-9030-474e-8216-f925ed5da4ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Good job!\n"
          ]
        }
      ],
      "source": [
        "# Apply your ner_pipeline to some sentences to see how it works,\n",
        "# Then you can test your code with this snippet\n",
        "# If the output of you pipeline is very similar to the list below,\n",
        "# with minor differences in the probabilities assigned to each entity,\n",
        "# then it's fine. Don't worry if the assert condition returns False.\n",
        "text = 'He was the son of Máel Dúin mac Máele Fithrich, and grandson of the high king Áed Uaridnach (died 612).'\n",
        "try:\n",
        "  assert ner_pipeline(text) == [\n",
        "                                {'entity': 'I-PER', 'index': 6, 'score': 0.982085645198822, 'word': 'M'},\n",
        "                                {'entity': 'I-PER', 'index': 7, 'score': 0.8588601350784302, 'word': '##á'},\n",
        "                                {'entity': 'I-PER', 'index': 8, 'score': 0.8766007423400879, 'word': '##el'},\n",
        "                                {'entity': 'I-PER', 'index': 9, 'score': 0.8375428915023804, 'word': 'D'},\n",
        "                                {'entity': 'I-PER', 'index': 10, 'score': 0.4897182583808899, 'word': '##ú'},\n",
        "                                {'entity': 'I-PER', 'index': 11, 'score': 0.901253342628479, 'word': '##in'},\n",
        "                                {'entity': 'I-PER', 'index': 12, 'score': 0.5821399688720703, 'word': 'mac'},\n",
        "                                {'entity': 'I-PER', 'index': 13, 'score': 0.8884768486022949, 'word': 'M'},\n",
        "                                {'entity': 'I-PER', 'index': 14, 'score': 0.7004077434539795, 'word': '##á'},\n",
        "                                {'entity': 'I-PER', 'index': 15, 'score': 0.8791088461875916, 'word': '##ele'},\n",
        "                                {'entity': 'I-PER', 'index': 16, 'score': 0.9720047116279602, 'word': 'Fi'},\n",
        "                                {'entity': 'I-PER', 'index': 17, 'score': 0.697806715965271, 'word': '##th'},\n",
        "                                {'entity': 'I-PER', 'index': 18, 'score': 0.697088360786438, 'word': '##rich'},\n",
        "                                {'entity': 'I-PER', 'index': 26, 'score': 0.9203088283538818, 'word': 'Á'},\n",
        "                                {'entity': 'I-PER', 'index': 27, 'score': 0.9416706562042236, 'word': '##ed'},\n",
        "                                {'entity': 'I-PER', 'index': 28, 'score': 0.9702795147895813, 'word': 'U'},\n",
        "                                {'entity': 'I-PER', 'index': 29, 'score': 0.8428962230682373, 'word': '##ari'},\n",
        "                                {'entity': 'I-PER', 'index': 31, 'score': 0.7077912092208862, 'word': '##ach'}\n",
        "                              ]\n",
        "  print(\"Good job!\")\n",
        "except AssertionError:\n",
        "  print(\"Something might be wrong with your pipeline.\") "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOzSPqsJKkve"
      },
      "source": [
        "#### Exercice 5\n",
        "\n",
        "\n",
        "Nous pouvons finalement développer une pipeline NRE reposante sur notre modèle de NRE et notre pipeline NER. \n",
        "\n",
        "Écrivez ci-dessous une classe `NREPipeline` équipée (entre autres) d'une méthode `__call__(self, text)` qui prend un texte en entrée et effectue les opérations suivantes :\n",
        "\n",
        "- elle reconnaît les entités dans le texte\n",
        "    - retenir seulement les deux entités auxquelles la pipeline NER associe la probabilité la plus élevée, écarter les autres (si presentes)\n",
        "    - si la pipeline NER ne reconnaît qu’une seule entités dans le texte, `__call__(self, text)` retourne None (voir le test en bas) car il n’y a aucune relation à prédire\n",
        "- elle donne en sortie une liste en format `[e1, e2, rel, p]` où :\n",
        "    - `e1` est la première entité reconnue dans le texte (entre les deux plus probables, la première qui apparaître dans le texte)\n",
        "    - `e2` est la deuxième entité  reconnue dans le texte (entre les deux plus probables, la deuxième qui apparaître dans le texte)\n",
        "    - `rel` est la relation qu’il y a entre `e1` et `e2`\n",
        "    - `p` est la probabilité associée à la relation `rel` par le modèle de NRE\n",
        "\n",
        "Pour vérifier la bonne qualité de votre classe `NREPipeline`, utilisez l’extrait de code ci-dessous. Le résultat devrait ressabler à celui-ci :\n",
        "\n",
        "````\n",
        "Sentence 0: He was the son of Máel Dúin mac Máele Fithrich, and grandson of the high king Áed Uaridnach (died 612).\n",
        "System out:  ['Máel Dúin mac Máele Fithrich', 'Áed Uari', 'father', 0.9923498034477234]\n",
        "------------------------------\n",
        "Sentence 1: He was the son of Máel Dúin\n",
        "System out:  None\n",
        "------------------------------\n",
        "Sentence 2: Ōda is home to the Ōda Iwami Ginzan Silver Mine , a World Heritage Site .\n",
        "System out:  ['I', 'World Heritage Site', 'heritage designation', 0.9991846680641174]\n",
        "------------------------------\n",
        "Sentence 3: It has been shown to be equally effective as leuprorelin , which is a second - line medication against endometriosis .\n",
        "System out:  None\n",
        "------------------------------\n",
        "Sentence 4: Located at Earleville and listed on the National Register of Historic Places are : Bohemia Farm , Mount Harmon , Rose Hill , and St. Stephen 's Episcopal Church .\n",
        "System out:  ['Earleville', \"St . Stephen ' s Episcopal Church\", 'location', 0.9127373099327087]\n",
        "------------------------------\n",
        "````"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kXeIMmj69f4R"
      },
      "outputs": [],
      "source": [
        "model = opennre.get_model('wiki80_bert_softmax')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ToAxtF4nZ_Bq"
      },
      "outputs": [],
      "source": [
        "# Write your pipeline in this cell. The fun begins here, because we are coding a whole Python class from scratch !\n",
        "from itertools import combinations\n",
        "class NREPipeline(object):\n",
        "  def __init__(self, ner_pipeline, nre_model):\n",
        "    self.ner = ner_pipeline\n",
        "    self.nre = nre_model\n",
        "\n",
        "  # ...\n",
        "\n",
        "  def __call__(self, text):\n",
        "    dict = [(elem['index'],elem['word']) for elem in ner_pipeline(text) if elem['word'] !='[UNK]']\n",
        "    i=0\n",
        "    while i <len(dict):\n",
        "      if dict [i][1][:2] !='##' or dict[i-1][0]+1 != dict[i][0]:\n",
        "        dict.insert(i, (dict[i-1][0]+1, ' '))\n",
        "        i+=1\n",
        "      i+=1\n",
        "    entities_detected = []\n",
        "    space_index=0\n",
        "    for i in range(1, len(dict)):\n",
        "      if dict[i - 1][1] == ' ' and dict[i - 1][0] != dict[i][0]:\n",
        "        entities_detected.append([dict[j][1] for j in range(space_index, i - 1)])\n",
        "        space_index = i\n",
        "    entities_detected.append([dict[i][1] for i in range(space_index, len(dict))])\n",
        "    entities_detected = [''.join(entity).replace(\" ' \", \" '\") for entity in entities_detected]\n",
        "    entities_detected = [''.join(entity).replace(\" . \", \". \") for entity in entities_detected]\n",
        "    entities_detected = [''.join(entity).replace('##', '') for entity in entities_detected]\n",
        "    output = (0,0)\n",
        "    if len(entities_detected) >= 2:\n",
        "      for elem in combinations(entities_detected, 2):\n",
        "        item = to_input_format(text, elem[0], elem[1])\n",
        "        if model.infer(item)[1] > output[1]:\n",
        "          output = model.infer(item)\n",
        "          output1 = elem\n",
        "      return list(output1 + output)\n",
        "    else:\n",
        "      return None\n",
        "   # ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaWrZEJc4IDK",
        "outputId": "7156e84c-fa71-4830-c090-f22718c713d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence 0: He was the son of Máel Dúin mac Máele Fithrich, and grandson of the high king Áed Uaridnach (died 612).\n",
            "System out:  ['Máel Dúin mac Máele Fithrich', 'Áed Uari', 'father', 0.9923498034477234]\n",
            "------------------------------\n",
            "Sentence 1: He was the son of Máel Dúin\n",
            "System out:  ['', 'Máel Dúin', 'child', 0.9939715266227722]\n",
            "------------------------------\n",
            "Sentence 2: Ōda is home to the Ōda Iwami Ginzan Silver Mine , a World Heritage Site .\n",
            "System out:  ['Iwami Ginzan', 'World Heritage Site', 'heritage designation', 0.9992959499359131]\n",
            "------------------------------\n",
            "Sentence 3: It has been shown to be equally effective as leuprorelin , which is a second - line medication against endometriosis .\n",
            "System out:  None\n",
            "------------------------------\n",
            "Sentence 4: Located at Earleville and listed on the National Register of Historic Places are : Bohemia Farm , Mount Harmon , Rose Hill , and St. Stephen 's Episcopal Church .\n",
            "System out:  ['Earleville', 'National Register of Historic Places', 'heritage designation', 0.9995023012161255]\n",
            "------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Test your code with this snippet\n",
        "\n",
        "sequences = [\n",
        "             'He was the son of Máel Dúin mac Máele Fithrich, and grandson of the high king Áed Uaridnach (died 612).', # Easy sentence\n",
        "             'He was the son of Máel Dúin', # There is only one entity in this sentence, therefore our pipeline should return None\n",
        "             'Ōda is home to the Ōda Iwami Ginzan Silver Mine , a World Heritage Site .', # Ōda is tokenized by the NER tokenizer as a \"[UNK]\" and it is detected as an entitity. For simplicity, you can discard [UNK] entities as if they were not detected. Here another difficulty arises from the fact that the different tokens in which Iwami Ginzan is decomposed are (wrongly) classified as entities belonging to different classes. In this case, we can consider only the first token \"I\" as standalone entity, for simplicity.  \n",
        "             'It has been shown to be equally effective as leuprorelin , which is a second - line medication against endometriosis .', # the NER system can not recognise any entity here, therefore the pipeline should return None\n",
        "             \"Located at Earleville and listed on the National Register of Historic Places are : Bohemia Farm , Mount Harmon , Rose Hill , and St. Stephen 's Episcopal Church .\" # This sentence is not trivial because the 's has to be managed properly\n",
        "\n",
        "]\n",
        "\n",
        "nre = NREPipeline(ner_pipeline, model)\n",
        "for n, sequence in enumerate(sequences):\n",
        "  out = nre(sequence)\n",
        "  print(\"Sentence {0}: {1}\".format(n, sequence))\n",
        "  print(\"System out: \", out)\n",
        "  print('------------------------------')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sl-hqEfaLvI-"
      },
      "source": [
        "## Application de le pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKfvPq_KLmD-"
      },
      "source": [
        "#### Exercice 6\n",
        "\n",
        "1. Appliquez la pipeline NRE aux phrases contenues dans le fichier _sentences.txt_, qui ont été extraites à partir de Wikipedia et Wikidata. Donnez un avis qualitatif sur sa performance, les problèmes rencontrés ainsi que des idées pour améliorations des résultats (e.g. entraînement sur des données différentes, modèle différent, etc.).\n",
        "\n",
        "2. Appliquez la pipeline NRE aux premières 50 phrases contenues dans le fichier _Sentences_AllAgree.txt_ que vous avez utilisé pour le TP BERT, qui parlent d’événements financiers. Remarquez-vous des différences en terme de performances par rapport à la question 2 ? Pourquoi ? Commentez…"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 796
        },
        "id": "4T2moXc3IA3f",
        "outputId": "b649663e-1f89-490e-abf2-ed43a6df7c7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence 0: The Willard and Josephine Hubbard House was individually listed on the National Register of Historic Places in 2016 .\n",
            "\n",
            "System out:  ['Josephine Hubbard House', 'National Register of Historic Places', 'heritage designation', 0.9995538592338562]\n",
            "------------------------------\n",
            "Sentence 1: His station commander , Group Captain Claude Hilton Keith , found a letter among the missing airman 's personal possessions .\n",
            "\n",
            "System out:  ['', 'Claude Hilton Keith', 'military rank', 0.9315220713615417]\n",
            "------------------------------\n",
            "Sentence 2: One was Quintus Caecilius Metellus Creticus , who was praetor in 74 BC and consul in 69 BC .\n",
            "\n",
            "System out:  ['', 'Quintus Caecilius Metellus Creticus', 'sibling', 0.3768742084503174]\n",
            "------------------------------\n",
            "Sentence 3: April 2009 In addition to musical acts , the label recorded beat poets Lawrence Ferlinghetti and Allen Ginsberg and comic Lenny Bruce .\n",
            "\n",
            "System out:  ['', 'Lawrence Ferlinghetti', 'participant', 0.9849905371665955]\n",
            "------------------------------\n",
            "Sentence 4: Walter Neusel ( November 25 , 1907 â October 3 , 1964 ) was a German heavyweight boxer .\n",
            "\n",
            "System out:  ['Walter Neusel', 'German', 'country of citizenship', 0.9982714653015137]\n",
            "------------------------------\n",
            "Sentence 5: HÃ©rcules debut defending the national team was a 1938 FIFA World Cup game , played on June 5 , 1938 , against Poland .\n",
            "\n",
            "System out:  ['FIFA World Cup', 'Poland', 'participating team', 0.9968666434288025]\n",
            "------------------------------\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-98-0292401e3b98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNREPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mner_pipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnre\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Sentence {0}: {1}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"System out: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-96-ef912d191f28>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities_detected\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities_detected\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_input_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m           \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-45-b11b8caa5b44>\u001b[0m in \u001b[0;36mto_input_format\u001b[0;34m(text, head, tail)\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0mdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'h'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'pos'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m   \u001b[0mdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m't'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'pos'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtail\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtail\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtail\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m   \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: substring not found"
          ]
        }
      ],
      "source": [
        "# Write your code here and then write your detailed answers below. Do not hesitate to use more code cells if needed\n",
        "filename = '../sentences.txt'\n",
        "file = open(filename, 'rt', encoding=\"ISO-8859-1\")\n",
        "nre = NREPipeline(ner_pipeline, model)\n",
        "for n, sequence in enumerate(file):\n",
        "  out = nre(sequence)\n",
        "  print(\"Sentence {0}: {1}\".format(n, sequence))\n",
        "  print(\"System out: \", out)\n",
        "  print('------------------------------')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6wXsUGMu8yq1",
        "outputId": "f9f8f284-3f4d-4f5e-d45d-ba1d463b5670"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence 0: According to Gran , the company has no plans to move all production to Russia , although that is where the company is growing .@neutral\n",
            "\n",
            "System out:  ['', 'Russia', 'country', 0.9923490285873413]\n",
            "------------------------------\n",
            "Sentence 1: For the last quarter of 2010 , Componenta 's net sales doubled to EUR131m from EUR76m for the same period a year earlier , while it moved to a zero pre-tax profit from a pre-tax loss of EUR7m .@positive\n",
            "\n",
            "System out:  ['EU', 'EU', 'applies to jurisdiction', 0.8518947958946228]\n",
            "------------------------------\n",
            "Sentence 2: In the third quarter of 2010 , net sales increased by 5.2 % to EUR 205.5 mn , and operating profit by 34.9 % to EUR 23.5 mn .@positive\n",
            "\n",
            "System out:  ['EU', 'EU', 'member of', 0.6252642869949341]\n",
            "------------------------------\n",
            "Sentence 3: Operating profit rose to EUR 13.1 mn from EUR 8.7 mn in the corresponding period in 2007 representing 7.7 % of net sales .@positive\n",
            "\n",
            "System out:  ['EU', 'EU', 'applies to jurisdiction', 0.3409990072250366]\n",
            "------------------------------\n",
            "Sentence 4: Operating profit totalled EUR 21.1 mn , up from EUR 18.6 mn in 2007 , representing 9.7 % of net sales .@positive\n",
            "\n",
            "System out:  ['EU', 'EU', 'member of', 0.3967757821083069]\n",
            "------------------------------\n",
            "Sentence 5: Finnish Talentum reports its operating profit increased to EUR 20.5 mn in 2005 from EUR 9.3 mn in 2004 , and net sales totaled EUR 103.3 mn , up from EUR 96.4 mn .@positive\n",
            "\n",
            "System out:  ['', 'Finnish Talentum', 'owned by', 0.902212917804718]\n",
            "------------------------------\n",
            "Sentence 6: Clothing retail chain Sepp+ñl+ñ 's sales increased by 8 % to EUR 155.2 mn , and operating profit rose to EUR 31.1 mn from EUR 17.1 mn in 2004 .@positive\n",
            "\n",
            "System out:  ['EU', 'EU', 'applies to jurisdiction', 0.957264244556427]\n",
            "------------------------------\n",
            "Sentence 7: Consolidated net sales increased 16 % to reach EUR74 .8 m , while operating profit amounted to EUR0 .9 m compared to a loss of EUR0 .7 m in the prior year period .@positive\n",
            "\n",
            "System out:  ['', 'EU', 'follows', 0.5484582185745239]\n",
            "------------------------------\n",
            "Sentence 8: Foundries division reports its sales increased by 9.7 % to EUR 63.1 mn from EUR 57.5 mn in the corresponding period in 2006 , and sales of the Machine Shop division increased by 16.4 % to EUR 41.2 mn from EUR 35.4 mn in the corresponding period in 2006 .@positive\n",
            "\n",
            "System out:  ['', 'Foundries', 'subsidiary', 0.9025299549102783]\n",
            "------------------------------\n",
            "Sentence 9: HELSINKI ( AFX ) - Shares closed higher , led by Nokia after it announced plans to team up with Sanyo to manufacture 3G handsets , and by Nokian Tyres after its fourth-quarter earnings report beat analysts ' expectations , dealers said .@positive\n",
            "\n",
            "System out:  ['', 'Nokian Tyres', 'headquarters location', 0.9552478194236755]\n",
            "------------------------------\n",
            "Sentence 10: Its board of directors will propose a dividend of EUR0 .12 per share for 2010 , up from the EUR0 .08 per share paid in 2009 .@positive\n",
            "\n",
            "System out:  ['EU', 'EU', 'has part', 0.9053260087966919]\n",
            "------------------------------\n",
            "Sentence 11: MegaFon 's subscriber base increased 16.1 % in 2009 to 50.5 million users as of December 31 , while its market share by the number of customers amounted to 24 % as of late 2009 , up from 23 % as of late 2008 , according to TeliaSonera estimates .@positive\n",
            "\n",
            "System out:  ['MegaFon', 'TeliaSonera', 'owned by', 0.9980899691581726]\n",
            "------------------------------\n",
            "Sentence 12: Net income from life insurance doubled to EUR 6.8 mn from EUR 3.2 mn , and net income from non-life insurance rose to EUR 5.2 mn from EUR 1.5 mn in the corresponding period in 2009 .@positive\n",
            "\n",
            "System out:  ['EU', 'EU', 'applies to jurisdiction', 0.6576498746871948]\n",
            "------------------------------\n",
            "Sentence 13: Net sales increased to EUR193 .3 m from EUR179 .9 m and pretax profit rose by 34.2 % to EUR43 .1 m. ( EUR1 = USD1 .4 )@positive\n",
            "\n",
            "System out:  ['EU', 'EU', 'has part', 0.6302096843719482]\n",
            "------------------------------\n",
            "Sentence 14: Net sales surged by 18.5 % to EUR167 .8 m. Teleste said that EUR20 .4 m , or 12.2 % , of the sales came from the acquisitions made in 2009 .@positive\n",
            "\n",
            "System out:  ['', 'Teleste', 'owned by', 0.9878984093666077]\n",
            "------------------------------\n",
            "Sentence 15: Nordea Group 's operating profit increased in 2010 by 18 percent year-on-year to 3.64 billion euros and total revenue by 3 percent to 9.33 billion euros .@positive\n",
            "\n",
            "System out:  ['', 'Nordea Group', 'owned by', 0.9232726693153381]\n",
            "------------------------------\n",
            "Sentence 16: Operating profit for the nine-month period increased from EUR13 .6 m , while net sales increased from EUR394 .7 m , as compared to the corresponding period in 2005 .@positive\n",
            "\n",
            "System out:  ['', 'EU', 'applies to jurisdiction', 0.927760660648346]\n",
            "------------------------------\n",
            "Sentence 17: Operating profit for the three-month period increased from EUR1 .2 m , while revenue increased from EUR20 .2 m , as compared to the corresponding period in 2005 .@positive\n",
            "\n",
            "System out:  ['', 'EU', 'applies to jurisdiction', 0.9488322734832764]\n",
            "------------------------------\n",
            "Sentence 18: The company 's net profit rose 11.4 % on the year to 82.2 million euros in 2005 on sales of 686.5 million euros , 13.8 % up on the year , the company said earlier .@positive\n",
            "\n",
            "System out:  None\n",
            "------------------------------\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-99-2f5c9393f1ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNREPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mner_pipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnre\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Sentence {0}: {1}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"System out: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-96-ef912d191f28>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities_detected\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities_detected\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_input_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m           \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-45-b11b8caa5b44>\u001b[0m in \u001b[0;36mto_input_format\u001b[0;34m(text, head, tail)\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0mdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'h'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'pos'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m   \u001b[0mdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m't'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'pos'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtail\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtail\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtail\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m   \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: substring not found"
          ]
        }
      ],
      "source": [
        "filename = '../Sentences_AllAgree.txt'\n",
        "file = open(filename, 'rt', encoding=\"ISO-8859-1\")\n",
        "nre = NREPipeline(ner_pipeline, model)\n",
        "for n, sequence in enumerate(file):\n",
        "  out = nre(sequence)\n",
        "  print(\"Sentence {0}: {1}\".format(n, sequence))\n",
        "  print(\"System out: \", out)\n",
        "  print('------------------------------')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "tp_re.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
