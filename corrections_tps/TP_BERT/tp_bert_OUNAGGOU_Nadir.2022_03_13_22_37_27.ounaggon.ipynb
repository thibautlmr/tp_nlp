{"cells":[{"cell_type":"markdown","metadata":{"id":"VYYjrbod7F3V"},"source":["# TP BERT\n","\n"]},{"cell_type":"markdown","metadata":{"id":"BJX8UgsoZMtQ"},"source":["## Introduction"]},{"cell_type":"markdown","metadata":{"id":"drnebPZ26_yA"},"source":["Dans ce TP nous allons:\n","0. Comprendre comment utiliser un *Jupyter Notebook*, un outil très populaire en analyse des données\n","1. Préparer un jeu de données pour l’apprentissage d’un modèle BERT\n","3. Comprendre comment utiliser un modèle BERT pré-entraîné\n","4. Créer un modèle de classification en classes multiples qui exploite les représentations cachés d’un encodeur BERT\n","5. Entraîner ce modèle et tester ses performances\n","\n","Avec les outils suivants:\n","1. [PyTorch](https://pytorch.org/docs/stable/index.html) : une bibliothèque Python *open-source* pour l'apprentissage machine\n","2. [HuggingFace’s Transformers](https://huggingface.co/transformers/) : une bibliothèque basée sur Pytorch pour le traitement automatique des langues et notamment les modèles neuronaux de type Transformer (comme BERT)\n","3. [HuggingFace’s Tokenizers](https://github.com/huggingface/tokenizers): une bibliothèque basée sur Pytorch pour la tokenisation, explicitement conçue pour travailler avec la bibliothèque Transformers\n","4. Google Colab, qui héberge ce *Jupyter Notebook*. Avant de commencer le TP, il est conseillé de consulter les pages d'introductions [à Colab](https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l01c01_introduction_to_colab_and_python.ipynb#scrollTo=YHI3vyhv5p85) et [aux Notebooks](https://realpython.com/jupyter-notebook-introduction/)\n","\n","\n","Les machines Colab sont livrées avec un système Linux et un environnement Python avec plusieurs bibliothèques pré-installées comme, par exemple, Pytorch. Néanmoins, si vous êtes sur une machine Colab, il faut d'abord installer les bibliothèques de HuggingFace, qui ne sont pas pré-installées.\n","\n","Pour exécuter une commande Unix sur un Jupyter Notebook, il faut placer un point d’exclamation avant la commande: `!commande`. "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13344,"status":"ok","timestamp":1647204893378,"user":{"displayName":"Nadir Ounaggou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14687011903990117142"},"user_tz":-60},"id":"OvdKhj2zlq03","outputId":"686c1144-f0d3-4c77-e4a4-65d98b45f162"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting transformers\n","  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n","\u001b[K     |████████████████████████████████| 3.8 MB 4.0 MB/s \n","\u001b[?25hCollecting tokenizers\n","  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n","\u001b[K     |████████████████████████████████| 6.5 MB 36.8 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 5.4 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 53.9 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 46.9 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.11.6 transformers-4.17.0\n"]}],"source":["%pip install transformers tokenizers"]},{"cell_type":"markdown","metadata":{"id":"eknnVYcJT7-g"},"source":["Maintenant nous pouvons importer les bibliothéques principales dont nous aurons besoin. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RQfvlh9lllN-"},"outputs":[],"source":["import torch\n","import transformers\n","\n","# Managing arrays\n","import numpy as np\n","\n","# Plotting tools:\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","# load the TensorBoard notebook extension\n","%load_ext tensorboard"]},{"cell_type":"markdown","metadata":{"id":"t9aD8i7_XGe9"},"source":["**GPU**\n","\n","L'apprentissage de notre réseau de neurones requiert beaucoup de calculs matriciels. Pour exécuter ces calculs plus rapidement, il est possible d'utiliser un processeur graphique (*GPU*) p. Si vous êtes sur Colab, vous pouvez utiliser un *GPU* en sélectionnant _Runtime -> Change runtime type -> GPU_."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1647204925460,"user":{"displayName":"Nadir Ounaggou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14687011903990117142"},"user_tz":-60},"id":"egeCpaPTEPRA","outputId":"7ebd951b-d3bd-478b-980f-1ffba045d1f3"},"outputs":[{"name":"stdout","output_type":"stream","text":["GPU is available.\n"]}],"source":["if torch.cuda.is_available():\n","  print(\"GPU is available.\")\n","  device = torch.cuda.current_device()\n","else:\n","  print(\"Will work on CPU.\")"]},{"cell_type":"markdown","metadata":{"id":"GBr8HR8WizRt"},"source":["### À rendre\n","\n","Chaque exercice de ce TP demande une réponse sous forme textuelle ou sous forme de code. Toute réponse doit être écrite dans une ou plusieurs cellules après l’énoncé de chaque exercice.\n","\n","Vous rendrez un répertoire compressé `tp_bert_nom1_nom2.zip` avec le contenu du répertoire `tp_bert.zip` dont le fichier `tp_bert.ipynb` aura été mis à jour avec vos reponses."]},{"cell_type":"markdown","metadata":{"id":"3itFE_0tZIBv"},"source":["## Données"]},{"cell_type":"markdown","metadata":{"id":"sbHy5DlHllOf"},"source":["\n","\n","Nous allons entraîner notre modèle sur une tache de **classification en classes multiples**. Notamment, la tâche est celle de repartir des textes en trois catégories de sentiments:\n","\n","1. négatif\n","2. neutre\n","3. positif\n","\n","Ces donnés sont collectées dans le jeu de données [FinancialPhraseBank-v1.0\n","](https://www.researchgate.net/publication/251231364_FinancialPhraseBank-v10), que vous pouvez trouver dans le répertoire de ce TP.\n","\n","Voici les informations essentielles à la compréhension de la tâche, qui figurent dans le file README.txt :\n","\n","---\n","\n","<em>The key arguments for the low utilization of statistical techniques in financial sentiment analysis have been the difficulty of implementation for practical applications and the lack of high quality training data for building such models. Especially in the case of finance and economic texts, annotated collections are a scarce resource and many are reserved for proprietary use only. To resolve the missing training data problem, we present a collection of ∼ 5000 sentences to establish human-annotated standards for benchmarking alternative modeling techniques. \n","\n","<em>The objective of the phrase level annotation task was to classify each example sentence into a positive, negative or neutral category by considering only the information explicitly available in the given sentence. Since the study is focused only on financial and economic domains, the annotators were asked to consider the sentences from the view point of an investor only; i.e. whether the news may have positive, negative or neutral influence on the stock price. As a result, sentences which have a sentiment that is not relevant from an economic or financial perspective are considered neutral.\n","\n","<em>This release of the financial phrase bank covers a collection of 4840 sentences. The selected collection of phrases was annotated by 16 people with adequate background knowledge on financial markets. Three of the annotators were researchers and the remaining 13 annotators were master’s students at Aalto University School of Business with majors primarily in finance, accounting, and economics.\n","\n","<em>Given the large number of overlapping annotations (5 to 8 annotations per sentence), there are several ways to define a majority vote based gold standard. To provide an objective comparison, we have formed 4 alternative reference datasets based on the strength of majority agreement: \n","\n","1. sentences with 100% agreement [file=Sentences_AllAgree.txt]; \n","2. sentences with more than 75% agreement [file=Sentences_75Agree.txt]; \n","3. sentences with more than 66% agreement [file=Sentences_66Agree.txt]; and \n","4. sentences with more than 50% agreement [file=Sentences_50Agree.txt].\n","\n","<em>All reference datasets are included in the release. The files are in a machine-readable \"@\"-separated format:\n","\n","<em>**sentence@sentiment**\n","\n","<em>where sentiment is either \"positive, neutral or negative\".\n","\n","<em>E.g.,  The operating margin came down to 2.4 % from 5.7 % .@negative<em>\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"2-Xmt1rCMZTp"},"source":["#### Exercice 1\n","\n","Nous allons utiliser les phrases contenues dans _Sentences_75Agree.txt_ pour entraîner et tester notre modèle. Pour ce faire, téléchargez le fichier sur la machine Colab (utiliser l’interface à gauche) ou, si vous travaillez sur un _Jupyter Notebook_ en local, placez le fichier _Sentences_75Agree.txt_ dans le même répertoire du _Notebook_.\n","\n","Ensuite, écrivez la fonction `load_data()` qui lit les phrases contenues dans ce fichier et les sépare de leurs étiquettes. Le résultat de cette fonction, assigné à la variable `data`, doit être une liste de listes, où chaque sous-liste contient une phrase comme premier élément et son étiquette comme deuxième élément. I.e.:\n","\n","````\n","data[0][0] == 'A high court in Finland has fined seven local asphalt companies more than   lion ( $ 117 million ) for operating a cartel .'\n","data[0][1] == 'negative'\n","````\n","\n","> Note: l'encodage du fichier _Sentences_75Agree.txt_ est `iso-8859-1`."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":349,"status":"ok","timestamp":1647204931402,"user":{"displayName":"Nadir Ounaggou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14687011903990117142"},"user_tz":-60},"id":"XvX8OYKJhGhD","outputId":"fdc6450b-61c2-47a8-8e0c-202c1f435d82"},"outputs":[{"name":"stdout","output_type":"stream","text":["anscombe.json\t\t      mnist_test.csv\t     Sentences_75Agree.txt\n","california_housing_test.csv   mnist_train_small.csv\n","california_housing_train.csv  README.md\n"]},{"data":{"text/plain":[]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["%%shell\n","cd sample_data\n","ls"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_RUyKYiCPrUT"},"outputs":[],"source":["# WRITE FUNCTION load_data HERE\n","def load_data(fname):\n","  res = []\n","  f = open(fname, 'rt', encoding=\"ISO-8859-1\")\n","  for line in f:\n","    tmp = line.split('@')\n","    tmp[1] = tmp[1][:-1]\n","    res.append(tmp)\n","  return res\n","\n","filename = './sample_data/Sentences_75Agree.txt'\n","data = load_data(filename)"]},{"cell_type":"markdown","metadata":{"id":"Gdz1-MmsO72_"},"source":["Testez le résultat de votre fonction en faisant tourner la cellule suivante."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":347,"status":"ok","timestamp":1647204942027,"user":{"displayName":"Nadir Ounaggou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14687011903990117142"},"user_tz":-60},"id":"Ws2gU_wEOp8S","outputId":"493d2222-38f1-4dd8-acc6-f8f06519ddaf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Test passed!\n"]}],"source":["classes = ['negative', 'neutral', 'positive']\n","assert type(data[0][0]) == str, \"The first element of every sub-list should be a sentence.\"\n","assert data[0][1] in classes, \"The second element of each sub-list should belong to one of the three classes available.\"\n","assert len(data) == 3453, \"The size of data should be of 3453 sentences.\"\n","#test ajouté, pour s'assurer toutes les lignes ont bien été séparées.\n","for elem in data:\n","  assert len(elem) == 2\n","print(\"Test passed!\")"]},{"cell_type":"markdown","metadata":{"id":"jJQ_PsuiQpcp"},"source":["Maintenant, nous allons séparer nos données pour l’entraînement et pour le test.\n","\n","> NOTE: nous n'allons pas utiliser un ensemble de développement (validation) ici dans l'objective de simplifier ce TP, mais rappelé vous de l'importance du dev dans toute application réelle."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":362,"status":"ok","timestamp":1647204945851,"user":{"displayName":"Nadir Ounaggou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14687011903990117142"},"user_tz":-60},"id":"UI8nt4K09PBA","outputId":"2bf8a97a-7d80-4676-b410-959f517a30d5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train data size :  2935\n","Test data size :  518\n"]}],"source":["import random, math\n","from sklearn import preprocessing\n","\n","# randomly sample train and test set from data\n","random.shuffle(data)\n","split = 0.85\n","num_elem = math.floor(len(data)*split)\n","train = data[:num_elem]\n","test = data[num_elem:]\n","print(\"Train data size : \", len(train))\n","print(\"Test data size : \", len(test))\n","\n","# build input features and labels\n","x_train = [t[0] for t in train]\n","y_train = [t[1] for t in train]\n","x_test = [t[0] for t in test]\n","y_test = [t[1] for t in test]\n","\n","# convert labels into integers ['negative', 'neutral', 'positive'] -> [0, 1, 2]\n","le = preprocessing.LabelEncoder()\n","le.fit(y_train)\n","y_train = le.transform(y_train)\n","y_test = le.transform(y_test)"]},{"cell_type":"markdown","metadata":{"id":"RETCPekGaoKX"},"source":["### Baseline\n"]},{"cell_type":"markdown","metadata":{"id":"ypuFm78gllPM"},"source":["#### Exercice 2\n","\n","Préalablement à une tache de classification, c’est toujours une bonne idée de vérifier si les données de training et de test sont (plus ou moins) uniformément distribuées par rapport aux classes existantes.\n","\n","1. Pourquoi ?\n","\n","2. Quel est le nombre de données d'entraînement et de test correspondant à chaque classe ?\n","\n","3. Étant donnée la distribution des étiquettes dans le _testset_, quelles sont les attentes par rapport aux performances de notre modèle en terme de _accuracy_ ? En d'autres termes, quelle est l'_accuracy_ minimale à battre par n'importe quel système de classification ? "]},{"cell_type":"markdown","metadata":{"id":"rWNvXEJ_5C0k"},"source":["1) Parce que la réalité reflétée par les données d'apprentissages doit être la même que celle représentée par les données de test, sinon il y aura intoduction d'un biais ce qui ne sera pas optimale pour nos prédictions.\n","\n","2) Voir le résultat du code ci-dessous.\n","\n","3) Étant données les pourcentages, dans notre test-set, suivantes:\n","\n","{'Negative': 11.91%, 'Neutral': 61.52%, 'Positive': 27.73%}\n","\n","On considère un classifieur naïf qui ne prédit que la classe avec la plus grande chance d'occurence, à savoir ici Neutral, il aura une précision de 61,5%.\n","\n","Sachant maintenant que notre classifieur sera plus complexe, on exigera au minimum une précision de 61,5%.\n","\n","**Rmq:** On s'assure bien que la distribution des classes dans notre train-set est à peut prêt la même que celle dans notre test-set, pour être sur de ne pas biaiser notre apprentissage."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":405,"status":"ok","timestamp":1647204952496,"user":{"displayName":"Nadir Ounaggou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14687011903990117142"},"user_tz":-60},"id":"BqQUhkuyllPO","outputId":"edbae1a2-49f1-4ee2-c20c-782c293c27ff"},"outputs":[{"name":"stdout","output_type":"stream","text":["nombre de données par classe dans le train-set:  349 1827 759\n","pourcentages de données par classe dans le train-set:  11.890971039182283 62.24872231686541 25.860306643952303\n","nombre de données par classe dans le test-set:  71 319 128\n","pourcentages de données par classes dans le test-set:  13.8671875 62.3046875 25.0\n"]}],"source":["# WRITE CODE TO ANSWER THE QUESTIONS HERE,  PRINT ANSWERS OR WRITE THEM IN A TEXT CELL BELOW\n","classes = ['negative', 'neutral', 'positive']\n","tx_neu = 0\n","tx_n = 0\n","tx_p = 0\n","for elem in y_train:\n","  if elem == 0:\n","    tx_n+=1\n","  elif elem == 1:\n","    tx_neu+=1\n","  else:\n","    tx_p+=1\n","print('nombre de données par classe dans le train-set: ', tx_n, tx_neu, tx_p)\n","print('pourcentages de données par classe dans le train-set: ', tx_n/2935*100, tx_neu/2935*100, tx_p/2935*100)\n","tx_neu = 0\n","tx_n = 0\n","tx_p = 0\n","for elem in y_test:\n","  if elem == 0:\n","    tx_n+=1\n","  elif elem == 1:\n","    tx_neu+=1\n","  else:\n","    tx_p+=1\n","print('nombre de données par classe dans le test-set: ', tx_n, tx_neu, tx_p)\n","print('pourcentages de données par classes dans le test-set: ', tx_n/512*100, tx_neu/512*100, tx_p/512*100)"]},{"cell_type":"markdown","metadata":{"id":"0fknJN5vWqlO"},"source":["#### Exercice 3\n","\n","Dans la cellule ci-dessous, on entraîne un modèle de [classification naïve bayésienne\n"," en classes multiples](https://fr.wikipedia.org/wiki/Classification_na%C3%AFve_bay%C3%A9sienne), en sorte d’avoir une performance de référence. Ainsi, l’objectif dans la suite sera de faire mieux de ce naïf.\n","\n","1. Pourquoi est-qu’on s’attende qu’un modèle de classification type BERT est plus puissante du modèle naïf bayésien ?\n","2. Dans quelles conditions les modèles non-neuronaux peuvent être plus avantageux ?"]},{"cell_type":"markdown","metadata":{"id":"H2vpsPllMYtX"},"source":["1) Comme le modèle naïf bayésien se base sur l'hypothèse naïve de Bayes, qui considère que les probabilités d'occurence de chaque mot sachant la classe indépendamment des autres. Ce modèle néglige alors la dépendance entre les mots contigus et mène à des résultats généralement erronés, d'où la puissance du modèle BERT.\n","\n","2) Les modèles non-neuronaux peuvent être avantageux dans le cas où on souhaite avoir un modèle rapide à entrainer même si on ne possède pas une grande puissance de calcul ou pour déterminer une référence d'une façon légère. \n","<span style=\"color:red\">Also: since neural models require more data than simpler ML algorithms to learn anything useful, if we don't have a lot of data a non-neural approach might achieve better performance. </span>"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":256,"status":"ok","timestamp":1647014156652,"user":{"displayName":"Nadir Ounaggou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14687011903990117142"},"user_tz":-60},"id":"1326MzvnWtPU","outputId":"f6988189-93e8-45e4-c52b-fdb1e223d5d4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy of a simple multinomial Naive-Bayes approach : 0.7104247104247104\n"]}],"source":["from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.feature_extraction.text import TfidfTransformer\n","from sklearn.naive_bayes import MultinomialNB\n","\n","# transform sentences in bag of words\n","count_vect = CountVectorizer()\n","x_train_counts = count_vect.fit_transform(x_train)\n","x_test_counts = count_vect.transform(x_test)\n","# transform bag of words in tfidf vectors\n","tfidf_transformer = TfidfTransformer()\n","x_train_tfidf = tfidf_transformer.fit_transform(x_train_counts)\n","x_test_tfidf = tfidf_transformer.fit_transform(x_test_counts)\n","# train a multinomial Naive-Bayes classifier on the tfidf vectors\n","classifier = MultinomialNB().fit(x_train_tfidf, y_train)\n","# use classifier to predict the labels of the test set\n","predicted = classifier.predict(x_test_tfidf)\n","# calculate accuracy\n","print(\"Accuracy of a simple multinomial Naive-Bayes approach :\", sum(predicted == y_test)/len(predicted))"]},{"cell_type":"markdown","metadata":{"id":"uhPQ-kYZN0Ev"},"source":["## Tokenisation"]},{"cell_type":"markdown","metadata":{"id":"-vf3eq1vllQK"},"source":["La bibliothèque HuggingFace offre des outils pour faire la tokenisation des données textuelles selon les modéles que nous allons utiliser: [see the docs](https://huggingface.co/transformers/tokenizer_summary.html).\n","\n","Dans ce TP, nous allons utiliser un modèles pré-entraîné qui s’appelle [DistilBERT](https://arxiv.org/pdf/1910.01108.pdf): un encodeur avec une architecture [Transformer](https://arxiv.org/abs/1706.03762) une version distillée de BERT et qui ainsi plus léger en terme de mémoire et plus rapide. Les auteurs le présentent dans leur papier de la manière suivante :\n","\n","<em>As Transfer Learning from large-scale pre-trained models becomes more prevalent in Natural Language Processing (NLP), operating these large models in on-the-edge and/or under constrained computational training or inference budgets remains challenging. In this work, we propose a method to pre-train a smaller general-purpose language representation model, called DistilBERT, which can then be fine-tuned with good performances on a wide range of tasks like its larger counterparts. While most prior work investigated the use of distillation for building task-specific models, we leverage knowledge distillation during the pre-training phase and show that it is possible to reduce the size of a BERT model by 40%, while retaining 97% of its language understanding capabilities and being 60% faster. To leverage the inductive biases learned by larger models during pre-training, we introduce a triple loss combining language modeling, distillation and cosine-distance losses. Our smaller, faster and lighter model is cheaper to pre-train and we demonstrate its capabilities for on-device computations in a proof-of-concept experiment and a comparative on-device study."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":706,"referenced_widgets":["9761b5f844564a11a172fb907e6f1816","ec5aaa623eb64cd2b54b3d55362ead62","c501abc913644f8dafb50924d1d21a1c","66498e36d12e4015875f3b4e3ba62b4f","dd9084ee925a46858d04fae94bbbb771","d8e48f84f4fa49eda51cbe952af7f602","ec7da52a0efa49ff815df2d81258521a","2e8b9c999a1b4f578ea5f7d8d5f3f734","e715bf5a48274ab1a83489699ba60895","fc2bd89e08bc4feda021b7e5367ff70d","b45ebf680d064a329fa11e47c0cf58f2","8ec4ced9e14a48dba408b7a116273db9","909ad98446d6478ea5b7401e567a67ec","7d40660b78eb48e197e2d0c2e89fb328","77563b78dcf946029dbf4e1f2509d492","8731f2a8ea7640718256b08648ce190c","81b44569749c4ea58fd5810185be0a5f","9e0de133f36e456082024437fe18c132","0ba0f0b02150463484ab170ceeb184a1","1bce05b7f5c843308990272ba5e3bbca","4301c17ff2c14b5c95380dc5992e939a","0502c98d69334b07939ae1806d05132e","094f3b8718784c189575f06eb80e50fe","05f9832f7a6c4f09b4909da706e9d161","b99c09df64634b51a1a7da3f9ef977b9","11defae41da84536bf8bd74abfe9f2ce","0f525a931b71457b8c3b9930edc0d0f8","45169928f9af49c5b2aead70e6d637c6","cdcd18b50a054c4a809f8b2b36629205","02045a312c3c46b288e7c0ccf99954df","971c8753cd1246dcba1933cd301bf725","646cee81cd1b4caaa46211ed73c84d6f","3b0a6096798845de8dde3420f4569642"]},"executionInfo":{"elapsed":9914,"status":"ok","timestamp":1647204985941,"user":{"displayName":"Nadir Ounaggou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14687011903990117142"},"user_tz":-60},"id":"QQlbOyzHllQN","outputId":"e6c2a6cb-39a0-4791-d46c-a4117cf8ea5a"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9761b5f844564a11a172fb907e6f1816","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8ec4ced9e14a48dba408b7a116273db9","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"094f3b8718784c189575f06eb80e50fe","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'input_ids': [101, 1996, 2194, 2003, 2036, 6224, 12020, 2000, 20102, 1996, 11320, 12248, 3211, 5073, 1010, 2070, 2753, 2111, 1010, 2000, 2060, 2039, 2213, 6341, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n","**********************\n","\n","['[CLS]', 'the', 'company', 'is', 'also', 'seeking', 'possibilities', 'to', 'relocate', 'the', 'lu', '##uma', '##ki', 'personnel', ',', 'some', '50', 'people', ',', 'to', 'other', 'up', '##m', 'mills', '.', '[SEP]'] \n","\n","**********************\n","\n","[CLS] the company is also seeking possibilities to relocate the luumaki personnel, some 50 people, to other upm mills. [SEP] \n","\n","---------------------- \n","\n","{'input_ids': [101, 2014, 2556, 2597, 2003, 1996, 2472, 1997, 4518, 5804, 1005, 1055, 2248, 2533, 5324, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n","**********************\n","\n","['[CLS]', 'her', 'present', 'position', 'is', 'the', 'director', 'of', 'stock', '##mann', \"'\", 's', 'international', 'department', 'stores', '.', '[SEP]'] \n","\n","**********************\n","\n","[CLS] her present position is the director of stockmann's international department stores. [SEP] \n","\n","---------------------- \n","\n","{'input_ids': [101, 16012, 16584, 1051, 2100, 3501, 11791, 1010, 22027, 1998, 6089, 6381, 8304, 3688, 1998, 16474, 3231, 3001, 2005, 2224, 1999, 2470, 1010, 9871, 1998, 3919, 12030, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n","**********************\n","\n","['[CLS]', 'bio', '##hit', 'o', '##y', '##j', 'develops', ',', 'manufactures', 'and', 'markets', 'liquid', 'handling', 'products', 'and', 'diagnostic', 'test', 'systems', 'for', 'use', 'in', 'research', ',', 'healthcare', 'and', 'industrial', 'laboratories', '.', '[SEP]'] \n","\n","**********************\n","\n","[CLS] biohit oyj develops, manufactures and markets liquid handling products and diagnostic test systems for use in research, healthcare and industrial laboratories. [SEP] \n","\n","---------------------- \n","\n"]}],"source":["from transformers import DistilBertTokenizer\n","\n","MAX_LEN = 512\n","\n","tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased', padding=True, truncation=True)\n","\n","# let's check out how the tokenizer works\n","for n in range(3):\n","    # tokenize sentences\n","    tokenizer_out = tokenizer(x_train[n])\n","    # convert numerical tokens to alphabetical tokens\n","    encoded_tok = tokenizer.convert_ids_to_tokens(tokenizer_out.input_ids)\n","    # decode tokens back to string\n","    decoded = tokenizer.decode(tokenizer_out.input_ids)\n","    print(tokenizer_out)\n","    print('**********************\\n')\n","    print(encoded_tok, '\\n')\n","    print('**********************\\n')\n","    print(decoded, '\\n')\n","    print('---------------------- \\n')\n"]},{"cell_type":"markdown","metadata":{"id":"mT5wpgrUllQZ"},"source":["#### Exercice 4\n","\n","1. Qu’est-ce que la sortie du tokeniseur (`tokeniser_out`) représente ? \n","2. Quels sont les tokens spéciaux introduits par le tokeniseur? Quel est leur fonction?\n","3. Pourquoi certains tokens commencent par ## (par exemple, ##r ##oxide) ? AIDE: cherche sur Google \"Byte pair encoding\"\n","4. Notez que le tokeniseur que l'on utilise à été pré-entraîné. Pourquoi un tokeniseur comme celui-ci nécessite d’un entraînement préalable à son application ?"]},{"cell_type":"markdown","metadata":{"id":"QVxPsNLtgnRN"},"source":["1) tokeniser_out donne à deux élément:\n","\n","* 'input_ids': qui expose un encodage numérique de tous les éléments de notre entrée sous forme d'une liste.\n","* 'attention_mask': une liste de 0s et de 1s; Soit idx un indice, attention_mask[idx] doit être égale à 1 si input_ids[idx] doit être considéré/traité par la suite, et 0 sinon.\n","\n","2) On remarque que le tokeniseur a ajouté un élément [CLS] au début de chaque phrase, et [SEP] à la fin.\n","\n","* [CLS] (abréviation de \"classification\"): Utiliser pour préciser à BERT le commencement de la première phrase dans la tâche \"Next sentence prediction\".\n","* [SEP] (abréviation de \"séparateur\"): Utiliser pour séparer entre les deux phrases d'une tâche de \"Next sentence prediction\".\n","\n","3) On usera d'un exemple pour répondre à cette question:\n","\n","Prenons le mot \"eur\" qui n'est pas reconnu par BERT il va le diviser en sous-mots plus fréquents à savoir \"eu\" et \"r\" puis pour préciser que les deux sous-mots font partie d'une même entité il va ajouter ## dans le deuxième élément ce qui va donner au final \"eu\" et \"##r\". Ce processus rentre dans un cadre de compression de la données -BPE-.\n","\n","4) Le tokeniseur a besoin d'un pré-entrainement pour qu'il puisse se constituer une base de mots qu'il reconnait, et qu'il pourra élargir en l'entrainant. En particulier cette étape d'entrainement est primordiale pour opérer le processus BPE."]},{"cell_type":"markdown","metadata":{"id":"_42B63m-llQp"},"source":["#### Exercise 5\n","\n","BERT (et DistilBERT) gère des séquences de longueur maximale égale à 512 (`MAX_LEN=512`). Vérifier si cette longueur est optimale pour notre tâche. En d'autre termes, vérifiez quelle est la distribution des longueurs des textes que nous devons classifier et s’il serait avantageux de réduire MAX_LEN de façon à réduire le temps de traitement des séquences. \n","\n","<span style=\"color:red\">MAX_LEN refers to maximum number of tokens, not characters ! Below, you are plotting the distribution of sentence length in terms of characters instead of tokens </span>"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":282},"executionInfo":{"elapsed":296,"status":"ok","timestamp":1647014196004,"user":{"displayName":"Nadir Ounaggou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14687011903990117142"},"user_tz":-60},"id":"abnwQh5KllQs","outputId":"d7137cea-7668-4f98-fbf9-e071b3123ffb"},"outputs":[{"data":{"text/plain":["[<matplotlib.lines.Line2D at 0x7fcbef503910>]"]},"execution_count":14,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["# WRITE CODE TO ANSWER THE QUESTION HERE.  PRINT THE ANSWER OR WRITE IT IN A TEXT CELL BELOW\n","distrib = [0 for i in range(316)]\n","for elem in data:\n","  idx = len(elem[0])\n","  distrib[idx - 1] += 1\n","plt.plot(distrib)"]},{"cell_type":"markdown","metadata":{"id":"9Zpe2gwqiN0P"},"source":["Maintenant que nous avons compris comment le tokeniseur fonctionne, nous pouvons désormais écrire une classe Dataset qui nous servira pour l'entraînement et le test. En effet, le classes Python qui s’occupent de la création de _batches_ et du training nécessitent en entrée une classe de type Dataset, comme la suivante.\n","\n","**Note** changez MAX_LEN si vous avez trouvé dans l'exercice précédent quelle valeur serait plus avantageuse."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HFI7JYSbllSk"},"outputs":[],"source":["from torch.utils.data import Dataset, DataLoader\n","\n","MAX_LEN = 316\n","\n","class MyDataset(Dataset):\n","    def __init__(self, sentences, labels, tokenizer, max_len):\n","        # variables that are set when the class is instantiated\n","        self.sentences = sentences\n","        self.labels = labels\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.sentences)\n","  \n","    def __getitem__(self, item):\n","        # select the sentence and its class\n","        sentence = str(self.sentences[item])\n","        label = self.labels[item]\n","        # tokenize the sencence\n","        tokenizer_out = self.tokenizer(\n","            sentence,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            return_token_type_ids=False,\n","            pad_to_max_length=True,\n","            return_attention_mask=True,\n","            return_tensors='pt',\n","            truncation=True\n","            )\n","        # return a dictionary with the output of the tokenizer and the label\n","        return  {\n","            'input_ids': tokenizer_out['input_ids'].flatten(),\n","            'attention_mask': tokenizer_out['attention_mask'].flatten(),\n","            'label': torch.tensor(label, dtype=torch.long)\n","        }\n","\n","\n","# instantiate two MyDataset objects\n","train_dataset = MyDataset(x_train, y_train, tokenizer, MAX_LEN)\n","test_dataset = MyDataset(x_test, y_test, tokenizer, MAX_LEN)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":372,"status":"ok","timestamp":1647205344746,"user":{"displayName":"Nadir Ounaggou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14687011903990117142"},"user_tz":-60},"id":"1JcS8nAnx2FX","outputId":"d0228108-a754-4dc9-8ed3-235951275729"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"data":{"text/plain":["{'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0]),\n"," 'input_ids': tensor([  101,  1996,  2194,  2003,  2036,  6224, 12020,  2000, 20102,  1996,\n","         11320, 12248,  3211,  5073,  1010,  2070,  2753,  2111,  1010,  2000,\n","          2060,  2039,  2213,  6341,  1012,   102,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0]),\n"," 'label': tensor(1)}"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["train_dataset[0]"]},{"cell_type":"markdown","metadata":{"id":"x8Eyuxv5KKlh"},"source":["## Modèle"]},{"cell_type":"markdown","metadata":{"id":"f-0mxvMC00YP"},"source":["C’est le moment de comprendre comment DistilBERT. Hugginface nous offre plusieurs modèles pré-entraînes de type DistilBERT, nous allons utiliser [distilbert-base-uncased](https://huggingface.co/distilbert-base-uncased), qui a une architecture profonde de 66’362’880 paramétres et qui a été pré-entraîné sur le jeu de données BookCorpus pour 90 heures avec huit GPUs de 16 GB de mémoire. Cela nous permettra d’obtenir de très bons résultat en attachant un classificateur très léger (un seul layer) au top de DistilBERT, qui fera le plus gros du travail, c’est-à-dire l’encodage de nos textes. Notre classificateur nécessitera d’être entraîné pendant quelques minutes seulement. \n","\n","On peut trouver les noms de tous les autres modèles pré-entraînés offerts par HuggingFace [à cette addresse](https://huggingface.co/models). \n","\n","Pour télécharger un modèle pré-entraîné on utilise l'option `.from_pretrained`:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":121,"referenced_widgets":["a327d5c4a7874359a17567da51ba804c","05da1b6252c14964a3048bd7804bb349","dfade37f6ec54c019ed3d9348c8df091","e1f97ed3fa5f4a63be42e04902639aa5","691778e421a4490f9f17be0171f6f46a","b59a53cb69c64337a701cbebae257694","b647080d3baf47298e2466621b85ecf2","ad06a3db8c2449c0a7a81bfa07b3b514","cd67999091a54016a8c8b119f8547710","577d0983b6414315a3898ff854a12350","4287ec9b21bc4ab5959e22d20e2d57c9"]},"executionInfo":{"elapsed":10486,"status":"ok","timestamp":1647205365011,"user":{"displayName":"Nadir Ounaggou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14687011903990117142"},"user_tz":-60},"id":"gKUjMtVrDx2D","outputId":"e5df7c30-3416-4eea-eb6a-2137f69cf449"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a327d5c4a7874359a17567da51ba804c","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/256M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.weight']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["from transformers import DistilBertModel\n","\n","PRE_TRAINED_MODEL_NAME = 'distilbert-base-uncased'\n","\n","distilbert = DistilBertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n"]},{"cell_type":"markdown","metadata":{"id":"PS5JItniHzP0"},"source":["Nous pouvons encoder les séquences de textes avec une passe en avant de distilBERT, qui nous renvoie les représentations cachés de la dernière couche.\n","\n","**Note** : la dimension des couches de `distilbert-base-uncased` est de 768 neurones \n","\n","**Note2** : nous utilisons la fonction `.unsqueeze(0)` parce que normalement on passe des batches au modèle, alors que cette fois ci ce n’est que un seul élement de la classe *MyDataset*. Avec `.unsqueeze(0)`, nous le traitons comme un batch de taille 1."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":840,"status":"ok","timestamp":1647205402208,"user":{"displayName":"Nadir Ounaggou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14687011903990117142"},"user_tz":-60},"id":"A_aq1_vqE3kK","outputId":"98bca0fe-9e2d-4014-bb94-73bb223b628e"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"data":{"text/plain":["torch.Size([1, 316, 768])"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["first_sent = train_dataset[0]\n","\n","hidden_state = distilbert(\n","    input_ids=first_sent['input_ids'].unsqueeze(0), attention_mask=first_sent['attention_mask'].unsqueeze(0)\n","    )\n","\n","hidden_state[0].shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":338,"status":"ok","timestamp":1647205412967,"user":{"displayName":"Nadir Ounaggou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14687011903990117142"},"user_tz":-60},"id":"gxZwaorkI11b","outputId":"e9e2ba56-96c4-4f5d-f10a-ea9d27824112"},"outputs":[{"data":{"text/plain":["DistilBertConfig {\n","  \"_name_or_path\": \"distilbert-base-uncased\",\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.17.0\",\n","  \"vocab_size\": 30522\n","}"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["distilbert.config"]},{"cell_type":"markdown","metadata":{"id":"SpNwIOQUKdHj"},"source":["#### Exercice 6\n","\n","Nous avons maintenant les éléments nécessaires à la construction d'un modèle de classification en classes multiples basé sur DistilBERT.\n","\n","Concernant le code ci-dessous :\n","\n","1. Quelle est la fonction de cet extrait de code ?\n","\t```Python\n","\tif freeze_encoder:\n","\t\tfor param in self.encoder.parameters():\n","\t\t\tparam.requires_grad = False\n","\t```\n","\n","2. Pourquoi on ne garde que la représentation caché du premier token de chaque séquence avec la commande `pooled_output = hidden_state[:, 0]` ?\n","\n","3. Compléter l’extrait de code sous-jacente à `if labels is not None:` de façon à calculer la fonction de perte (*loss  function*) du modèle lorsque les cibles sont passées à la fonction `forward`\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Jv-NkNnDf_rL"},"source":["1) Comme on travaille avec un model pré-entrainé, la fonction donnée s'occupe de faire stagner les nœuds dont les paramètres ont déjà été calibrés dans l'entrainement de BERT.\n","\n","2) le token [CLS] est unique pour chaque entrée, et est généré de telle façon à ce qu'il soit représentatif de l'entrée en question. D'où [CLS] est suffisant pour retenir toute l'information.\n","\n","3) Voir code ci-dessous."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2723,"status":"ok","timestamp":1647205879664,"user":{"displayName":"Nadir Ounaggou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14687011903990117142"},"user_tz":-60},"id":"IPqk1pk6llTM","outputId":"fcc4c22b-3acd-4e25-9de0-a2b53aff4ea2"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.weight']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["model total params:  66365187\n","model trainable params:  2307\n","\n"," DistilBertForSentimentClassification(\n","  (encoder): DistilBertModel(\n","    (embeddings): Embeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (transformer): Transformer(\n","      (layer): ModuleList(\n","        (0): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","            (activation): GELUActivation()\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (1): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","            (activation): GELUActivation()\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (2): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","            (activation): GELUActivation()\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (3): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","            (activation): GELUActivation()\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (4): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","            (activation): GELUActivation()\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (5): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","            (activation): GELUActivation()\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","      )\n","    )\n","  )\n","  (classifier): Linear(in_features=768, out_features=3, bias=True)\n","  (dropout): Dropout(p=0.1, inplace=False)\n",")\n"]}],"source":["from transformers import DistilBertPreTrainedModel, DistilBertConfig\n","\n","\n","PRE_TRAINED_MODEL_NAME = 'distilbert-base-uncased'\n","FREEZE_PRETRAINED_MODEL = True\n","\n","class DistilBertForSentimentClassification(DistilBertPreTrainedModel):\n","    def __init__(self, config, num_labels, freeze_encoder=False):\n","        # instantiate the parent class DistilBertPreTrainedModel\n","        super().__init__(config)\n","        # instantiate num. of classes\n","        self.num_labels = num_labels\n","        # instantiate and load a pretrained DistilBERT model as encoder\n","        self.encoder = DistilBertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n","        # [Q1] freeze the encoder parameters if required \n","        if freeze_encoder:\n","          for param in self.encoder.parameters():\n","              param.requires_grad = False\n","        # the classifier: a feed-forward layer attached to the encoder's head\n","        self.classifier = torch.nn.Linear(\n","            in_features=config.dim, out_features=self.num_labels, bias=True)\n","        # instantiate a dropout function for the classifier's input\n","        self.dropout = torch.nn.Dropout(p=0.1)\n","\n","\n","    def forward(\n","        self,\n","        input_ids=None,\n","        attention_mask=None,\n","        head_mask=None,\n","        inputs_embeds=None,\n","        labels=None,\n","        output_attentions=None,\n","        output_hidden_states=None,\n","    ):\n","        # encode a batch of sequences with DistilBERT\n","        encoder_output = self.encoder(\n","            input_ids=input_ids,\n","            attention_mask=attention_mask,\n","            head_mask=head_mask,\n","            inputs_embeds=inputs_embeds,\n","            output_attentions=output_attentions,\n","            output_hidden_states=output_hidden_states,\n","        )\n","        # extract the hidden representations from the encoder output\n","        hidden_state = encoder_output[0]  # (bs, seq_len, dim)\n","        # only select the encoding corresponding to the first token\n","        # [Q2] of each sequence in the batch \n","        pooled_output = hidden_state[:, 0]  # (bs, dim)\n","        # apply dropout\n","        pooled_output = self.dropout(pooled_output)  # (bs, dim)\n","        # feed into the classifier\n","        logits = self.classifier(pooled_output)  # (bs, dim)\n","\n","        outputs = (logits,) + encoder_output[1:]\n","        \n","        if labels is not None:\n","          loss_fct = torch.nn.CrossEntropyLoss()\n","          if attention_mask is not None:\n","            active_loss = attention_mask.view(-1) == 1\n","            active_logits = self.classifier(hidden_state).view(-1, self.num_labels)\n","            active_labels = torch.where(active_loss, labels.view(-1)[0], torch.tensor(loss_fct.ignore_index).type_as(labels))\n","            loss = loss_fct(active_logits, active_labels)\n","          else:\n","            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n","          outputs = (loss,) + outputs\n","\n","        return outputs  # (loss), logits, (hidden_states), (attentions)\n","\n","\n","# instantiate model\n","model = DistilBertForSentimentClassification(\n","    config=distilbert.config, num_labels=len(classes),\n","    freeze_encoder = FREEZE_PRETRAINED_MODEL\n","    )\n","\n","# print info about model's parameters\n","total_params = sum(p.numel() for p in model.parameters())\n","model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n","trainable_params = sum([np.prod(p.size()) for p in model_parameters])\n","print('model total params: ', total_params)\n","print('model trainable params: ', trainable_params)\n","print('\\n', model)\n"]},{"cell_type":"markdown","metadata":{"id":"I1bjajujllTv"},"source":["## Entraînement"]},{"cell_type":"markdown","metadata":{"id":"kfrOtIN4NSaK"},"source":["*Let's train our classifier!*\n","\n","Le moment est arrivé. Heureusement *HuggingFace* nous fournit la classe Python nécessaire à gérer le training : `Trainer`. Nous lui passons les hyper-paramètres avec la classe `TrainingArgument`. Nous allons aussi lui passer les métrique que nous désirons pour l’évaluation du modèle en phase de test :\n","\n","1. justesse (accuracy)\n","2. précision (precision)\n","3. rappel (recall)\n","4. f1\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0W8S-cFL_rsU"},"outputs":[],"source":["# clean logs and results directory from old files\n","# this could be useful if we were running the cells below multiple times\n","!rm -r ./logs ./results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oIsuEFzillTx"},"outputs":[],"source":["from transformers import Trainer, TrainingArguments\n","from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n","\n","def compute_metrics(pred):\n","    labels = pred.label_ids\n","    preds = pred.predictions.argmax(-1)\n","    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds)\n","    acc = accuracy_score(labels, preds)\n","    return {\n","        'accuracy': acc,\n","        'f1': f1,\n","        'precision': precision,\n","        'recall': recall\n","    }\n","\n","training_args = TrainingArguments(\n","    output_dir='./results',          \n","    logging_dir='./logs',\n","    logging_first_step=True,\n","    logging_steps=50,\n","    num_train_epochs=16,              \n","    per_device_train_batch_size=8,  \n","    learning_rate=5e-5,\n","    weight_decay=0.01        \n",")\n","\n","trainer = Trainer(\n","    model=model,                         \n","    args=training_args,                  \n","    train_dataset=train_dataset,         \n","    compute_metrics=compute_metrics\n",")"]},{"cell_type":"markdown","metadata":{"id":"O_HknicPPbhA"},"source":["Pour visualiser l’évolution de la *loss* tout au long de l'entraînement, nous pouvons utiliser *TensorBoard *:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1BZrFuTg81Sh"},"outputs":[],"source":["%tensorboard --logdir logs"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":1123206,"status":"ok","timestamp":1647207073757,"user":{"displayName":"Nadir Ounaggou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14687011903990117142"},"user_tz":-60},"id":"V4NW8wLAllT7","outputId":"b9a40ee6-e26f-4052-a287-5d0fbb6416ab"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 2935\n","  Num Epochs = 16\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 5872\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='5872' max='5872' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [5872/5872 18:42, Epoch 16/16]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.157500</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>1.093500</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>1.039500</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.936300</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.968300</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.999000</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.962400</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>1.092800</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>1.041300</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.993900</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>1.071100</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.864600</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>1.019200</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>1.040600</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>1.215700</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>1.236000</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>1.185100</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.771600</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>1.091500</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>1.121400</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>1.354400</td>\n","    </tr>\n","    <tr>\n","      <td>1050</td>\n","      <td>1.204000</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>1.255200</td>\n","    </tr>\n","    <tr>\n","      <td>1150</td>\n","      <td>1.216200</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>1.360300</td>\n","    </tr>\n","    <tr>\n","      <td>1250</td>\n","      <td>1.407300</td>\n","    </tr>\n","    <tr>\n","      <td>1300</td>\n","      <td>1.122900</td>\n","    </tr>\n","    <tr>\n","      <td>1350</td>\n","      <td>1.212700</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>1.166700</td>\n","    </tr>\n","    <tr>\n","      <td>1450</td>\n","      <td>1.179400</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>1.109200</td>\n","    </tr>\n","    <tr>\n","      <td>1550</td>\n","      <td>1.239200</td>\n","    </tr>\n","    <tr>\n","      <td>1600</td>\n","      <td>1.291700</td>\n","    </tr>\n","    <tr>\n","      <td>1650</td>\n","      <td>1.505100</td>\n","    </tr>\n","    <tr>\n","      <td>1700</td>\n","      <td>1.421700</td>\n","    </tr>\n","    <tr>\n","      <td>1750</td>\n","      <td>1.602600</td>\n","    </tr>\n","    <tr>\n","      <td>1800</td>\n","      <td>1.321000</td>\n","    </tr>\n","    <tr>\n","      <td>1850</td>\n","      <td>1.487600</td>\n","    </tr>\n","    <tr>\n","      <td>1900</td>\n","      <td>1.289900</td>\n","    </tr>\n","    <tr>\n","      <td>1950</td>\n","      <td>1.219500</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>1.520700</td>\n","    </tr>\n","    <tr>\n","      <td>2050</td>\n","      <td>1.232600</td>\n","    </tr>\n","    <tr>\n","      <td>2100</td>\n","      <td>1.192300</td>\n","    </tr>\n","    <tr>\n","      <td>2150</td>\n","      <td>1.334500</td>\n","    </tr>\n","    <tr>\n","      <td>2200</td>\n","      <td>1.394800</td>\n","    </tr>\n","    <tr>\n","      <td>2250</td>\n","      <td>1.420000</td>\n","    </tr>\n","    <tr>\n","      <td>2300</td>\n","      <td>1.419800</td>\n","    </tr>\n","    <tr>\n","      <td>2350</td>\n","      <td>1.628700</td>\n","    </tr>\n","    <tr>\n","      <td>2400</td>\n","      <td>1.294000</td>\n","    </tr>\n","    <tr>\n","      <td>2450</td>\n","      <td>1.128200</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>1.434200</td>\n","    </tr>\n","    <tr>\n","      <td>2550</td>\n","      <td>1.384900</td>\n","    </tr>\n","    <tr>\n","      <td>2600</td>\n","      <td>1.595000</td>\n","    </tr>\n","    <tr>\n","      <td>2650</td>\n","      <td>1.294100</td>\n","    </tr>\n","    <tr>\n","      <td>2700</td>\n","      <td>1.516200</td>\n","    </tr>\n","    <tr>\n","      <td>2750</td>\n","      <td>1.462600</td>\n","    </tr>\n","    <tr>\n","      <td>2800</td>\n","      <td>1.484400</td>\n","    </tr>\n","    <tr>\n","      <td>2850</td>\n","      <td>1.499000</td>\n","    </tr>\n","    <tr>\n","      <td>2900</td>\n","      <td>1.307000</td>\n","    </tr>\n","    <tr>\n","      <td>2950</td>\n","      <td>0.915000</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>1.698500</td>\n","    </tr>\n","    <tr>\n","      <td>3050</td>\n","      <td>1.358100</td>\n","    </tr>\n","    <tr>\n","      <td>3100</td>\n","      <td>1.144300</td>\n","    </tr>\n","    <tr>\n","      <td>3150</td>\n","      <td>1.651900</td>\n","    </tr>\n","    <tr>\n","      <td>3200</td>\n","      <td>1.157600</td>\n","    </tr>\n","    <tr>\n","      <td>3250</td>\n","      <td>1.670900</td>\n","    </tr>\n","    <tr>\n","      <td>3300</td>\n","      <td>1.599000</td>\n","    </tr>\n","    <tr>\n","      <td>3350</td>\n","      <td>1.103100</td>\n","    </tr>\n","    <tr>\n","      <td>3400</td>\n","      <td>1.149700</td>\n","    </tr>\n","    <tr>\n","      <td>3450</td>\n","      <td>1.710400</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>1.360600</td>\n","    </tr>\n","    <tr>\n","      <td>3550</td>\n","      <td>1.485800</td>\n","    </tr>\n","    <tr>\n","      <td>3600</td>\n","      <td>1.290100</td>\n","    </tr>\n","    <tr>\n","      <td>3650</td>\n","      <td>1.326800</td>\n","    </tr>\n","    <tr>\n","      <td>3700</td>\n","      <td>0.914100</td>\n","    </tr>\n","    <tr>\n","      <td>3750</td>\n","      <td>1.325500</td>\n","    </tr>\n","    <tr>\n","      <td>3800</td>\n","      <td>1.285500</td>\n","    </tr>\n","    <tr>\n","      <td>3850</td>\n","      <td>1.089600</td>\n","    </tr>\n","    <tr>\n","      <td>3900</td>\n","      <td>1.531600</td>\n","    </tr>\n","    <tr>\n","      <td>3950</td>\n","      <td>1.180500</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>1.429000</td>\n","    </tr>\n","    <tr>\n","      <td>4050</td>\n","      <td>1.340600</td>\n","    </tr>\n","    <tr>\n","      <td>4100</td>\n","      <td>1.282000</td>\n","    </tr>\n","    <tr>\n","      <td>4150</td>\n","      <td>1.180200</td>\n","    </tr>\n","    <tr>\n","      <td>4200</td>\n","      <td>1.334600</td>\n","    </tr>\n","    <tr>\n","      <td>4250</td>\n","      <td>1.227500</td>\n","    </tr>\n","    <tr>\n","      <td>4300</td>\n","      <td>1.129800</td>\n","    </tr>\n","    <tr>\n","      <td>4350</td>\n","      <td>1.745900</td>\n","    </tr>\n","    <tr>\n","      <td>4400</td>\n","      <td>1.379400</td>\n","    </tr>\n","    <tr>\n","      <td>4450</td>\n","      <td>1.231700</td>\n","    </tr>\n","    <tr>\n","      <td>4500</td>\n","      <td>1.384100</td>\n","    </tr>\n","    <tr>\n","      <td>4550</td>\n","      <td>1.663300</td>\n","    </tr>\n","    <tr>\n","      <td>4600</td>\n","      <td>1.507900</td>\n","    </tr>\n","    <tr>\n","      <td>4650</td>\n","      <td>1.223200</td>\n","    </tr>\n","    <tr>\n","      <td>4700</td>\n","      <td>1.245100</td>\n","    </tr>\n","    <tr>\n","      <td>4750</td>\n","      <td>1.180500</td>\n","    </tr>\n","    <tr>\n","      <td>4800</td>\n","      <td>1.083400</td>\n","    </tr>\n","    <tr>\n","      <td>4850</td>\n","      <td>0.867800</td>\n","    </tr>\n","    <tr>\n","      <td>4900</td>\n","      <td>1.325100</td>\n","    </tr>\n","    <tr>\n","      <td>4950</td>\n","      <td>1.333100</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>0.986400</td>\n","    </tr>\n","    <tr>\n","      <td>5050</td>\n","      <td>1.198200</td>\n","    </tr>\n","    <tr>\n","      <td>5100</td>\n","      <td>1.600400</td>\n","    </tr>\n","    <tr>\n","      <td>5150</td>\n","      <td>1.359600</td>\n","    </tr>\n","    <tr>\n","      <td>5200</td>\n","      <td>1.619000</td>\n","    </tr>\n","    <tr>\n","      <td>5250</td>\n","      <td>1.333000</td>\n","    </tr>\n","    <tr>\n","      <td>5300</td>\n","      <td>1.241600</td>\n","    </tr>\n","    <tr>\n","      <td>5350</td>\n","      <td>1.513600</td>\n","    </tr>\n","    <tr>\n","      <td>5400</td>\n","      <td>1.869000</td>\n","    </tr>\n","    <tr>\n","      <td>5450</td>\n","      <td>0.904300</td>\n","    </tr>\n","    <tr>\n","      <td>5500</td>\n","      <td>1.278400</td>\n","    </tr>\n","    <tr>\n","      <td>5550</td>\n","      <td>0.954200</td>\n","    </tr>\n","    <tr>\n","      <td>5600</td>\n","      <td>1.120300</td>\n","    </tr>\n","    <tr>\n","      <td>5650</td>\n","      <td>1.549500</td>\n","    </tr>\n","    <tr>\n","      <td>5700</td>\n","      <td>1.432200</td>\n","    </tr>\n","    <tr>\n","      <td>5750</td>\n","      <td>1.390600</td>\n","    </tr>\n","    <tr>\n","      <td>5800</td>\n","      <td>0.998400</td>\n","    </tr>\n","    <tr>\n","      <td>5850</td>\n","      <td>1.427000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./results/checkpoint-500\n","Configuration saved in ./results/checkpoint-500/config.json\n","Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","Saving model checkpoint to ./results/checkpoint-1000\n","Configuration saved in ./results/checkpoint-1000/config.json\n","Model weights saved in ./results/checkpoint-1000/pytorch_model.bin\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","Saving model checkpoint to ./results/checkpoint-1500\n","Configuration saved in ./results/checkpoint-1500/config.json\n","Model weights saved in ./results/checkpoint-1500/pytorch_model.bin\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","Saving model checkpoint to ./results/checkpoint-2000\n","Configuration saved in ./results/checkpoint-2000/config.json\n","Model weights saved in ./results/checkpoint-2000/pytorch_model.bin\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","Saving model checkpoint to ./results/checkpoint-2500\n","Configuration saved in ./results/checkpoint-2500/config.json\n","Model weights saved in ./results/checkpoint-2500/pytorch_model.bin\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","Saving model checkpoint to ./results/checkpoint-3000\n","Configuration saved in ./results/checkpoint-3000/config.json\n","Model weights saved in ./results/checkpoint-3000/pytorch_model.bin\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","Saving model checkpoint to ./results/checkpoint-3500\n","Configuration saved in ./results/checkpoint-3500/config.json\n","Model weights saved in ./results/checkpoint-3500/pytorch_model.bin\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","Saving model checkpoint to ./results/checkpoint-4000\n","Configuration saved in ./results/checkpoint-4000/config.json\n","Model weights saved in ./results/checkpoint-4000/pytorch_model.bin\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","Saving model checkpoint to ./results/checkpoint-4500\n","Configuration saved in ./results/checkpoint-4500/config.json\n","Model weights saved in ./results/checkpoint-4500/pytorch_model.bin\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","Saving model checkpoint to ./results/checkpoint-5000\n","Configuration saved in ./results/checkpoint-5000/config.json\n","Model weights saved in ./results/checkpoint-5000/pytorch_model.bin\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","Saving model checkpoint to ./results/checkpoint-5500\n","Configuration saved in ./results/checkpoint-5500/config.json\n","Model weights saved in ./results/checkpoint-5500/pytorch_model.bin\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]}],"source":["train_results = trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":178},"executionInfo":{"elapsed":12218,"status":"ok","timestamp":1647207140001,"user":{"displayName":"Nadir Ounaggou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14687011903990117142"},"user_tz":-60},"id":"U9j6ZBcQllUV","outputId":"8f82cbc0-8200-4bc1-9b8f-e0ef562595de"},"outputs":[{"name":"stderr","output_type":"stream","text":["***** Running Prediction *****\n","  Num examples = 518\n","  Batch size = 8\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='65' max='65' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [65/65 00:11]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}],"source":["test_results = trainer.predict(test_dataset=test_dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1647207205318,"user":{"displayName":"Nadir Ounaggou","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14687011903990117142"},"user_tz":-60},"id":"72_BIMte5Q4K","outputId":"224b0a5b-4089-4911-d890-73fb21796651"},"outputs":[{"name":"stdout","output_type":"stream","text":["Predictions: \n"," [[-1.7919149  1.9175174 -1.1695372]\n"," [-2.0998962  1.9808561 -1.2448895]\n"," [-1.7759197  1.6685061 -1.1737936]\n"," ...\n"," [-1.732656   1.628288  -1.0976973]\n"," [-1.5971028  1.6696329 -1.0805976]\n"," [-2.1805737  1.9884248 -1.2964308]]\n","Accuracy:  0.6158301158301158\n","Precision:  [0.         0.61583012 0.        ]\n","Recall:  [0. 1. 0.]\n","F1:  [0.         0.76224612 0.        ]\n","['negative', 'neutral', 'positive']\n"]}],"source":["print('Predictions: \\n', test_results.predictions)\n","print('Accuracy: ', test_results.metrics['test_accuracy'])\n","print('Precision: ', test_results.metrics['test_precision'])\n","print('Recall: ', test_results.metrics['test_recall'])\n","print('F1: ', test_results.metrics['test_f1'])\n","print(classes)"]},{"cell_type":"markdown","metadata":{"id":"HL1A5EzIPzxT"},"source":["Si nous avons fait les choses bien, la performance (*accuracy*) de notre modèle dans la classification des phraces qu’il n’a jamais vu est d'environ 70.0%. Cela n'est pas très satisfaisant si on considère :\n","\n","1. que la distribution des classes dans notre ensemble de test n’était pas équilibrée (c.f. Exercice 2)\n","2. qu'un modèle de classification naïve bayésienne obtient une accuracy de 72.6% (c.f. Exercice 3)\n"," "]},{"cell_type":"markdown","metadata":{"id":"T21FtfBO5TBG"},"source":["### Améliorer les performances"]},{"cell_type":"markdown","metadata":{"id":"UIiPrE74SRV6"},"source":["#### Exercice 7\n","\n","1. Comment est-ce qu'on peut améliorer le résultat du modèle ?\n","2. Ré-entraînez le modèle avec la nouvelle stratégie et calculez ses performances avec les métriques utilisées avant. Quelle _accuracy_ vous arrivez à obtenir ?\n","\n","**Aide** : pensez à laisser le modèle améliorer l'encodage des phrases..."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ssy9fAXU2w4S"},"outputs":[],"source":["# WRITE CODE TO ANSWER THE QUESTION HERE.  PRINT THE ANSWER OR WRITE IT IN A TEXT CELL BELOW"]},{"cell_type":"markdown","metadata":{"id":"TMSR2zq-cbp3"},"source":["Si nous somme satisfaits de la performance de notre modèle, nous pouvons le sauvegarder pour l’utiliser dans le prochain exercice : "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FrOnJarvBDf2"},"outputs":[],"source":["MODEL_PATH = './my_model'\n","trainer_unfreezed.save_model(MODEL_PATH)"]},{"cell_type":"markdown","metadata":{"id":"t8MUjNgvllUg"},"source":["## Prédictions"]},{"cell_type":"markdown","metadata":{"id":"sX0bwUA5RkST"},"source":["#### Exercice 8\n","\n","En utilisant le modèle que l’on vient de sauvegarder, prédire la classe à laquelle appartient les phrases suivantes :\n","\n","````\n","  \"CocaCola saw its share price dropping of more than 25% this semester.\",\n","  \"Despite most of the company's sales are taking place in China, the shareholders decided not to relocate the production there.\" ,\n","  \"This year's profits quintuplicated with respect to the last year.\"\n","````\n","\n","1. Quelles classes a prédit le modèle ?\n","2. Avec quelle probabilité ?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4ZXfWabRllUh"},"outputs":[],"source":["# WRITE CODE TO ANSWER THE QUESTION HERE.  PRINT THE ANSWER OR WRITE IT IN A TEXT CELL BELOW"]},{"cell_type":"markdown","metadata":{"id":"sne9jShhiNae"},"source":["## Changer de modèle"]},{"cell_type":"markdown","metadata":{"id":"E4uf5_NyiQ41"},"source":["#### Exercice 9 (bonus)\n","\n","Expérimentez avec d’autres modèles pré-entraînés. La liste des modèles pré-entraînés est disponible ici: https://huggingface.co/models.\n","\n","- Qu’est-ce que vous avez essayé ? Laissez votre code dans des cellules ci-dessous. \n","- Qu’est-ce que vous avez appris ?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9FVOmYuOYamk"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"tp_bert.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"02045a312c3c46b288e7c0ccf99954df":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0502c98d69334b07939ae1806d05132e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"05da1b6252c14964a3048bd7804bb349":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b59a53cb69c64337a701cbebae257694","placeholder":"​","style":"IPY_MODEL_b647080d3baf47298e2466621b85ecf2","value":"Downloading: 100%"}},"05f9832f7a6c4f09b4909da706e9d161":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_45169928f9af49c5b2aead70e6d637c6","placeholder":"​","style":"IPY_MODEL_cdcd18b50a054c4a809f8b2b36629205","value":"Downloading: 100%"}},"094f3b8718784c189575f06eb80e50fe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_05f9832f7a6c4f09b4909da706e9d161","IPY_MODEL_b99c09df64634b51a1a7da3f9ef977b9","IPY_MODEL_11defae41da84536bf8bd74abfe9f2ce"],"layout":"IPY_MODEL_0f525a931b71457b8c3b9930edc0d0f8"}},"0ba0f0b02150463484ab170ceeb184a1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f525a931b71457b8c3b9930edc0d0f8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"11defae41da84536bf8bd74abfe9f2ce":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_646cee81cd1b4caaa46211ed73c84d6f","placeholder":"​","style":"IPY_MODEL_3b0a6096798845de8dde3420f4569642","value":" 483/483 [00:00&lt;00:00, 12.4kB/s]"}},"1bce05b7f5c843308990272ba5e3bbca":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2e8b9c999a1b4f578ea5f7d8d5f3f734":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b0a6096798845de8dde3420f4569642":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4287ec9b21bc4ab5959e22d20e2d57c9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4301c17ff2c14b5c95380dc5992e939a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45169928f9af49c5b2aead70e6d637c6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"577d0983b6414315a3898ff854a12350":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"646cee81cd1b4caaa46211ed73c84d6f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"66498e36d12e4015875f3b4e3ba62b4f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fc2bd89e08bc4feda021b7e5367ff70d","placeholder":"​","style":"IPY_MODEL_b45ebf680d064a329fa11e47c0cf58f2","value":" 226k/226k [00:00&lt;00:00, 282kB/s]"}},"691778e421a4490f9f17be0171f6f46a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"77563b78dcf946029dbf4e1f2509d492":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4301c17ff2c14b5c95380dc5992e939a","placeholder":"​","style":"IPY_MODEL_0502c98d69334b07939ae1806d05132e","value":" 28.0/28.0 [00:00&lt;00:00, 705B/s]"}},"7d40660b78eb48e197e2d0c2e89fb328":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ba0f0b02150463484ab170ceeb184a1","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1bce05b7f5c843308990272ba5e3bbca","value":28}},"81b44569749c4ea58fd5810185be0a5f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8731f2a8ea7640718256b08648ce190c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ec4ced9e14a48dba408b7a116273db9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_909ad98446d6478ea5b7401e567a67ec","IPY_MODEL_7d40660b78eb48e197e2d0c2e89fb328","IPY_MODEL_77563b78dcf946029dbf4e1f2509d492"],"layout":"IPY_MODEL_8731f2a8ea7640718256b08648ce190c"}},"909ad98446d6478ea5b7401e567a67ec":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_81b44569749c4ea58fd5810185be0a5f","placeholder":"​","style":"IPY_MODEL_9e0de133f36e456082024437fe18c132","value":"Downloading: 100%"}},"971c8753cd1246dcba1933cd301bf725":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9761b5f844564a11a172fb907e6f1816":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ec5aaa623eb64cd2b54b3d55362ead62","IPY_MODEL_c501abc913644f8dafb50924d1d21a1c","IPY_MODEL_66498e36d12e4015875f3b4e3ba62b4f"],"layout":"IPY_MODEL_dd9084ee925a46858d04fae94bbbb771"}},"9e0de133f36e456082024437fe18c132":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a327d5c4a7874359a17567da51ba804c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_05da1b6252c14964a3048bd7804bb349","IPY_MODEL_dfade37f6ec54c019ed3d9348c8df091","IPY_MODEL_e1f97ed3fa5f4a63be42e04902639aa5"],"layout":"IPY_MODEL_691778e421a4490f9f17be0171f6f46a"}},"ad06a3db8c2449c0a7a81bfa07b3b514":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b45ebf680d064a329fa11e47c0cf58f2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b59a53cb69c64337a701cbebae257694":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b647080d3baf47298e2466621b85ecf2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b99c09df64634b51a1a7da3f9ef977b9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_02045a312c3c46b288e7c0ccf99954df","max":483,"min":0,"orientation":"horizontal","style":"IPY_MODEL_971c8753cd1246dcba1933cd301bf725","value":483}},"c501abc913644f8dafb50924d1d21a1c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2e8b9c999a1b4f578ea5f7d8d5f3f734","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e715bf5a48274ab1a83489699ba60895","value":231508}},"cd67999091a54016a8c8b119f8547710":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cdcd18b50a054c4a809f8b2b36629205":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d8e48f84f4fa49eda51cbe952af7f602":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd9084ee925a46858d04fae94bbbb771":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dfade37f6ec54c019ed3d9348c8df091":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad06a3db8c2449c0a7a81bfa07b3b514","max":267967963,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cd67999091a54016a8c8b119f8547710","value":267967963}},"e1f97ed3fa5f4a63be42e04902639aa5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_577d0983b6414315a3898ff854a12350","placeholder":"​","style":"IPY_MODEL_4287ec9b21bc4ab5959e22d20e2d57c9","value":" 256M/256M [00:07&lt;00:00, 36.5MB/s]"}},"e715bf5a48274ab1a83489699ba60895":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ec5aaa623eb64cd2b54b3d55362ead62":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d8e48f84f4fa49eda51cbe952af7f602","placeholder":"​","style":"IPY_MODEL_ec7da52a0efa49ff815df2d81258521a","value":"Downloading: 100%"}},"ec7da52a0efa49ff815df2d81258521a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fc2bd89e08bc4feda021b7e5367ff70d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}
